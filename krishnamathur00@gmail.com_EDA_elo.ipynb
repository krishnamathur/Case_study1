{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our business problem is to find out that the promotions given by the\n",
    "company to the customer and the merchants works or not. Do\n",
    "customers enjoy their experience? Do merchants see any profit from\n",
    "these? Now, our problem at hand is to find out how useful and\n",
    "beneficial these promotions are for merchants as well as for the\n",
    "customers. We need to find out if the customers actually use these\n",
    "promotions or discounts offered to them. Customer loyalty score will\n",
    "give us an idea of how often the users/customers use these\n",
    "promotions and discounts offered to them. With the data they have\n",
    "collected our goal is to predict the loyalty score which then will help\n",
    "the company (Elo) to now focus on the customers which are more\n",
    "loyal. This would also ensure that Elo reduces the unwanted\n",
    "marketing campaigns towards the customers who are predicted to\n",
    "have low customer loyalty. This would ultimately lead to better\n",
    "customer retention rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from math import sqrt\n",
    "from numpy import hstack\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/frtgnn/elo-eda-lgbm\n",
    "# this code reduce the memory of dataframe\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple files given now we will read and understand each files one by one to look what features are provided and what new features we can invent in order to solve the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 6)\n"
     ]
    }
   ],
   "source": [
    "# reading the train.csv file\n",
    "train = pd.read_csv('train.csv')\n",
    "# looking how many rows and columns are there in the file\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0            2017-06  C_ID_92a2005557          5          2          1   \n",
       "1            2017-01  C_ID_3d0044924f          4          1          0   \n",
       "2            2016-08  C_ID_d639edf6cd          2          2          0   \n",
       "3            2017-09  C_ID_186d6a6901          4          3          0   \n",
       "4            2017-11  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  \n",
       "0 -0.820283  \n",
       "1  0.392913  \n",
       "2  0.688056  \n",
       "3  0.142495  \n",
       "4 -0.159749  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking the first five rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of columns provided for train.csv file - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "card_id: Unique card identifier\n",
    "\n",
    "first_active_month: 'YYYY-MM', month of first purchase\n",
    "\n",
    "feature_1: Anonymized card categorical feature\n",
    "\n",
    "feature_2: Anonymized card categorical feature\n",
    "\n",
    "feature_3: Anonymized card categorical feature\n",
    "\n",
    "target: Loyalty numerical score calculated 2 months after historical and evaluation period!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_active_month     object\n",
       "card_id                object\n",
       "feature_1               int64\n",
       "feature_2               int64\n",
       "feature_3               int64\n",
       "target                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking the data tyoes of all columns\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_active_month        75\n",
       "card_id               201917\n",
       "feature_1                  5\n",
       "feature_2                  3\n",
       "feature_3                  2\n",
       "target                197110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many unique entries a column contains\n",
    "train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the uniquie values a feature holds we can see that feature_1, feature_2, feature_3 are categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>feature_1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.130969</td>\n",
       "      <td>0.583092</td>\n",
       "      <td>-0.014251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feature_2</td>\n",
       "      <td>-0.130969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060925</td>\n",
       "      <td>-0.006242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feature_3</td>\n",
       "      <td>0.583092</td>\n",
       "      <td>0.060925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>target</td>\n",
       "      <td>-0.014251</td>\n",
       "      <td>-0.006242</td>\n",
       "      <td>-0.008125</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature_1  feature_2  feature_3    target\n",
       "feature_1   1.000000  -0.130969   0.583092 -0.014251\n",
       "feature_2  -0.130969   1.000000   0.060925 -0.006242\n",
       "feature_3   0.583092   0.060925   1.000000 -0.008125\n",
       "target     -0.014251  -0.006242  -0.008125  1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the correlation between features in train.csv\n",
    "train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using violin plot understanding how given features are helping in predicting loyalty scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature 1\n",
    "sns.violinplot(x=train['feature_1'], y=train['target'])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.xlabel('Feature 1', fontsize=12)\n",
    "plt.ylabel('Loyalty score', fontsize=12)\n",
    "plt.title(\"Feature 1 distribution\")\n",
    "plt.show()\n",
    "\n",
    "# feature 2\n",
    "\n",
    "sns.violinplot(x=train['feature_2'], y=train['target'])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.xlabel('Feature 2', fontsize=12)\n",
    "plt.ylabel('Loyalty score', fontsize=12)\n",
    "plt.title(\"Feature 2 distribution\")\n",
    "plt.show()\n",
    "\n",
    "# feature 3\n",
    "sns.violinplot(x=train['feature_3'], y=train['target'])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.xlabel('Feature 3', fontsize=12)\n",
    "plt.ylabel('Loyalty score', fontsize=12)\n",
    "plt.title(\"Feature 3 distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the plots are looking same it is not possible to see any information which can help us to determine which features is more helpful in pridicting loyalty score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution of Taeget variable which is Loyalty Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train['target'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that maximum value lies in the range of -10 to 10 but we can see some outliners with values around -30 and above.\n",
    "Now lets look the number of points which are having loyalty score less than -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2264"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train['target'] < -10).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see out of 201917 total points only 2264 are outliners which are very less nearly a little over 1% of all the data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are checking if we have any null values in our train.csv file and we found are none null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_active_month    0\n",
       "card_id               0\n",
       "feature_1             0\n",
       "feature_2             0\n",
       "feature_3             0\n",
       "target                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the histogram for every featurs in the train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:307: MatplotlibDeprecationWarning: \n",
      "The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead.\n",
      "  layout[ax.rowNum, ax.colNum] = ax.get_visible()\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:307: MatplotlibDeprecationWarning: \n",
      "The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead.\n",
      "  layout[ax.rowNum, ax.colNum] = ax.get_visible()\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:313: MatplotlibDeprecationWarning: \n",
      "The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead.\n",
      "  if not layout[ax.rowNum + 1, ax.colNum]:\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:313: MatplotlibDeprecationWarning: \n",
      "The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead.\n",
      "  if not layout[ax.rowNum + 1, ax.colNum]:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001DD79860C48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD798993C8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001DD798CFA88>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD7990B208>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.hist(bins=30, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see the distribution of values of categorical features which occurs maximum time and we can see that for feature_1 we have 5 values and the value 3 occures for maximum times, for feature_2 we have 3 values and the value 1 occures for maximum times, for feature_3 we have 2 values and the value 1 occures for maximum times  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting object type to date type\n",
    "train['first_active_month'] = pd.to_datetime(train['first_active_month']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are provided with a date column lets look the count of values over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14ee761abc8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAADuCAYAAAA5pXBbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyc5XXo8d+ZRTPabVnyJtmWbWxsbLNZgLOYPYGkCdAEEqdNcBuKE0obkjZtIL256U1KC03bNDQJXAopkHAhzgZuEkMIEMDFGIQNMQIbJMuLLNuSbGu3lpk594/3HXuQx1pmRjOj0fl+PvrMzPMueh6PNWeeXVQVY4wxxpPpDBhjjMkOFhCMMcYAFhCMMca4LCAYY4wBLCAYY4xxWUAwxhgDgC/TGUhUeXm5VldXZzobxhgzobz66qttqloR79iEDQjV1dXU1tZmOhvGGDOhiMieUx2zJiNjjDGABQRjjDGuEQOCiPxARFpE5I04x74sIioi5TFpt4lIvYjsFJErYtJXish299hdIiJuekBEfuymbxGR6tQUzRhjzFiMpobwAHDl0EQRmQN8ANgbk3YGsAZY5l7zfRHxuofvBtYBi9yf6D1vAI6q6mnAt4E7EymIMcaY5IwYEFT1eeBInEPfBv4WiF0d72rgUVXtV9VGoB44X0RmASWqulmd1fQeAq6JueZB9/lPgcuitQdjjDHpk1AfgohcBexX1deHHKoE9sW8bnLTKt3nQ9PfdY2qhoAOYNopfu86EakVkdrW1tZEsm6MMVltMBzh1T1HCEfSvxL1mIedikgB8HfAB+MdjpOmw6QPd83Jiar3AvcC1NTU2Lrdxpic8vahLv56/ets39/B4hlF/M0VS7h86XTS1WiSSA1hITAfeF1EdgNVwFYRmYnzzX9OzLlVQLObXhUnndhrRMQHlBK/icoYY3JSOKLc81wDH7lrE83tx/jyBxczGFZufKiWa+/ZzMuN6flIHHNAUNXtqjpdVatVtRrnA/1cVT0IbADWuCOH5uN0Hr+sqgeALhFZ5fYPXA887t5yA7DWfX4t8Izarj3GmElid1sP193zInds3MGlS6bz5Jcu5C8uXcRvvnQh//iHK9h3pJdP/N/NfO/Z+nHPy2iGnT4CbAZOF5EmEbnhVOeqah2wHngTeAK4WVXD7uGbgPtwOpobgI1u+v3ANBGpB/4KuDXBshhjzISiqnz2gVeob+nmO2vO5u5Pn0t5UQAAv9fDH10wl+f+5hIuOb2Ce37XQGff4LjmRybql/Gamhq1pSuMMRPZrtZuLv3X5/jmNcv5zKp5pzxve1MHH/3uJm790BI+f9HCpH6niLyqqjXxjtlMZWOMyZDn33ZGS160KO5ac8etqCrlfadN4webGukPhYc9NxkWEIwxJkOef6eN6mkFzJ1WMOK5n7twIS1d/Ty+rXnEcxNlAcEYYzKgPxRmc8NhLlw8fO0gavWicpbNLuGe5xuIjNMcBQsIxhiTAbW7j3JsMMyFIzQXRYkIn7toIbtae/jtW4fGJU8WEIwxJgOef7sVv1d4z8K4CzPE9eHlM5lTls89zzUwHgOCLCAYY0wGPPd2KzXzyigMjH7BCJ/Xw42rF7B1bzu1e46mPE8WEIwxJs1aOvvYcbBr1P0Hsa5bOYeywjzu+V1DyvNlAcEYY9Ls+XfaALhwcfkIZ54sP8/L9e+Zx9M7WjjY0ZfSfFlAMMaYNHv+7VbKiwIsnVmS0PXnV5cBsKutO5XZsoBgjDHpFIkom+rbuHBROR5PYquYVk115i3sP3oslVmzgGCMMen0RnMHR3oGEuo/iJpZGkQEmiwgGGPMxBVdruL9i8befxCV5/MwsyRoAcEYYyay599uY3llyfFVTRNVNTWfpqO9KcqVwwKCMcakSWffIK/uPTrq2cnDqZpaYDUEY4yZqF5qOEw4okn1H0RVTc3nYGcfoXAkBTlzWEAwxpg02XmwC4Cz50xJ+l6VU/IJR5SDnambizCaHdN+ICItIvJGTNq3RGSHiPxeRH4hIlNijt0mIvUislNErohJXyki291jd7lbaeJut/ljN32LiFSnrHTGGJNFdh/uZVZpkKDfm/S9okNPU9lsNJoawgPAlUPSngKWq+qZwNvAbQAicgawBljmXvN9EYmW/G5gHc4+y4ti7nkDcFRVTwO+DdyZaGGMMSab7Tncw7xR7H0wGlVT84E0BwRVfR44MiTtN6oacl++BFS5z68GHlXVflVtxNk/+XwRmQWUqOpmdZboewi4JuaaB93nPwUui9YejDEml+w+3EP1tMKU3GvWlOhchNSNNEpFH8JngY3u80pgX8yxJjet0n0+NP1d17hBpgMY/XqwxhgzAXT1DdLWPcC8FAWEgM/LjOJgSmcrJxUQROTvgBDwcDQpzmk6TPpw18T7fetEpFZEaltbW8eaXWOMyZg9h51v8tUpajICqJyan/Y+hLhEZC3wEeCP9cRODU3AnJjTqoBmN70qTvq7rhERH1DKkCaqKFW9V1VrVLWmoiL5YVvGGJMu0YCQqhoCuJPT2jPcZCQiVwJfAa5S1djcbADWuCOH5uN0Hr+sqgeALhFZ5fYPXA88HnPNWvf5tcAzOh5bARljTAbtPtwDkLJOZXACwoH21M1FGHGrHhF5BLgYKBeRJuDrOKOKAsBTbv/vS6r6eVWtE5H1wJs4TUk3q2rYvdVNOCOW8nH6HKL9DvcDPxSRepyawZqUlMwYY7LInsM9VBQHxrRD2kiqphYQiiiHuvqpnJKf9P1GzJmqfipO8v3DnH87cHuc9FpgeZz0PuC6kfJhjDET2e7DvcxPYXMRnBh6uv/osZQEBJupbIwxaZDKOQhR0SCQqqGnFhCMMWac9Q6EONTZT3V5amsIs6ekdnKaBQRjjBlne49ERxiltoYQ9HuZXhywGoIxxkwUu9uicxBSW0OA6L4IVkMwxpgJYY875HRuimsIkNp9ESwgGGPMONt9uJdphXmUBP0pv3fl1HwOdBwjHEl++pYFBGOMGWe721I/wiiqamo+g2GlpSv5fREsIBhjzDjbk8JVTodK5b4IFhCMMWYc9Q2Gae7oS+kaRrFO7IuQ/EgjCwjGGDOO9rlDTqvLx6fJ6PjktCNWQzDGmKy2exxWOY0V9HspLwqwv90CgjHGZLXokNNU7oMwVKrmIlhAMMaYcbT7cA+l+X6mFOSN2+9wAoL1IRhjTFbbc7h3XGsH4Iw02t9+jEiScxEsIBhjzDjafbgn5YvaDXViLkJ/UvexgGCMMeNkIBRh/9Fj49ahHFUZ3Rchye00LSAYY8w4aTraS0THt0MZYM7U1CyDPWJAEJEfiEiLiLwRk1YmIk+JyDvu49SYY7eJSL2I7BSRK2LSV4rIdvfYXe7eyrj7L//YTd8iItVJlcgYY7LEnnEechpVOcUJONE5D4kaTQ3hAeDKIWm3Ak+r6iLgafc1InIGzp7Iy9xrvi8iXveau4F1wCL3J3rPG4Cjqnoa8G3gzkQLY4wx2WR3GoacAuTneSnM89LeO5jUfUYMCKr6PHBkSPLVwIPu8weBa2LSH1XVflVtBOqB80VkFlCiqptVVYGHhlwTvddPgcuitQdjjJnIdrf1UBzwUVY4fkNOo4J+L32hcFL3SLQPYYaqHgBwH6e76ZXAvpjzmty0Svf50PR3XaOqIaADmBbvl4rIOhGpFZHa1tbWBLNujDHp0Xi4l3nlBaTjO27Q76VvMJLUPVLdqRyv1DpM+nDXnJyoeq+q1qhqTUVFRYJZNMaY8dfa1c9Luw5z9pwpafl9Ab+HvsHM1BAOuc1AuI8tbnoTMCfmvCqg2U2vipP+rmtExAeUcnITlTHGTCgPvNjIYDjCZ983Py2/L+jLXA1hA7DWfb4WeDwmfY07cmg+Tufxy26zUpeIrHL7B64fck30XtcCz7j9DMYYMyF194f44eY9XLlsJgsqitLyOwN+D/1J9iH4RjpBRB4BLgbKRaQJ+DpwB7BeRG4A9gLXAahqnYisB94EQsDNqhrN4U04I5bygY3uD8D9wA9FpB6nZrAmqRIZY8wYhMIRnqw7xJlVpcwpS81ooEe27KWzL8TnL1qYkvuNhlNDGOeAoKqfOsWhy05x/u3A7XHSa4HlcdL7cAOKMcak0wvvtPIPv3yLnYe6+OhZs/mPT52T9D0HQhHu39TIexZM46w09R8ABP0e2rpDSd1jxIBgjDG5pqG1m3/81Vs8vaOFOWX5LJtdwiuNR1DVpEcEPfbafg529nHntWemKLej44wyykynsjHGTEjPv93KFd9+ni2NR7j1Q0t46ksX8cnz5nCwsy/ppR8iEeXe53exdFYJFy4qT1GORycV8xCshmCMmVR++9Yhgn4vz375YiqKAwDUzCsD4JXdR5LqR3h6Rwv1Ld18Z83ZaZl7ECvo92TdPARjjMlqDa3dLJxedDwYAJw+s5jioI9Xdic34v2e5xqomprPH6yYlWw2xyyQgk5lCwjGmEmloaWHhRXvXmzO6xFq5k3lld1HE77vsztbeHXPUW5cvQCfN/0frUG/l36rIRhjzOh09Q1ysLOP06afPDegprqM+pZujvQMjPm+9S3dfOGRbZw+o5hP1MwZ+YJxEPR7GAhHCCexa5oFBGPMpLGr1Vl9dGGcyWLnzz/RjzAWR3sGuOHBV8jzerhvbQ35ed6RLxoHQb/ze5OZnGYBwRgzaTS0dgPxA8KKylLyvB5qxxAQBkIRPv+jVznQ0ce9169M2cS2RAR9zsd5Mh3LFhCMMZNGQ2s3Po8wL87+BEG/l7PmlPLyKPsRVJX/9dh2tjQe4VvXnslKd6RSpkRrCMl0LFtAMMZMGvUt3cybVoD/FJ2+51WXUbe/g96BkWf83r+pkfW1TXzh0tO4+uzKEc8fbxYQjDFmDBpae+I2F0WdV11GKKK8trd92Pts23uUf9q4gyuXzeSLly9OdTYTEvRbk5ExxozKYDjCnsM9LIwzwijq3HlTEYGXh+lH6Oob5AuPbmNmSZA7rz0Tjyc7NngMRGsISXQq20xlY8yksO9IL4NhHbaGUJrvZ8nMEmqH6Uf42mNv0Nzex/rPraI03z8eWU1I0OeOMrIagjHGDK/BHXIabw5CrPOqp7J171FC4ZM/WH++tYnHXmvmlssWZbwTeajjTUY27NQYY4ZX3+IMOV0wZJbyUOdVl9E7EKauufNd6bvbevjaY29w/vwybr7ktHHLZ6KOz0OwTmVjjBleQ2s304sDlASHb+Y5r/rkCWo9/SFueXQbPq+Hf//k2XizpN8g1olRRtZkZIwxw2po7R62/yBqZmmQOWX5vLL7CL0DIe55roHV//wsrzd1cOfHVzB7Sn4acjt2geMT0zJUQxCRL4lInYi8ISKPiEhQRMpE5CkRecd9nBpz/m0iUi8iO0Xkipj0lSKy3T12l6R73VhjTE5TVRpaukfsP4g6r7qMTe+0sfrOZ7lj4w5WVJbyiz9/L1cuT/8qpqOV0XkIIlIJfAGoUdXlgBdnP+RbgadVdRHwtPsaETnDPb4MuBL4vohEF/24G1gHLHJ/rkw0X8YYM1Rrdz+dfaGTVjk9lYsWV9AzEGZZZSk/u+m9PPjZ8zln7tSRL8ygE53KiTcZJTvs1Afki8ggUAA0A7cBF7vHHwR+B3wFuBp4VFX7gUYRqQfOF5HdQImqbgYQkYeAa4CNSebNGGMAZ8lrYNg5CLGuOms2F8yfxszS4HhmK6Wiw04zUkNQ1f3AvwB7gQNAh6r+Bpihqgfccw4A091LKoF9MbdoctMq3edD008iIutEpFZEaltbWxPNujFmkhluUbt4RGRCBQMAj0fI8ya3a1oyTUZTcb71zwdmA4Ui8unhLomTpsOkn5yoeq+q1qhqTUVFxVizbIyZpBpauynI8zJrgn3Ij1XA78lYp/LlQKOqtqrqIPBz4L3AIRGZBeA+trjnNwGxO0dU4TQxNbnPh6YbY0xKRNcwyvXxKkG/N2P7IewFVolIgTsq6DLgLWADsNY9Zy3wuPt8A7BGRAIiMh+n8/hlt1mpS0RWufe5PuYaY4xJWkNL96g7lCeyoD+5JqOEO5VVdYuI/BTYCoSAbcC9QBGwXkRuwAka17nn14nIeuBN9/ybVTUaym4CHgDycTqTrUPZGJMSvQMh9rcfY01FZra2TKegz5tUk1FSo4xU9evA14ck9+PUFuKdfztwe5z0WmB5Mnkxxph4jm+bOcoRRhNZ0J9cQLCZysaYnBYdYTTaSWkTWbJNRhYQjDE5raGlG48Qd9vMXBP0e221U2OMOZWG1h7mlhUQ8HlHPnmCC/i8VkMwxphTGe2idrkg6PfY8tfGGBNPfyhMfUs3p88sznRW0sI6lY0x5hTeOdRNKKIsm12a6aykRdDvSWpxOwsIxpicVdfcAcCy2SUZzkl6BH1eazIyxph46po7KQr4mFuW+yOMIDrKyGoIxhhzkrrmTs6YVYInC7e8HA8Bn4dwRBkMJxYULCAYY3JSOKK8daCTMyZJcxEkv2uaBQRjTE7afbiH3oHwpOk/gJhd0xKci2ABwRiTk+qaOwEmzQgjgIDVEIwx5mR1zR3keT0smjE5JqXBiSajRPdEsIBgjMlJbzZ3snhmEX7v5PmYC/qsycgYY95FValr7mTZrMnTXATWqWyMMSc52NnHkZ4BllVOng5liA0IGaghiMgUEfmpiOwQkbdE5D0iUiYiT4nIO+7j1JjzbxORehHZKSJXxKSvFJHt7rG7JNc3PjXGjKu6/dEO5ckWEKJNRpmpIXwHeEJVlwBn4eypfCvwtKouAp52XyMiZwBrgGXAlcD3RSS6Hu3dwDqcfZYXuceNMSYhdc2diMCSmZMtILg1hHR3KotICXAhcD+Aqg6oajtwNfCge9qDwDXu86uBR1W1X1UbgXrgfBGZBZSo6mZVVeChmGuMMWbM6po7mF9eSGEgqV2CJ5ygL3NNRguAVuC/RGSbiNwnIoXADFU9AOA+TnfPrwT2xVzf5KZVus+HphtjTELqmjsn1fyDqEw2GfmAc4G7VfUcoAe3eegU4vUL6DDpJ99AZJ2I1IpIbWtr61jza4yZBNp7B9jffmzS9R9AZiemNQFNqrrFff1TnABxyG0Gwn1siTl/Tsz1VUCzm14VJ/0kqnqvqtaoak1FRUUSWTfG5Ko3mydnhzKcqCH0J7jiacIBQVUPAvtE5HQ36TLgTWADsNZNWws87j7fAKwRkYCIzMfpPH7ZbVbqEpFV7uii62OuMcaYMZmMS1ZE5Xk9iCReQ0i2x+UvgYdFJA/YBfwpTpBZLyI3AHuB6wBUtU5E1uMEjRBws6pGc30T8ACQD2x0f4wxZszqmjuYVRqkrDAv01lJOxEh6Et8G82kAoKqvgbUxDl02SnOvx24PU56LbA8mbwYYwxEO5QnX3NRVNDvsaUrjDHm2ECYhtZuzpiEzUVRQX/iNQQLCMaYnLHjYCcRnZwdylFBvzf9ncrGGJNttu5tByZ3QAj4PFZDMMaY/369maWzSqiaWpDprGRMwO+lz2oIxpjJbHdbD6/ta+eas2dnOisZFbQagjFmsnv8tWZE4KrJHhD8XvotIBhjct1gOH5TiKry2Gv7WTV/GrNK89Ocq+xiw06NMTnviTcOcu43n+L3Te0nHft9UweNbT1cc87krh2AO+zU9lQ2xuQqVeWup9+hqy/EV3+xndCQmsIvtu0nz+vhyuWzMpTD7JHMTGULCMaYrLe54TBvHujk8qUzeGN/Jw9u3nP8WCgc4Ze/b+bSJdMpzfdnMJfZwZqMjDE57T9f2EV5UR7f/aNzuOT0Cv71Nztpbj8GwP80HKate4BrzrFtVMBmKhtjclh9SxfP7mzlM6uqCfq9fOPq5URU+fqGOgAe27afkqCPS5bYkvjgzEPoD0VwNqAcGwsIxpisdt8LjQR8Hj69ai4Ac8oK+NLli3nqzUM8tm0/T9Yd5MMrZhHweUe40+SQzJ4IFhCMMVmrtaufn2/bz8dXVjGtKHA8/bPvn8+SmcV8+Sev0zsQ5uqzrbko6sS+ymNvNrKAYIzJWj96aQ8DoQg3vH/+u9L9Xg//+LEVhFWZVRrkgvllGcph9gke30Zz7DWEZDfIMcaYcdE3GOaHL+3h8qXTWVhRdNLxc+dO5ZtXL6e8KA+PJ97W7JNTtMkokRqCBQRjTFb6+db9HOkZ4M9WLzjlOZ9eNS+NOZoYjtcQEpiclnRAEBEvUAvsV9WPiEgZ8GOgGtgNfEJVj7rn3gbcAISBL6jqk276Sk5soflr4BZNpIvcGDNhqSr1Ld28tOswL+06wvNvt7KistSag8boRA0hM01GtwBvAdEFyG8FnlbVO0TkVvf1V0TkDGANsAyYDfxWRBa7+yrfDawDXsIJCFdi+yobM2m8c6iL63/wMgc6+gCYXRrkA8tm8PmLFiJizUFjkUynclIBQUSqgD/A2Sf5r9zkq4GL3ecPAr8DvuKmP6qq/UCjiNQD54vIbqBEVTe793wIuAYLCMZMGv/xTD1dfSH++eNnsmrBNOaU5VsgSFDAn6GAAPw78LdAcUzaDFU9AKCqB0RkupteiVMDiGpy0wbd50PTTyIi63BqEsydOzfJrBtjssH+9mP8avsBPvu+aj5x3pxMZ2fCC/gSbzJKeNipiHwEaFHVV0d7SZw0HSb95ETVe1W1RlVrKipsVqIxueC/NjUC8Cfvmz/CmWY0op3K/WnuVH4fcJWIfBgIAiUi8iPgkIjMcmsHs4AW9/wmIDb8VwHNbnpVnHRjTI7r7Bvk0Vf28QcrZlE5ZXLvY5Aqx2cqp7OGoKq3qWqVqlbjdBY/o6qfBjYAa93T1gKPu883AGtEJCAi84FFwMtu81KXiKwSp9Hw+phrjDE57Mcv76O7P8SNwwwtNWOT0WGncdwBrBeRG4C9wHUAqlonIuuBN4EQcLM7wgjgJk4MO92IdSgbk/MGwxH+638auWB+GSuqSjOdnZwRzGCnMgCq+juc0USo6mHgslOcdzvOiKSh6bXA8lTkxRgzMfx6+wGaO/r4xtX2p59KwUx0KhtjTKJUlfteaGRBRSGXLpk+8gVm1HxeDz6P2OJ2xpiJYUvjEbbv7+CG98+3dYjGgbNJjtUQjDFZLhxRvvtMPWWFeXz83KqRLzBjFvR7EupUtoBgjEkbVeX//Hcdm+rb+OLli453gJrUCvgS20bTAoIxJm3+45l6Htq8hxtXz+f691RnOjs5K+j3pHcegjHGjMXDW/bwb0+9zcfOreS2Dy3NdHZymtOHYDUEY0wW2rj9AP/rsTe4dMl07vz4mdaRPM6Cfq/1IRhjsk9Daze3PPoa58yZwvf+6Fz8XvvYGW9Bv8dGGRljss8jW/aiKPd8ZiX5edaJnA5B61Q2xmSbwXCEx17bz2VLZjC9OJjp7Ewa1odgjMk6z+5ooa17gOtqbL5BOgWsycgYk23W1zZRURzgosW2f0k6Bf3ehPZDsIBgjBkXrV39PLuzhY+dW4nPOpLTKuCzGoIxJos8tm0/4Yhy3UrbFjPdrA/BGJNy25s6GAyP/ZumqrK+dh/nzJ3CadOLxiFnZjhBn5dQRAmN8b2zgGCMiWvb3qN89Lub+Len3h7zta83dfBOS7fVDjIkuo1mXyhNAUFE5ojIsyLylojUicgtbnqZiDwlIu+4j1NjrrlNROpFZKeIXBGTvlJEtrvH7nK30jTGZNB/vrALgPs3NdJ0tHdM1/6kdh9Bv4ePnDVrPLJmRhBdNLB/jM1GydQQQsBfq+pSYBVws4icAdwKPK2qi4Cn3de4x9YAy4Arge+LSHSWyt3AOpx9lhe5x40xGbL3cC9PvHGQPzynEgH++Ymdo762bzDMhteb+dDyWZQE/eOXSXNKaa8hqOoBVd3qPu8C3gIqgauBB93THgSucZ9fDTyqqv2q2gjUA+eLyCygRFU3q6oCD8VcY4zJgB/8TyNej3Drh5Zw4+oFbHi9mdf2tY/q2ifrDtLVF+K6lTb3IFMS3Vc5JX0IIlINnANsAWao6gFwggYQ3R+vEtgXc1mTm1bpPh+abozJgPbeAdbX7uOqsyqZURLk8xcvpLwowD/88k2c72yn1jcY5r4XGqmams+qBdPSlGMzVMCXoYAgIkXAz4AvqmrncKfGSdNh0uP9rnUiUisita2trWPPrDFmRA9v2UvvQJg/Wz0fgKKAj7/+4GJq9xxl4xsHT3ldOKLc8ug23mju4KsfXmormmbQ8SajMc5FSCogiIgfJxg8rKo/d5MPuc1AuI8tbnoTEDvkoApodtOr4qSfRFXvVdUaVa2pqLCZj8ak2kAowoMv7mb1onKWzio5nv6JmjksmVnMHRt3xJ0Bq6r878ff4Mm6Q3ztD87gwyusMzmT0t6p7I4Euh94S1X/LebQBmCt+3wt8HhM+hoRCYjIfJzO45fdZqUuEVnl3vP6mGuMMWm04fVmWrr6uXH1gnelez3CVz+8lL1Herl/UyORyLsr8d99pp6Ht+zlcxct4LPvn5/OLJs4jvchjHH5Cl8Sv/N9wGeA7SLympv2VeAOYL2I3ADsBa4DUNU6EVkPvIkzQulmVY3m9ibgASAf2Oj+GGPSSFW574VdLJlZzOpF5Scdv3BxBRefXsE/P7GTe37XwFlzpnBW1RQ8HuGup9/hY+dU8pUrlmQg52aoRJuMEg4IqrqJ+O3/AJed4prbgdvjpNcCyxPNizEmMX2DYfYe6WV3Ww9b97az42AX37r2TE41Fei7f3Quv/79AV5rauf1fe3c/VwD4Yhy4eIK7rzWdkLLFsEEO5WTqSEYYyYAVaWuuZOXdh3mQEcfBzqOOY/tfRzs7HvXuWfNmcJVZ88+5b2KAj4+cd4cPnGe0x14bCBMY1sPi2YU2U5oWeTEsNM01RCMMdlBVWnp6ifo91KY58Xn9aCqvLG/k19tP8Cvtx9g7xFnpnG+38usKUFml+bz/kXlzC0roLq8kOppBcwrK6S0YGwTyfLzvJwxu2TkE01anWgyshqCMZNGe+8Af/7wVl5sOHw8Lc/nIeD10NUfwusR3rtwGjdfspBLl8ygvCjvlM1BJndkolPZGJNBu1q7ueHBWvYfPcZffWAxBXleegfC9PSH6B0Is7yyhA+eMZOphRVWprwAAA6gSURBVHmZzqpJs4AvzZ3KxpjMebGhjZt+tBWvR3j4xgs4r7os01kyWURECPg8Y56HYAHBmAkkElEefnkv/2dDHfPLC7l/7XnMnVaQ6WyZLJTIJjkWEIyZAFSVp99q4V9+s5MdB7tYvaic7/3xubaaqDmlRLbRtIBgTJbb3HCYbz25g61726meVsBdnzqHj6yYZWP+zbCCfq91KhuTK+qaO7jziZ08/3YrM0uC/NPHVnDtyiob729GJej3WJORMRPdviO9/OtvdvLYa82U5vv56oeXcP17qo8PJTRmNJw+BGsyMmbCUVW27WvnZ6828ZPaJkTgposX8vmLFlKab/0EZuyCPutUNiYj+gbDdPeHKC8KjOm6+pYuHn+tmcdfa2bvkV7yfB4+dm4lX7x8MTNLg+OUWzMZBPweuvpCY7rGAoIxSXizuZNHX9nLL7btp6svxNyyAs6rLuO86qnUVJcxrTAPn1fwez34PMLhngE2Nxxmc8NhXtzVxr4jx/AIvO+0cr5w2SI+uGyGjRwyKRH0e2nt6h/TNRYQjDmFgVCE/e3H2HuklyM9/YTCSjiihCJK70CIX20/yOv72snzefjw8pksnVXC1r1H+d3OFn62tWnYe5cEfaxaMI0bVy/gyuUzmV5stQGTWkG/l/6Q9SGYSaSzb5Cte47y6p6jvN7UQUVRgAsWlHHB/DLmlhUcX7enrbufHQe6ePtQF6FIxPnG7vWQ5xXCEef48Z+uAfa3H6O54xjDbSG8aHoR//sjZ/CxcyuZUnBieQhVZVdbD9v2ttPVN0gorAxGIoTCSkGel1ULprF0VgleGzZqxlHQZ6OMTI6LRJRt+47ymzcP8dzOVnYe6kIVPAKLZxSzvan9+LfzGSUBqqcV0tDaQ1v3yFXn0nw/5UV5lBcFuGB+GXPKCpyfqflMLwni8wg+r+D1CD6Ph6kF/rgLxYkICyuKWFhRlPLyGzNaNlPZ5Jye/hB7DvfS2NbDC++08tu3Wmjr7sfnEc6fX8YXL1tMTfVUzp4zhcKAj0hEaWjtZkvjEV5uPMLeI71ccnoFS2aVsHRmMYtnFpPv9zIYjjAQdr61i0BZYR4Bnw3rNLnDmYcwQZuMRORK4DuAF7hPVe/IcJZMiqgqHccGaenqp6Wzn8M9/QR8HoqDfoqDPoqDfsKRCA2tPexq7WFXazeNbT3sPtz7rm/2RQEfF51ewQfPmMHFp0+POxzT4xEWzShm0YxiPr1qXjqLaUxWic5UVtVRL3meFQFBRLzA94APAE3AKyKyQVXfzGzOcoOq0nksxMFOZ4esQx19dPYNEvR7Kcjzku/3Eszz0tMfoq2rn7buAdq6+znaO0DvQPj4z7GBEApuk4ngEecnok5Hq9PhGiEcdl6HIkooHKFv0Pk2PloVxQHmlxdy2ZLpzJ1WwDx385bFM4vsW7wxoxT0e1GFgXBk1H83WREQgPOBelXdBSAijwJXA6cMCO3HBvn19gN4PYLfK3g9zi5RqhBRJeI+aszziOK+VsIRJy0Udj7EBkIRBsPqNCWEIvSHwgyEnA8yESHP6yHP5yHP68HjEedYzHmD4QiD7gdgyP1AjLg9khE3X9EPUqcz04Oi9PSH6R0I0dMf5thgmII8L+VFAaYV5VFRFKAw4HPuFYl+6EboD0U4NhCmdzBM30CYnoEQHcdCdB4bpOPYID0D7x57PFzHaDwegbLCAFML/BQGfBQGvJQV5pHv9+IRYj78nX/faJu61yMxZTyRFvR7qSgOML04QEVxgPKiPPpDEbr6Qu7PICIwv7yIBRWFNuzSmBSI7onw9xvqmFWaT0VxgIoR5slkS0CoBPbFvG4CLhjugn1Hevnzh7eOS2Y8AgGfl4Dfg9/djjAaHAZCESIKeV4PAZ8bJHwed9SK4Pd43A9DQUTwiNPJKEDYDUCD4QihiPMpXZjnpTDgY/aUPPKj39K7+6lv6aa1u58Bd9iY1yN4RfB4nG0Qo9/qC/K8FPh9VE7J54xZJZTk+ygK+BhaQSzJ9zOjJMjM0iAzS4KU5PvpH4z59j8YojDgo7wowNSCPBsBY8wEd151GUtmFrPxjYO09w6O6ppsCQjxPn1O+l4rIuuAdQCz58zjyS9eyGA4crypQiTajAEeEcR9PPH8xOtomt/rwe8V/D4Pfo/z3DfC4mFjaZNLhqrzTdzrBpeUsyURjMlZZ82ZwhNfvBCA/lCYw90DtHb1c/adp74mWwJCEzAn5nUV0Dz0JFW9F7gXoKamRk+fWZye3A2Rrj1pRZymF2OMSUbA52X2lHxmT8kf9rxsWUf3FWCRiMwXkTxgDbAhw3kyxphJJStqCKoaEpG/AJ7EGXb6A1Wty3C2jDFmUsmKgACgqr8Gfp3pfBhjzGSVLU1GxhhjMswCgjHGGMACgjHGGJfoWKexZgkRaQX2jHBaOdCWhuykWy6WKxfLBLlZrlwsE+RmueKVaZ6qVsQ7ecIGhNEQkVpVrcl0PlItF8uVi2WC3CxXLpYJcrNcYy2TNRkZY4wBLCAYY4xx5XpAuDfTGRgnuViuXCwT5Ga5crFMkJvlGlOZcroPwRhjzOjleg3BGGPMKFlAMMYYA+RAQJB0rUWdRrlYJmNM9pvwAYHcKMNQOblzjYiUu485szGyiFRnOg/jQURqRGR6pvORSiJyuYiszHQ+Uk1ESmOeJ/VlcsJ+mIrI+SLyI+CfRGSFiEzYskS5f4Q/Ab4lIu/PhQ9OcRSIyCPA4wCqGs5wtpImIueKyG+Bb+TC+xQlIstE5EXg68CUTOcnFUTkHBHZCPwCOC3T+UkVEblARB4H7hORz4pIQJMcJTThPkRFxCMiXwfuAzbiLOF9M3BWRjOWBPdD8w7gHuCXwCHgL4C5Gc1YCqij131ZLiI3gfM+ZjBbCXPfq78DHgEeVdXrowEuR5r6bgF+oaofVdW3YeKWS0S8InIv8J/A/wX+H7DUPTYh//9FiciZwPeAnwI/AS4lBcFuwv2jqGoEZw2jP1HVh4HbgXk4G+tMSG5U/x3wAVV9EPgvnD2lWzOZr1RwP0Bn4QS5G4CbRGSKqkYm4h+l+175gU2qeh8c/wbqS/bbWSa5H55lOP/vvuum/aGIVAH57usJFRjcQP0EsFpVHwN+BlwiIkH3c2QiWwnUq+oPgaeAILA3ejDR92pCzEMQkYuAPlXd4r4OAgOAX1X7RWQ98ENV/e9M5nMshpYpJn018COcPaW3AL9S1acykMWExJZLRDzRPzwReQyn1vMVoAf4T1VtyGBWRy3O/79CnA+XN4CLcIJdB843659mLKNjdIq/q23Al4FP4SyMdhAYUNV1GcvoGAzzdyXAZcAnga+o6pFM5C9Rcd6r6cA+4F+AtTj70r8F7FDVOxP+RaqatT9AMfBz4AjwA6DMTZeYc/zAi8DiTOc3wTJNddM97uMy4BL3+Z/i1BaWZDrfiZbLPbYY+Df3+VVAJ7AVCOAE9YznP4Ey/THwW+BC9/XncJoxs/7/4Qjl+ltgN/AZ93Wl+/f1oUznO5EyAcKJL75VwC5gdvRYpvOd5Hu1BLgTuN59fRHw38B7Ev192V5lHwCeAT6N8435WjhebY9aChxS1bdFpFhEzk9/NsdkaJmug+NNYahqnao+6577HE7HXncG8jlWccvlagYWi8gG4Fs45dqjqv2qOpj2nI7eKcukTnPlJ1T1eTfpt0AFE/+9+j5OE1EFgKruBzYB2d7Ecqq/K1VVdWurTTi17nifI9lquP+DO3CCwj436VWgBehP9JdlXUAQketF5CK3nbkf51vXb4G3gRoRWeyeF90PugzoFZE/wfkmsyLb2jrHUKah+f4gznvUldYMj9Joy4XzLacZ59vZSlX9KDAnG4cAjuW90nc3O3wAp/09KwPCaMulqt3AXwJrReRsdxDA5Ti1hqwyhvfKo06flQ94B6fJMmuN4e8K4DfA37ufHWtwWhgOJ/y7syFIuoWZiTMKIAI0AIXALara5p6zCKetrE9V/yHm2n/CaZd+APh3Vf19enMfX6JlEpEAsBqnKrgf+Fv3m0BWGGO5+lX1m25aqap2xNznXa8zKYn3ygO8H/gOTofeVybwezX07+qTOCP3lgFfVdW6NGc/rmTeKzcofBvoVtWvZaQAp5DE31U+zgJ203EG1nxBVd9MOCNZ0EbmdR8XAz9yn/uA/wB+NuTcP8Sp0p4GFLhp7wU+melypKhMAZw+kRXARzJdjhSWKx8IuOmeTJcjRWUK4rRPLwSuynQ5UliuQtx+HbKsjT3J96owG8uURLkWxXwG+oCZqchLtNkl7dzq2zcAr4j8GigBwgCqGhKRLwDNInKRqj7npv9CRJbiDCUrEpFLVPXFDBXhJKkoE06H8nZge0YKEUeqygW8pVky3C9FZbpUnW9jWTNaKsXvVeabD8jNMkHS5drIic/At3BGgyUtI30I7hCqV4GpQD3wTWAQZ4zw+XC8w+cbwN/HXHcd8HfAs8CZ7j9EVsjFMkFuliuFZUq8aj4O7L2aGGWCLC5XhqpIq3GHtbmvvw/cBPwJ8Kqb5sFpU1sPzI+5bnUm8jwZy5Sr5crFMuVquXKxTNlcrkyNMnoVWC8n1oD5H2Cuqj6AU336S3WaFqqAsKo2AqjqC6r6QkZyPLJcLBPkZrlysUyQm+XKxTJBlpYrIwFBVXvVGYMeXeTsA5xYpuFPgaUi8kuc9WK2ZiKPY5WLZYLcLFculglys1y5WCbI3nJlrFMZji+DrMAMYIOb3AV8FVgONKozMWbCyMUyQW6WKxfLBLlZrlwsE2RfuTI9MS2CM8yyDTjTjYhfAyKqumkivsHkZpkgN8uVi2WC3CxXLpYJsq1c49U5MdofYJX7j7IJuCHT+bEyTa5y5WKZcrVcuVimbCtXxmcqi7O87mdwFj9LeA2ObJKLZYLcLFculglys1y5WCbIrnJlPCAYY4zJDpnuQzDGGJMlLCAYY4wBLCAYY4xxWUAwxhgDWEAwxhjjsoBgjDEGsIBgjDHG9f8BaPKzHvWj8RsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['first_active_month'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By this plot we can see that in the later years there is are more purchases but as the given data for year 2018 is only for 2 months are can see the line in graphs dips down close to 0 as it only has only 2 months of counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating some featurs based on date featur such as year, month, day_of_week, day_of_year, week of the year and the time (i.e., diffrence between number of days from 1st feb of 2018 columns to the date purchasing was done) and calling it elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year'] = train['first_active_month'].dt.year\n",
    "train['month'] = train['first_active_month'].dt.month\n",
    "train['dayofweek'] = train['first_active_month'].dt.dayofweek\n",
    "train['dayofyear'] = train['first_active_month'].dt.dayofyear\n",
    "train['days_in_month'] = train['first_active_month'].dt.days_in_month\n",
    "train['week'] = train['first_active_month'].dt.week \n",
    "train['elapsed_time'] = (datetime.date(2018, 2, 1) - train['first_active_month'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['days_feature1'] = train['elapsed_time'] * train['feature_1']\n",
    "train['days_feature2'] = train['elapsed_time'] * train['feature_2']\n",
    "train['days_feature3'] = train['elapsed_time'] * train['feature_3']\n",
    "\n",
    "train['days_feature1_ratio'] = train['feature_1'] / train['elapsed_time']\n",
    "train['days_feature2_ratio'] = train['feature_2'] / train['elapsed_time']\n",
    "train['days_feature3_ratio'] = train['feature_3'] / train['elapsed_time']\n",
    "\n",
    "train['feature_sum'] = train['feature_1'] + train['feature_2'] + train['feature_3']\n",
    "train['feature_mean'] = train['feature_sum']/3\n",
    "train['feature_max'] = train[['feature_1', 'feature_2', 'feature_3']].max(axis=1)\n",
    "train['feature_min'] = train[['feature_1', 'feature_2', 'feature_3']].min(axis=1)\n",
    "train['feature_var'] = train[['feature_1', 'feature_2', 'feature_3']].std(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the 5 values after adding the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>...</th>\n",
       "      <th>days_feature2</th>\n",
       "      <th>days_feature3</th>\n",
       "      <th>days_feature1_ratio</th>\n",
       "      <th>days_feature2_ratio</th>\n",
       "      <th>days_feature3_ratio</th>\n",
       "      <th>feature_sum</th>\n",
       "      <th>feature_mean</th>\n",
       "      <th>feature_max</th>\n",
       "      <th>feature_min</th>\n",
       "      <th>feature_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>490</td>\n",
       "      <td>245</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>8</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.081666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>396</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.081666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>...</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.154701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.081666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>305</td>\n",
       "      <td>...</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.527525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0         2017-06-01  C_ID_92a2005557          5          2          1   \n",
       "1         2017-01-01  C_ID_3d0044924f          4          1          0   \n",
       "2         2016-08-01  C_ID_d639edf6cd          2          2          0   \n",
       "3         2017-09-01  C_ID_186d6a6901          4          3          0   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  year  month  dayofweek  dayofyear  ...  days_feature2  \\\n",
       "0 -0.820283  2017      6          3        152  ...            490   \n",
       "1  0.392913  2017      1          6          1  ...            396   \n",
       "2  0.688056  2016      8          0        214  ...           1098   \n",
       "3  0.142495  2017      9          4        244  ...            459   \n",
       "4 -0.159749  2017     11          2        305  ...            276   \n",
       "\n",
       "   days_feature3  days_feature1_ratio  days_feature2_ratio  \\\n",
       "0            245             0.020408             0.008163   \n",
       "1              0             0.010101             0.002525   \n",
       "2              0             0.003643             0.003643   \n",
       "3              0             0.026144             0.019608   \n",
       "4              0             0.010870             0.032609   \n",
       "\n",
       "   days_feature3_ratio  feature_sum  feature_mean  feature_max  feature_min  \\\n",
       "0             0.004082            8      2.666667            5            1   \n",
       "1             0.000000            5      1.666667            4            0   \n",
       "2             0.000000            4      1.333333            2            0   \n",
       "3             0.000000            7      2.333333            4            0   \n",
       "4             0.000000            4      1.333333            3            0   \n",
       "\n",
       "   feature_var  \n",
       "0     2.081666  \n",
       "1     2.081666  \n",
       "2     1.154701  \n",
       "3     2.081666  \n",
       "4     1.527525  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again checking the corelation between the features after adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>days_in_month</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>days_feature2</th>\n",
       "      <th>days_feature3</th>\n",
       "      <th>days_feature1_ratio</th>\n",
       "      <th>days_feature2_ratio</th>\n",
       "      <th>days_feature3_ratio</th>\n",
       "      <th>feature_sum</th>\n",
       "      <th>feature_mean</th>\n",
       "      <th>feature_max</th>\n",
       "      <th>feature_min</th>\n",
       "      <th>feature_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>feature_1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.130969</td>\n",
       "      <td>0.583092</td>\n",
       "      <td>-0.014251</td>\n",
       "      <td>-0.115267</td>\n",
       "      <td>-0.012128</td>\n",
       "      <td>-0.012269</td>\n",
       "      <td>-0.011660</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009194</td>\n",
       "      <td>0.373576</td>\n",
       "      <td>0.328158</td>\n",
       "      <td>-0.118900</td>\n",
       "      <td>0.319565</td>\n",
       "      <td>0.835593</td>\n",
       "      <td>0.835593</td>\n",
       "      <td>0.965617</td>\n",
       "      <td>0.583092</td>\n",
       "      <td>0.863129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feature_2</td>\n",
       "      <td>-0.130969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060925</td>\n",
       "      <td>-0.006242</td>\n",
       "      <td>-0.151782</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>-0.011680</td>\n",
       "      <td>-0.026699</td>\n",
       "      <td>-0.011156</td>\n",
       "      <td>-0.015200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532591</td>\n",
       "      <td>0.138137</td>\n",
       "      <td>-0.124810</td>\n",
       "      <td>0.374337</td>\n",
       "      <td>-0.053619</td>\n",
       "      <td>0.380058</td>\n",
       "      <td>0.380058</td>\n",
       "      <td>-0.044213</td>\n",
       "      <td>0.060925</td>\n",
       "      <td>-0.111160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feature_3</td>\n",
       "      <td>0.583092</td>\n",
       "      <td>0.060925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008125</td>\n",
       "      <td>-0.194084</td>\n",
       "      <td>-0.016784</td>\n",
       "      <td>-0.008997</td>\n",
       "      <td>-0.016465</td>\n",
       "      <td>-0.004336</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175726</td>\n",
       "      <td>0.646479</td>\n",
       "      <td>0.151162</td>\n",
       "      <td>-0.084734</td>\n",
       "      <td>0.602655</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>0.541164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>target</td>\n",
       "      <td>-0.014251</td>\n",
       "      <td>-0.006242</td>\n",
       "      <td>-0.008125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040341</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.031365</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039569</td>\n",
       "      <td>-0.036119</td>\n",
       "      <td>0.043513</td>\n",
       "      <td>0.043449</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>-0.015550</td>\n",
       "      <td>-0.015550</td>\n",
       "      <td>-0.015067</td>\n",
       "      <td>-0.008125</td>\n",
       "      <td>-0.015111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>year</td>\n",
       "      <td>-0.115267</td>\n",
       "      <td>-0.151782</td>\n",
       "      <td>-0.194084</td>\n",
       "      <td>0.040341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.119644</td>\n",
       "      <td>0.124323</td>\n",
       "      <td>-0.120962</td>\n",
       "      <td>-0.046169</td>\n",
       "      <td>-0.044076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.799964</td>\n",
       "      <td>-0.756547</td>\n",
       "      <td>0.439563</td>\n",
       "      <td>0.416985</td>\n",
       "      <td>0.257009</td>\n",
       "      <td>-0.210583</td>\n",
       "      <td>-0.210583</td>\n",
       "      <td>-0.095292</td>\n",
       "      <td>-0.194084</td>\n",
       "      <td>-0.065148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>month</td>\n",
       "      <td>-0.012128</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>-0.016784</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>-0.119644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038125</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.227296</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168041</td>\n",
       "      <td>-0.121517</td>\n",
       "      <td>0.419520</td>\n",
       "      <td>0.396403</td>\n",
       "      <td>0.265066</td>\n",
       "      <td>-0.026170</td>\n",
       "      <td>-0.026170</td>\n",
       "      <td>-0.002472</td>\n",
       "      <td>-0.016784</td>\n",
       "      <td>0.007714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dayofweek</td>\n",
       "      <td>-0.012269</td>\n",
       "      <td>-0.011680</td>\n",
       "      <td>-0.008997</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.124323</td>\n",
       "      <td>-0.038125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038354</td>\n",
       "      <td>0.161987</td>\n",
       "      <td>0.220884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079902</td>\n",
       "      <td>-0.066867</td>\n",
       "      <td>0.119236</td>\n",
       "      <td>0.109999</td>\n",
       "      <td>0.079489</td>\n",
       "      <td>-0.016865</td>\n",
       "      <td>-0.016865</td>\n",
       "      <td>-0.006147</td>\n",
       "      <td>-0.008997</td>\n",
       "      <td>-0.009919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dayofyear</td>\n",
       "      <td>-0.011660</td>\n",
       "      <td>-0.026699</td>\n",
       "      <td>-0.016465</td>\n",
       "      <td>0.031365</td>\n",
       "      <td>-0.120962</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>-0.038354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223736</td>\n",
       "      <td>0.649136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167018</td>\n",
       "      <td>-0.120877</td>\n",
       "      <td>0.418330</td>\n",
       "      <td>0.395287</td>\n",
       "      <td>0.264379</td>\n",
       "      <td>-0.025522</td>\n",
       "      <td>-0.025522</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>-0.016465</td>\n",
       "      <td>0.008168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>days_in_month</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>-0.011156</td>\n",
       "      <td>-0.004336</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>-0.046169</td>\n",
       "      <td>0.227296</td>\n",
       "      <td>0.161987</td>\n",
       "      <td>0.223736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.376717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025086</td>\n",
       "      <td>-0.016756</td>\n",
       "      <td>0.077621</td>\n",
       "      <td>0.068263</td>\n",
       "      <td>0.048736</td>\n",
       "      <td>-0.004478</td>\n",
       "      <td>-0.004478</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>-0.004336</td>\n",
       "      <td>0.005961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>week</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>-0.015200</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>-0.044076</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.220884</td>\n",
       "      <td>0.649136</td>\n",
       "      <td>0.376717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139066</td>\n",
       "      <td>-0.097237</td>\n",
       "      <td>0.336864</td>\n",
       "      <td>0.313798</td>\n",
       "      <td>0.217504</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.038007</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>0.040984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>elapsed_time</td>\n",
       "      <td>0.117144</td>\n",
       "      <td>0.158150</td>\n",
       "      <td>0.196046</td>\n",
       "      <td>-0.050453</td>\n",
       "      <td>-0.938988</td>\n",
       "      <td>-0.229130</td>\n",
       "      <td>-0.108738</td>\n",
       "      <td>-0.227843</td>\n",
       "      <td>-0.032218</td>\n",
       "      <td>-0.181678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842504</td>\n",
       "      <td>0.783841</td>\n",
       "      <td>-0.576334</td>\n",
       "      <td>-0.546192</td>\n",
       "      <td>-0.343844</td>\n",
       "      <td>0.215429</td>\n",
       "      <td>0.215429</td>\n",
       "      <td>0.094193</td>\n",
       "      <td>0.196046</td>\n",
       "      <td>0.061133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>days_feature1</td>\n",
       "      <td>0.484119</td>\n",
       "      <td>0.034493</td>\n",
       "      <td>0.382136</td>\n",
       "      <td>-0.049600</td>\n",
       "      <td>-0.839733</td>\n",
       "      <td>-0.179893</td>\n",
       "      <td>-0.096862</td>\n",
       "      <td>-0.178714</td>\n",
       "      <td>-0.022041</td>\n",
       "      <td>-0.130112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656295</td>\n",
       "      <td>0.845210</td>\n",
       "      <td>-0.410398</td>\n",
       "      <td>-0.495246</td>\n",
       "      <td>-0.217226</td>\n",
       "      <td>0.479208</td>\n",
       "      <td>0.479208</td>\n",
       "      <td>0.459307</td>\n",
       "      <td>0.382136</td>\n",
       "      <td>0.398920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>days_feature2</td>\n",
       "      <td>-0.009194</td>\n",
       "      <td>0.532591</td>\n",
       "      <td>0.175726</td>\n",
       "      <td>-0.039569</td>\n",
       "      <td>-0.799964</td>\n",
       "      <td>-0.168041</td>\n",
       "      <td>-0.079902</td>\n",
       "      <td>-0.167018</td>\n",
       "      <td>-0.025086</td>\n",
       "      <td>-0.139066</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680886</td>\n",
       "      <td>-0.461877</td>\n",
       "      <td>-0.325371</td>\n",
       "      <td>-0.261725</td>\n",
       "      <td>0.289116</td>\n",
       "      <td>0.289116</td>\n",
       "      <td>-0.011265</td>\n",
       "      <td>0.175726</td>\n",
       "      <td>-0.074815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>days_feature3</td>\n",
       "      <td>0.373576</td>\n",
       "      <td>0.138137</td>\n",
       "      <td>0.646479</td>\n",
       "      <td>-0.036119</td>\n",
       "      <td>-0.756547</td>\n",
       "      <td>-0.121517</td>\n",
       "      <td>-0.066867</td>\n",
       "      <td>-0.120877</td>\n",
       "      <td>-0.016756</td>\n",
       "      <td>-0.097237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.300965</td>\n",
       "      <td>-0.352897</td>\n",
       "      <td>-0.019629</td>\n",
       "      <td>0.526416</td>\n",
       "      <td>0.526416</td>\n",
       "      <td>0.346274</td>\n",
       "      <td>0.646479</td>\n",
       "      <td>0.139127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>days_feature1_ratio</td>\n",
       "      <td>0.328158</td>\n",
       "      <td>-0.124810</td>\n",
       "      <td>0.151162</td>\n",
       "      <td>0.043513</td>\n",
       "      <td>0.439563</td>\n",
       "      <td>0.419520</td>\n",
       "      <td>0.119236</td>\n",
       "      <td>0.418330</td>\n",
       "      <td>0.077621</td>\n",
       "      <td>0.336864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.461877</td>\n",
       "      <td>-0.300965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.652169</td>\n",
       "      <td>0.703170</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.323997</td>\n",
       "      <td>0.151162</td>\n",
       "      <td>0.294888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>days_feature2_ratio</td>\n",
       "      <td>-0.118900</td>\n",
       "      <td>0.374337</td>\n",
       "      <td>-0.084734</td>\n",
       "      <td>0.043449</td>\n",
       "      <td>0.416985</td>\n",
       "      <td>0.396403</td>\n",
       "      <td>0.109999</td>\n",
       "      <td>0.395287</td>\n",
       "      <td>0.068263</td>\n",
       "      <td>0.313798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325371</td>\n",
       "      <td>-0.352897</td>\n",
       "      <td>0.652169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397467</td>\n",
       "      <td>0.059617</td>\n",
       "      <td>0.059617</td>\n",
       "      <td>-0.042674</td>\n",
       "      <td>-0.084734</td>\n",
       "      <td>-0.044103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>days_feature3_ratio</td>\n",
       "      <td>0.319565</td>\n",
       "      <td>-0.053619</td>\n",
       "      <td>0.602655</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>0.257009</td>\n",
       "      <td>0.265066</td>\n",
       "      <td>0.079489</td>\n",
       "      <td>0.264379</td>\n",
       "      <td>0.048736</td>\n",
       "      <td>0.217504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261725</td>\n",
       "      <td>-0.019629</td>\n",
       "      <td>0.703170</td>\n",
       "      <td>0.397467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.386905</td>\n",
       "      <td>0.386905</td>\n",
       "      <td>0.292444</td>\n",
       "      <td>0.602655</td>\n",
       "      <td>0.066735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feature_sum</td>\n",
       "      <td>0.835593</td>\n",
       "      <td>0.380058</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>-0.015550</td>\n",
       "      <td>-0.210583</td>\n",
       "      <td>-0.026170</td>\n",
       "      <td>-0.016865</td>\n",
       "      <td>-0.025522</td>\n",
       "      <td>-0.004478</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289116</td>\n",
       "      <td>0.526416</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.059617</td>\n",
       "      <td>0.386905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837789</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>0.626401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feature_mean</td>\n",
       "      <td>0.835593</td>\n",
       "      <td>0.380058</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>-0.015550</td>\n",
       "      <td>-0.210583</td>\n",
       "      <td>-0.026170</td>\n",
       "      <td>-0.016865</td>\n",
       "      <td>-0.025522</td>\n",
       "      <td>-0.004478</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289116</td>\n",
       "      <td>0.526416</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.059617</td>\n",
       "      <td>0.386905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837789</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>0.626401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feature_max</td>\n",
       "      <td>0.965617</td>\n",
       "      <td>-0.044213</td>\n",
       "      <td>0.541164</td>\n",
       "      <td>-0.015067</td>\n",
       "      <td>-0.095292</td>\n",
       "      <td>-0.002472</td>\n",
       "      <td>-0.006147</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.038007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011265</td>\n",
       "      <td>0.346274</td>\n",
       "      <td>0.323997</td>\n",
       "      <td>-0.042674</td>\n",
       "      <td>0.292444</td>\n",
       "      <td>0.837789</td>\n",
       "      <td>0.837789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.541164</td>\n",
       "      <td>0.914890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feature_min</td>\n",
       "      <td>0.583092</td>\n",
       "      <td>0.060925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008125</td>\n",
       "      <td>-0.194084</td>\n",
       "      <td>-0.016784</td>\n",
       "      <td>-0.008997</td>\n",
       "      <td>-0.016465</td>\n",
       "      <td>-0.004336</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175726</td>\n",
       "      <td>0.646479</td>\n",
       "      <td>0.151162</td>\n",
       "      <td>-0.084734</td>\n",
       "      <td>0.602655</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>0.541164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feature_var</td>\n",
       "      <td>0.863129</td>\n",
       "      <td>-0.111160</td>\n",
       "      <td>0.185234</td>\n",
       "      <td>-0.015111</td>\n",
       "      <td>-0.065148</td>\n",
       "      <td>0.007714</td>\n",
       "      <td>-0.009919</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074815</td>\n",
       "      <td>0.139127</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>-0.044103</td>\n",
       "      <td>0.066735</td>\n",
       "      <td>0.626401</td>\n",
       "      <td>0.626401</td>\n",
       "      <td>0.914890</td>\n",
       "      <td>0.185234</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature_1  feature_2  feature_3    target      year  \\\n",
       "feature_1             1.000000  -0.130969   0.583092 -0.014251 -0.115267   \n",
       "feature_2            -0.130969   1.000000   0.060925 -0.006242 -0.151782   \n",
       "feature_3             0.583092   0.060925   1.000000 -0.008125 -0.194084   \n",
       "target               -0.014251  -0.006242  -0.008125  1.000000  0.040341   \n",
       "year                 -0.115267  -0.151782  -0.194084  0.040341  1.000000   \n",
       "month                -0.012128  -0.027170  -0.016784  0.031512 -0.119644   \n",
       "dayofweek            -0.012269  -0.011680  -0.008997  0.007254  0.124323   \n",
       "dayofyear            -0.011660  -0.026699  -0.016465  0.031365 -0.120962   \n",
       "days_in_month         0.002659  -0.011156  -0.004336  0.006889 -0.046169   \n",
       "week                  0.023545  -0.015200   0.005486  0.017922 -0.044076   \n",
       "elapsed_time          0.117144   0.158150   0.196046 -0.050453 -0.938988   \n",
       "days_feature1         0.484119   0.034493   0.382136 -0.049600 -0.839733   \n",
       "days_feature2        -0.009194   0.532591   0.175726 -0.039569 -0.799964   \n",
       "days_feature3         0.373576   0.138137   0.646479 -0.036119 -0.756547   \n",
       "days_feature1_ratio   0.328158  -0.124810   0.151162  0.043513  0.439563   \n",
       "days_feature2_ratio  -0.118900   0.374337  -0.084734  0.043449  0.416985   \n",
       "days_feature3_ratio   0.319565  -0.053619   0.602655  0.027539  0.257009   \n",
       "feature_sum           0.835593   0.380058   0.748389 -0.015550 -0.210583   \n",
       "feature_mean          0.835593   0.380058   0.748389 -0.015550 -0.210583   \n",
       "feature_max           0.965617  -0.044213   0.541164 -0.015067 -0.095292   \n",
       "feature_min           0.583092   0.060925   1.000000 -0.008125 -0.194084   \n",
       "feature_var           0.863129  -0.111160   0.185234 -0.015111 -0.065148   \n",
       "\n",
       "                        month  dayofweek  dayofyear  days_in_month      week  \\\n",
       "feature_1           -0.012128  -0.012269  -0.011660       0.002659  0.023545   \n",
       "feature_2           -0.027170  -0.011680  -0.026699      -0.011156 -0.015200   \n",
       "feature_3           -0.016784  -0.008997  -0.016465      -0.004336  0.005486   \n",
       "target               0.031512   0.007254   0.031365       0.006889  0.017922   \n",
       "year                -0.119644   0.124323  -0.120962      -0.046169 -0.044076   \n",
       "month                1.000000  -0.038125   0.999976       0.227296  0.647312   \n",
       "dayofweek           -0.038125   1.000000  -0.038354       0.161987  0.220884   \n",
       "dayofyear            0.999976  -0.038354   1.000000       0.223736  0.649136   \n",
       "days_in_month        0.227296   0.161987   0.223736       1.000000  0.376717   \n",
       "week                 0.647312   0.220884   0.649136       0.376717  1.000000   \n",
       "elapsed_time        -0.229130  -0.108738  -0.227843      -0.032218 -0.181678   \n",
       "days_feature1       -0.179893  -0.096862  -0.178714      -0.022041 -0.130112   \n",
       "days_feature2       -0.168041  -0.079902  -0.167018      -0.025086 -0.139066   \n",
       "days_feature3       -0.121517  -0.066867  -0.120877      -0.016756 -0.097237   \n",
       "days_feature1_ratio  0.419520   0.119236   0.418330       0.077621  0.336864   \n",
       "days_feature2_ratio  0.396403   0.109999   0.395287       0.068263  0.313798   \n",
       "days_feature3_ratio  0.265066   0.079489   0.264379       0.048736  0.217504   \n",
       "feature_sum         -0.026170  -0.016865  -0.025522      -0.004478  0.011669   \n",
       "feature_mean        -0.026170  -0.016865  -0.025522      -0.004478  0.011669   \n",
       "feature_max         -0.002472  -0.006147  -0.001984       0.000752  0.038007   \n",
       "feature_min         -0.016784  -0.008997  -0.016465      -0.004336  0.005486   \n",
       "feature_var          0.007714  -0.009919   0.008168       0.005961  0.040984   \n",
       "\n",
       "                     ...  days_feature2  days_feature3  days_feature1_ratio  \\\n",
       "feature_1            ...      -0.009194       0.373576             0.328158   \n",
       "feature_2            ...       0.532591       0.138137            -0.124810   \n",
       "feature_3            ...       0.175726       0.646479             0.151162   \n",
       "target               ...      -0.039569      -0.036119             0.043513   \n",
       "year                 ...      -0.799964      -0.756547             0.439563   \n",
       "month                ...      -0.168041      -0.121517             0.419520   \n",
       "dayofweek            ...      -0.079902      -0.066867             0.119236   \n",
       "dayofyear            ...      -0.167018      -0.120877             0.418330   \n",
       "days_in_month        ...      -0.025086      -0.016756             0.077621   \n",
       "week                 ...      -0.139066      -0.097237             0.336864   \n",
       "elapsed_time         ...       0.842504       0.783841            -0.576334   \n",
       "days_feature1        ...       0.656295       0.845210            -0.410398   \n",
       "days_feature2        ...       1.000000       0.680886            -0.461877   \n",
       "days_feature3        ...       0.680886       1.000000            -0.300965   \n",
       "days_feature1_ratio  ...      -0.461877      -0.300965             1.000000   \n",
       "days_feature2_ratio  ...      -0.325371      -0.352897             0.652169   \n",
       "days_feature3_ratio  ...      -0.261725      -0.019629             0.703170   \n",
       "feature_sum          ...       0.289116       0.526416             0.224800   \n",
       "feature_mean         ...       0.289116       0.526416             0.224800   \n",
       "feature_max          ...      -0.011265       0.346274             0.323997   \n",
       "feature_min          ...       0.175726       0.646479             0.151162   \n",
       "feature_var          ...      -0.074815       0.139127             0.294888   \n",
       "\n",
       "                     days_feature2_ratio  days_feature3_ratio  feature_sum  \\\n",
       "feature_1                      -0.118900             0.319565     0.835593   \n",
       "feature_2                       0.374337            -0.053619     0.380058   \n",
       "feature_3                      -0.084734             0.602655     0.748389   \n",
       "target                          0.043449             0.027539    -0.015550   \n",
       "year                            0.416985             0.257009    -0.210583   \n",
       "month                           0.396403             0.265066    -0.026170   \n",
       "dayofweek                       0.109999             0.079489    -0.016865   \n",
       "dayofyear                       0.395287             0.264379    -0.025522   \n",
       "days_in_month                   0.068263             0.048736    -0.004478   \n",
       "week                            0.313798             0.217504     0.011669   \n",
       "elapsed_time                   -0.546192            -0.343844     0.215429   \n",
       "days_feature1                  -0.495246            -0.217226     0.479208   \n",
       "days_feature2                  -0.325371            -0.261725     0.289116   \n",
       "days_feature3                  -0.352897            -0.019629     0.526416   \n",
       "days_feature1_ratio             0.652169             0.703170     0.224800   \n",
       "days_feature2_ratio             1.000000             0.397467     0.059617   \n",
       "days_feature3_ratio             0.397467             1.000000     0.386905   \n",
       "feature_sum                     0.059617             0.386905     1.000000   \n",
       "feature_mean                    0.059617             0.386905     1.000000   \n",
       "feature_max                    -0.042674             0.292444     0.837789   \n",
       "feature_min                    -0.084734             0.602655     0.748389   \n",
       "feature_var                    -0.044103             0.066735     0.626401   \n",
       "\n",
       "                     feature_mean  feature_max  feature_min  feature_var  \n",
       "feature_1                0.835593     0.965617     0.583092     0.863129  \n",
       "feature_2                0.380058    -0.044213     0.060925    -0.111160  \n",
       "feature_3                0.748389     0.541164     1.000000     0.185234  \n",
       "target                  -0.015550    -0.015067    -0.008125    -0.015111  \n",
       "year                    -0.210583    -0.095292    -0.194084    -0.065148  \n",
       "month                   -0.026170    -0.002472    -0.016784     0.007714  \n",
       "dayofweek               -0.016865    -0.006147    -0.008997    -0.009919  \n",
       "dayofyear               -0.025522    -0.001984    -0.016465     0.008168  \n",
       "days_in_month           -0.004478     0.000752    -0.004336     0.005961  \n",
       "week                     0.011669     0.038007     0.005486     0.040984  \n",
       "elapsed_time             0.215429     0.094193     0.196046     0.061133  \n",
       "days_feature1            0.479208     0.459307     0.382136     0.398920  \n",
       "days_feature2            0.289116    -0.011265     0.175726    -0.074815  \n",
       "days_feature3            0.526416     0.346274     0.646479     0.139127  \n",
       "days_feature1_ratio      0.224800     0.323997     0.151162     0.294888  \n",
       "days_feature2_ratio      0.059617    -0.042674    -0.084734    -0.044103  \n",
       "days_feature3_ratio      0.386905     0.292444     0.602655     0.066735  \n",
       "feature_sum              1.000000     0.837789     0.748389     0.626401  \n",
       "feature_mean             1.000000     0.837789     0.748389     0.626401  \n",
       "feature_max              0.837789     1.000000     0.541164     0.914890  \n",
       "feature_min              0.748389     0.541164     1.000000     0.185234  \n",
       "feature_var              0.626401     0.914890     0.185234     1.000000  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the dates related features are highly corelated to each other and mainly the feature elapsed_time and year are showing good corelation with our target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 24)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing shape of train file after adding the features\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the Test file here we can see that it is same as the train file but does not include our target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123623, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-08</td>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2015-12</td>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3\n",
       "0            2017-04  C_ID_0ab67a22ab          3          3          1\n",
       "1            2017-01  C_ID_130fd0cbdd          2          3          0\n",
       "2            2017-08  C_ID_b709037bc5          5          1          1\n",
       "3            2017-12  C_ID_d27d835a9f          2          1          0\n",
       "4            2015-12  C_ID_2b5e3df5c2          5          1          1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw we have same features in test as of train so we are applying same feature engineering which we have applied for train dataset and creating same features for test as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['first_active_month'] = pd.to_datetime(test['first_active_month'])\n",
    "test['year'] = test['first_active_month'].dt.year\n",
    "test['month'] = test['first_active_month'].dt.month\n",
    "test['dayofweek']= test['first_active_month'].dt.dayofweek\n",
    "test['dayofyear']= test['first_active_month'].dt.dayofyear\n",
    "test['days_in_month']= test['first_active_month'].dt.days_in_month\n",
    "test['week']= test['first_active_month'].dt.week \n",
    "test['elapsed_time'] = (datetime.date(2018, 2, 1) - test['first_active_month'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['days_feature1'] = test['elapsed_time'] * test['feature_1']\n",
    "test['days_feature2'] = test['elapsed_time'] * test['feature_2']\n",
    "test['days_feature3'] = test['elapsed_time'] * test['feature_3']\n",
    "\n",
    "test['days_feature1_ratio'] = test['feature_1'] / test['elapsed_time']\n",
    "test['days_feature2_ratio'] = test['feature_2'] / test['elapsed_time']\n",
    "test['days_feature3_ratio'] = test['feature_3'] / test['elapsed_time']\n",
    "\n",
    "test['feature_sum'] = test['feature_1'] + test['feature_2'] + test['feature_3']\n",
    "test['feature_mean'] = test['feature_sum']/3\n",
    "test['feature_max'] = test[['feature_1', 'feature_2', 'feature_3']].max(axis=1)\n",
    "test['feature_min'] = test[['feature_1', 'feature_2', 'feature_3']].min(axis=1)\n",
    "test['feature_var'] = test[['feature_1', 'feature_2', 'feature_3']].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 23)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the 3rd file which is new_merchant_transactions and printing the shape and first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1963031, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_415bb3a509</td>\n",
       "      <td>107</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>307</td>\n",
       "      <td>M_ID_b0c793002c</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.557574</td>\n",
       "      <td>2018-03-11 14:57:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_415bb3a509</td>\n",
       "      <td>140</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>307</td>\n",
       "      <td>M_ID_88920c89e8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.569580</td>\n",
       "      <td>2018-03-19 18:53:37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_415bb3a509</td>\n",
       "      <td>330</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>507</td>\n",
       "      <td>M_ID_ad5237ef6b</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.551037</td>\n",
       "      <td>2018-04-26 14:08:44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_415bb3a509</td>\n",
       "      <td>-1</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>661</td>\n",
       "      <td>M_ID_9e84cda3b1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.671925</td>\n",
       "      <td>2018-03-07 09:43:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_ef55cf8d4b</td>\n",
       "      <td>-1</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>166</td>\n",
       "      <td>M_ID_3c86fa3831</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.659904</td>\n",
       "      <td>2018-03-22 21:07:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  authorized_flag          card_id  city_id category_1  installments  \\\n",
       "0               Y  C_ID_415bb3a509      107          N             1   \n",
       "1               Y  C_ID_415bb3a509      140          N             1   \n",
       "2               Y  C_ID_415bb3a509      330          N             1   \n",
       "3               Y  C_ID_415bb3a509       -1          Y             1   \n",
       "4               Y  C_ID_ef55cf8d4b       -1          Y             1   \n",
       "\n",
       "  category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0          B                   307  M_ID_b0c793002c          1   \n",
       "1          B                   307  M_ID_88920c89e8          1   \n",
       "2          B                   507  M_ID_ad5237ef6b          2   \n",
       "3          B                   661  M_ID_9e84cda3b1          1   \n",
       "4          B                   166  M_ID_3c86fa3831          1   \n",
       "\n",
       "   purchase_amount        purchase_date  category_2  state_id  subsector_id  \n",
       "0        -0.557574  2018-03-11 14:57:36         1.0         9            19  \n",
       "1        -0.569580  2018-03-19 18:53:37         1.0         9            19  \n",
       "2        -0.551037  2018-04-26 14:08:44         1.0         9            14  \n",
       "3        -0.671925  2018-03-07 09:43:21         NaN        -1             8  \n",
       "4        -0.659904  2018-03-22 21:07:53         NaN        -1            29  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transactions = pd.read_csv('new_merchant_transactions.csv')\n",
    "print(new_transactions.shape)\n",
    "new_transactions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we noticed is that this files contains more than 1 transaction record for a single card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of columns provided for new_merchant_transactions.csv file - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "card_id - Card identifier \n",
    "\n",
    "month_lag -\tmonth lag to reference date\n",
    "\n",
    "purchase_date -\tPurchase date\n",
    "\n",
    "authorized_flag - 'Y' if approved, 'N' if denied\n",
    "\n",
    "category_3 - anonymized category\n",
    "\n",
    "installments - number of installments of purchase\n",
    "\n",
    "category_1 - anonymized category\n",
    "\n",
    "merchant_category_id - Merchant category identifier (anonymized )\n",
    "\n",
    "subsector_id - Merchant category group identifier (anonymized )\n",
    "\n",
    "merchant_id - Merchant identifier (anonymized)\n",
    "\n",
    "purchase_amount - Normalized purchase amount\n",
    "\n",
    "city_id\tCity - identifier (anonymized )\n",
    "\n",
    "state_id - State identifier (anonymized )\n",
    "\n",
    "category_2 - anonymized category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag               1\n",
       "card_id                  290001\n",
       "city_id                     308\n",
       "category_1                    2\n",
       "installments                 15\n",
       "category_3                    3\n",
       "merchant_category_id        314\n",
       "merchant_id              226129\n",
       "month_lag                     2\n",
       "purchase_amount           75190\n",
       "purchase_date           1667025\n",
       "category_2                    5\n",
       "state_id                     25\n",
       "subsector_id                 41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how many unique values a column contains\n",
    "new_transactions.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id                  object\n",
       "city_id                   int64\n",
       "category_1                int64\n",
       "installments              int64\n",
       "category_3              float64\n",
       "merchant_category_id      int64\n",
       "merchant_id              object\n",
       "month_lag                 int64\n",
       "purchase_amount         float64\n",
       "purchase_date            object\n",
       "category_2              float64\n",
       "state_id                  int64\n",
       "subsector_id              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prinitng the data types of features\n",
    "new_transactions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag              0\n",
       "card_id                      0\n",
       "city_id                      0\n",
       "category_1                   0\n",
       "installments                 0\n",
       "category_3               55922\n",
       "merchant_category_id         0\n",
       "merchant_id              26216\n",
       "month_lag                    0\n",
       "purchase_amount              0\n",
       "purchase_date                0\n",
       "category_2              111745\n",
       "state_id                     0\n",
       "subsector_id                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if we have any null values in new_merchant_transactions file\n",
    "new_transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we saw that we have 3 columns which contain nan or null values now we will look those columns and will fill the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we saw in unique colums the authorized_flag column only contains Y values or all are authorized which will not help us in predicting\n",
    "# anything as all the value are same.\n",
    "\n",
    "new_transactions.drop(columns='authorized_flag',inplace=True)\n",
    "\n",
    "# Changing the value of categorical features to numerical\n",
    "new_transactions['category_1'] = new_transactions['category_1'].map({'N':0, 'Y':1})\n",
    "new_transactions['category_3'] = new_transactions['category_3'].map({'A':0, 'B':1, 'C':2}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a machine learning model to fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat3 = new_transactions[~new_transactions['category_3'].isnull()].drop(columns=['category_2','merchant_id','card_id','purchase_date'])\n",
    "test_cat3 = new_transactions[new_transactions['category_3'].isnull()].drop(columns=['category_2','merchant_id','card_id','purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_cat3['category_3'].values\n",
    "X = train_cat3.drop(columns='category_3').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=0,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='(0,0,0,0,0,0,0,0)', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='gpu_hist', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(gpu_id=0,tree_method = 'gpu_hist')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "result = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cat3 = clf.predict(test_cat3.drop(columns='category_3').values)\n",
    "print(predicted_cat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions['category_3'].fillna(0.0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Machine Learning model for category_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat2 = new_transactions[~new_transactions['category_2'].isnull()].drop(columns=['merchant_id','card_id','purchase_date'])\n",
    "test_cat2 = new_transactions[new_transactions['category_2'].isnull()].drop(columns=['merchant_id','card_id','purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_cat2['category_2'].values\n",
    "X = train_cat2.drop(columns='category_2').values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=0,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='(0,0,0,0,0,0,0,0,0)', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='gpu_hist', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(gpu_id=0,tree_method = 'gpu_hist')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "result = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. ... 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "predicted_cat2 = clf.predict(test_cat2.drop(columns='category_2').values)\n",
    "print((predicted_cat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique items in the list are: 1\n"
     ]
    }
   ],
   "source": [
    "new_set = set(predicted_cat2) \n",
    "print(\"No of unique items in the list are:\", len(new_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions['category_2'].fillna(3.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id                 0\n",
       "city_id                 0\n",
       "category_1              0\n",
       "installments            0\n",
       "category_3              0\n",
       "merchant_category_id    0\n",
       "merchant_id             0\n",
       "month_lag               0\n",
       "purchase_amount         0\n",
       "purchase_date           0\n",
       "category_2              0\n",
       "state_id                0\n",
       "subsector_id            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M_ID_00a6ca8a8a    23018\n",
       "M_ID_cd2c0b07e9    19118\n",
       "M_ID_9139332ccc    14220\n",
       "M_ID_50f575c681    13778\n",
       "M_ID_725a60d404     7029\n",
       "                   ...  \n",
       "M_ID_15ec4e206d        1\n",
       "M_ID_d6771e8fbf        1\n",
       "M_ID_1e422cabdd        1\n",
       "M_ID_291685d4d7        1\n",
       "M_ID_555f7b11bb        1\n",
       "Name: merchant_id, Length: 226129, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transactions.merchant_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merchant_id are unique for every merchant so filling most occured values as we will later on merge this with merchant file with merchant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the histogram for the features present in new_merchant_transactions files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:307: MatplotlibDeprecationWarning: \n",
      "The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead.\n",
      "  layout[ax.rowNum, ax.colNum] = ax.get_visible()\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:307: MatplotlibDeprecationWarning: \n",
      "The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead.\n",
      "  layout[ax.rowNum, ax.colNum] = ax.get_visible()\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:313: MatplotlibDeprecationWarning: \n",
      "The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead.\n",
      "  if not layout[ax.rowNum + 1, ax.colNum]:\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:313: MatplotlibDeprecationWarning: \n",
      "The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead.\n",
      "  if not layout[ax.rowNum + 1, ax.colNum]:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001DAECDA2488>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DA8DD6F608>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DAECFC3148>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001DA8DD25608>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DAA18F1A08>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DAA19AC9C8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001DAA2063608>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DAA20990C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DAA20991C8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001DAA2397E48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DA8DDA01C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DAA1903448>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_transactions.hist(bins=30, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see the distribution of values of categorical features which occurs maximum time and we can see that for category_1 we have 2 values and the value 1 occures for maximum times, for category_2 we have 5 values and the value 1 occures for maximum times, for category_3 we have 3 values and the value 0 occures for maximum times, for the feature month_lag we gave 2 values and value 1 occurs maximum times.\n",
    "For the features installments and purchase_amount we can see that both have small value which are near 0. We will look into those features to see in what range their values lie\n",
    "Rest of the features are id types which uniqiely identify the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the installments feature we can see that 75% points have value around 1 but we have some outliners value which are close to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.963031e+06\n",
       "mean     7.389226e-01\n",
       "std      1.188660e+00\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      1.000000e+00\n",
       "75%      1.000000e+00\n",
       "max      1.200000e+01\n",
       "Name: installments, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transactions.installments.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = new_transactions.installments.median()\n",
    "new_transactions['installments'].replace(-1, val,inplace=True)\n",
    "new_transactions['installments'].replace(999, val,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purchase amount feature we can see that 75% points have value which are negative and some outliners value which have values which are positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.963031e+06\n",
       "mean    -5.834388e-01\n",
       "std      2.695303e-01\n",
       "min     -7.468928e-01\n",
       "25%     -7.166294e-01\n",
       "50%     -6.748406e-01\n",
       "75%     -5.816162e-01\n",
       "max      8.000000e-01\n",
       "Name: purchase_amount, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transactions.purchase_amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions['purchase_amount'] = new_transactions['purchase_amount'].apply(lambda x: min(x, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating more features which depends on date\n",
    "new_transactions['purchase_date'] = pd.to_datetime(new_transactions['purchase_date'])\n",
    "new_transactions['month_diff'] = ((datetime.datetime.today() - new_transactions['purchase_date']).dt.days)//30\n",
    "new_transactions['month_diff'] += new_transactions['month_lag']\n",
    "\n",
    "new_transactions['n_duration'] = new_transactions['purchase_amount']*new_transactions['month_diff']\n",
    "new_transactions['n_amount_month_ratio'] = new_transactions['purchase_amount']/new_transactions['month_diff']\n",
    "new_transactions['n_price'] = new_transactions['purchase_amount'] / new_transactions['installments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(new_transactions.category_3, prefix='category_3')\n",
    "new_transactions['category_3_0.0'] = y['category_3_0.0']\n",
    "new_transactions['category_3_1.0'] = y['category_3_1.0']\n",
    "new_transactions['category_3_2.0'] = y['category_3_2.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(new_transactions.category_2, prefix='category_2')\n",
    "new_transactions['category_2_1.0'] = y['category_2_1.0']\n",
    "new_transactions['category_2_2.0'] = y['category_2_2.0']\n",
    "new_transactions['category_2_3.0'] = y['category_2_3.0']\n",
    "new_transactions['category_2_4.0'] = y['category_2_4.0']\n",
    "new_transactions['category_2_5.0'] = y['category_2_5.0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions.drop(columns=['category_2','category_3'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Christmas : December 25 2017\n",
    "new_transactions['Christmas_Day_2017'] = (pd.to_datetime('2017-12-25')-new_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "# Mothers Day: May 14 2017\n",
    "new_transactions['Mothers_Day_2017'] = (pd.to_datetime('2017-06-04')-new_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "# fathers day: August 13 2017\n",
    "new_transactions['fathers_day_2017'] = (pd.to_datetime('2017-08-13')-new_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "# Childrens day: October 12 2017\n",
    "new_transactions['Children_day_2017'] = (pd.to_datetime('2017-10-12')-new_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "# Valentine's Day : 12th June, 2017\n",
    "new_transactions['Valentine_Day_2017'] = (pd.to_datetime('2017-06-12')-new_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "# Black Friday : 24th November 2017\n",
    "new_transactions['Black_Friday_2017'] = (pd.to_datetime('2017-11-24') - new_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "\n",
    "# 2018\n",
    "# Mothers Day: May 13 2018\n",
    "new_transactions['Mothers_Day_2018'] = (pd.to_datetime('2018-05-13')-new_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new features from existing features such as taking mean,max,unique values\n",
    "# below function takes a dataframe and a prefix for column name and create new features and return the new dataframe\n",
    "# as their are multiple values for single card id this function uses groupby to group all the cards and then uses the agg\n",
    "# function on top of it to calculate the aggregation functions like min,max,ect\n",
    "def aggregate_new_transactions(new_trans,prefix):    \n",
    "    agg_func = {\n",
    "        'category_1':   ['mean','nunique','sum'],\n",
    "        'category_3_0.0':   ['mean','sum'],\n",
    "        'category_3_1.0':   ['mean','sum'],\n",
    "        'category_3_2.0':   ['mean','sum'],\n",
    "        'category_2_1.0':   ['mean','sum'],\n",
    "        'category_2_2.0':   ['mean','sum'],\n",
    "        'category_2_3.0':   ['mean','sum'],\n",
    "        'category_2_4.0':   ['mean','sum'],\n",
    "        'category_2_5.0':   ['mean','sum'],     \n",
    "        'merchant_id': ['nunique'],\n",
    "        'Christmas_Day_2017': ['mean','var'],\n",
    "        'Mothers_Day_2017': ['mean','var'],\n",
    "        'fathers_day_2017': ['mean','var'],\n",
    "        'Children_day_2017': ['mean','var'],\n",
    "        'Valentine_Day_2017': ['mean','var'],\n",
    "        'Black_Friday_2017': ['mean','var'],\n",
    "        'Mothers_Day_2018': ['mean','var'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'purchase_amount': ['sum','max','min','mean','var','skew'],\n",
    "        'purchase_date': ['max', 'min'],\n",
    "        'installments': ['sum','max','min','mean','var','skew'],\n",
    "        'month_lag': ['sum','min', 'max','mean','var','skew'],\n",
    "        'state_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'n_price' :['sum','mean','max','min','var'],\n",
    "        'n_duration' : ['mean','min','max','var','skew'],\n",
    "        'n_amount_month_ratio':['mean','min','max','var','skew'],\n",
    "        'month_diff': ['mean','min','max','var','skew']\n",
    "        }\n",
    "    #computing all the aggs values\n",
    "    agg_new_trans = new_trans.groupby(['card_id']).agg(agg_func)\n",
    "    # giving name to all the calculated values\n",
    "    agg_new_trans.columns = [prefix +'_'+ '_'.join(col).strip() \n",
    "                           for col in agg_new_trans.columns.values]\n",
    "    agg_new_trans.reset_index(inplace=True)\n",
    "    # calculating accuracne of single card_id(how many rows are there with sanme card_id)\n",
    "    df = (new_trans.groupby('card_id').size().reset_index(name='new_transactions_count'))\n",
    "    # merging occurance of card_id with all the calculated aggs features\n",
    "    agg_new_trans = pd.merge(df, agg_new_trans, on='card_id', how='left')\n",
    "    \n",
    "    return agg_new_trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>new_transactions_count</th>\n",
       "      <th>new_tr_category_1_mean</th>\n",
       "      <th>new_tr_category_1_nunique</th>\n",
       "      <th>new_tr_category_1_sum</th>\n",
       "      <th>new_tr_category_3_0.0_mean</th>\n",
       "      <th>new_tr_category_3_0.0_sum</th>\n",
       "      <th>new_tr_category_3_1.0_mean</th>\n",
       "      <th>new_tr_category_3_1.0_sum</th>\n",
       "      <th>new_tr_category_3_2.0_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>new_tr_n_amount_month_ratio_mean</th>\n",
       "      <th>new_tr_n_amount_month_ratio_min</th>\n",
       "      <th>new_tr_n_amount_month_ratio_max</th>\n",
       "      <th>new_tr_n_amount_month_ratio_var</th>\n",
       "      <th>new_tr_n_amount_month_ratio_skew</th>\n",
       "      <th>new_tr_month_diff_mean</th>\n",
       "      <th>new_tr_month_diff_min</th>\n",
       "      <th>new_tr_month_diff_max</th>\n",
       "      <th>new_tr_month_diff_var</th>\n",
       "      <th>new_tr_month_diff_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018979</td>\n",
       "      <td>-0.019194</td>\n",
       "      <td>-0.018764</td>\n",
       "      <td>9.216176e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>21</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016572</td>\n",
       "      <td>-0.021168</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>2.525667e-05</td>\n",
       "      <td>1.573947</td>\n",
       "      <td>34.461538</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>0.258462</td>\n",
       "      <td>0.163916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020984</td>\n",
       "      <td>-0.021529</td>\n",
       "      <td>-0.020439</td>\n",
       "      <td>5.949484e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004353</td>\n",
       "      <td>-0.019122</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>1.948446e-04</td>\n",
       "      <td>0.884160</td>\n",
       "      <td>38.290323</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0.212903</td>\n",
       "      <td>0.971526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>6</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017221</td>\n",
       "      <td>-0.020924</td>\n",
       "      <td>-0.003167</td>\n",
       "      <td>2.724659e-05</td>\n",
       "      <td>2.294204</td>\n",
       "      <td>34.727273</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>-1.189373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  new_transactions_count  new_tr_category_1_mean  \\\n",
       "0  C_ID_00007093c1                       2                0.000000   \n",
       "1  C_ID_0001238066                      26                0.076923   \n",
       "2  C_ID_0001506ef0                       2                0.000000   \n",
       "3  C_ID_0001793786                      31                0.000000   \n",
       "4  C_ID_000183fdda                      11                0.000000   \n",
       "\n",
       "   new_tr_category_1_nunique  new_tr_category_1_sum  \\\n",
       "0                          1                      0   \n",
       "1                          2                      2   \n",
       "2                          1                      0   \n",
       "3                          1                      0   \n",
       "4                          1                      0   \n",
       "\n",
       "   new_tr_category_3_0.0_mean  new_tr_category_3_0.0_sum  \\\n",
       "0                    0.000000                          0   \n",
       "1                    0.038462                          1   \n",
       "2                    1.000000                          2   \n",
       "3                    1.000000                         31   \n",
       "4                    0.090909                          1   \n",
       "\n",
       "   new_tr_category_3_1.0_mean  new_tr_category_3_1.0_sum  \\\n",
       "0                    1.000000                          2   \n",
       "1                    0.807692                         21   \n",
       "2                    0.000000                          0   \n",
       "3                    0.000000                          0   \n",
       "4                    0.545455                          6   \n",
       "\n",
       "   new_tr_category_3_2.0_mean  ...  new_tr_n_amount_month_ratio_mean  \\\n",
       "0                    0.000000  ...                         -0.018979   \n",
       "1                    0.153846  ...                         -0.016572   \n",
       "2                    0.000000  ...                         -0.020984   \n",
       "3                    0.000000  ...                         -0.004353   \n",
       "4                    0.363636  ...                         -0.017221   \n",
       "\n",
       "   new_tr_n_amount_month_ratio_min  new_tr_n_amount_month_ratio_max  \\\n",
       "0                        -0.019194                        -0.018764   \n",
       "1                        -0.021168                        -0.002303   \n",
       "2                        -0.021529                        -0.020439   \n",
       "3                        -0.019122                         0.021053   \n",
       "4                        -0.020924                        -0.003167   \n",
       "\n",
       "   new_tr_n_amount_month_ratio_var  new_tr_n_amount_month_ratio_skew  \\\n",
       "0                     9.216176e-08                               NaN   \n",
       "1                     2.525667e-05                          1.573947   \n",
       "2                     5.949484e-07                               NaN   \n",
       "3                     1.948446e-04                          0.884160   \n",
       "4                     2.724659e-05                          2.294204   \n",
       "\n",
       "   new_tr_month_diff_mean  new_tr_month_diff_min  new_tr_month_diff_max  \\\n",
       "0               35.000000                     35                     35   \n",
       "1               34.461538                     34                     35   \n",
       "2               34.500000                     34                     35   \n",
       "3               38.290323                     38                     39   \n",
       "4               34.727273                     34                     35   \n",
       "\n",
       "   new_tr_month_diff_var  new_tr_month_diff_skew  \n",
       "0               0.000000                     NaN  \n",
       "1               0.258462                0.163916  \n",
       "2               0.500000                     NaN  \n",
       "3               0.212903                0.971526  \n",
       "4               0.218182               -1.189373  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_new_transactions = aggregate_new_transactions(new_transactions,'new_tr')\n",
    "agg_new_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id                      0\n",
       "new_transactions_count       0\n",
       "new_tr_category_1_mean       0\n",
       "new_tr_category_1_nunique    0\n",
       "new_tr_category_1_sum        0\n",
       "                            ..\n",
       "new_tr_month_diff_mean       0\n",
       "new_tr_month_diff_min        0\n",
       "new_tr_month_diff_max        0\n",
       "new_tr_month_diff_var        0\n",
       "new_tr_month_diff_skew       0\n",
       "Length: 80, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_new_transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_new_transactions.new_tr_month_diff_var.fillna(0.203728,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_new_transactions.new_tr_month_diff_skew.fillna(-0.199049,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_new_transactions.to_pickle('agg_new_transactions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_new_transactions = pd.read_pickle('agg_new_transactions.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the features created using new_transaction files with test and train files on card id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nt = pd.merge(train,agg_new_transactions, on= 'card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 50.84 Mb (68.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_nt = reduce_mem_usage(train_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 103)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nt['new_tr_purchase_date_max'] = pd.to_datetime(train_nt['new_tr_purchase_date_max'])\n",
    "train_nt['new_tr_purchase_date_min'] = pd.to_datetime(train_nt['new_tr_purchase_date_min'])\n",
    "train_nt['new_time_diff'] = (train_nt['new_tr_purchase_date_max'].dt.date - train_nt['new_tr_purchase_date_min'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nt = pd.merge(test, agg_new_transactions, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nt['new_tr_purchase_date_max'] = pd.to_datetime(test_nt['new_tr_purchase_date_max'])\n",
    "test_nt['new_tr_purchase_date_min'] = pd.to_datetime(test_nt['new_tr_purchase_date_min'])\n",
    "test_nt['new_time_diff'] = (test_nt['new_tr_purchase_date_max'].dt.date - test_nt['new_tr_purchase_date_min'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 104)\n",
      "(123623, 103)\n"
     ]
    }
   ],
   "source": [
    "print(train_nt.shape)\n",
    "print(test_nt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nt.to_pickle('train_nt.pkl')\n",
    "test_nt.to_pickle('test_nt.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the 4th csv file which is historical_transactions and priting the shape and first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1749.11 Mb (43.7% reduction)\n",
      "(29112361, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.703331</td>\n",
       "      <td>2017-06-25 15:33:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.733128</td>\n",
       "      <td>2017-07-15 12:10:45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.720386</td>\n",
       "      <td>2017-08-09 22:04:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.735352</td>\n",
       "      <td>2017-09-02 10:06:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.722865</td>\n",
       "      <td>2017-03-10 01:14:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  authorized_flag          card_id  city_id category_1  installments  \\\n",
       "0               Y  C_ID_4e6213e9bc       88          N             0   \n",
       "1               Y  C_ID_4e6213e9bc       88          N             0   \n",
       "2               Y  C_ID_4e6213e9bc       88          N             0   \n",
       "3               Y  C_ID_4e6213e9bc       88          N             0   \n",
       "4               Y  C_ID_4e6213e9bc       88          N             0   \n",
       "\n",
       "  category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0          A                    80  M_ID_e020e9b302         -8   \n",
       "1          A                   367  M_ID_86ec983688         -7   \n",
       "2          A                    80  M_ID_979ed661fc         -6   \n",
       "3          A                   560  M_ID_e6d5ae8ea6         -5   \n",
       "4          A                    80  M_ID_e020e9b302        -11   \n",
       "\n",
       "   purchase_amount        purchase_date  category_2  state_id  subsector_id  \n",
       "0        -0.703331  2017-06-25 15:33:07         1.0        16            37  \n",
       "1        -0.733128  2017-07-15 12:10:45         1.0        16            16  \n",
       "2        -0.720386  2017-08-09 22:04:29         1.0        16            37  \n",
       "3        -0.735352  2017-09-02 10:06:26         1.0        16            34  \n",
       "4        -0.722865  2017-03-10 01:14:19         1.0        16            37  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = pd.read_csv('historical_transactions.csv')\n",
    "historical_transactions = reduce_mem_usage(ht)\n",
    "del ht\n",
    "# historical_transactions = pd.read_pickle('history_trans.pkl')\n",
    "print(historical_transactions.shape)\n",
    "historical_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions.to_pickle('history_trans.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of columns provided for historical_transactions.csv file - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "card_id - Card identifier\n",
    "\n",
    "month_lag -\tmonth lag to reference date\n",
    "\n",
    "purchase_date -\tPurchase date\n",
    "\n",
    "authorized_flag - Y' if approved, 'N' if denied\n",
    "\n",
    "category_3 - anonymized category\n",
    "\n",
    "installments - number of installments of purchase\n",
    "\n",
    "category_1 - anonymized category\n",
    "\n",
    "merchant_category_id - Merchant category identifier (anonymized )\n",
    "\n",
    "subsector_id - Merchant category group identifier (anonymized )\n",
    "\n",
    "merchant_id - Merchant identifier (anonymized)\n",
    "\n",
    "purchase_amount\t- Normalized purchase amount\n",
    "\n",
    "city_id\tCity - identifier (anonymized )\n",
    "\n",
    "state_id - State identifier (anonymized )\n",
    "\n",
    "category_2 - anonymized category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag                2\n",
       "card_id                   325540\n",
       "city_id                      308\n",
       "category_1                     2\n",
       "installments                  15\n",
       "category_3                     3\n",
       "merchant_category_id         327\n",
       "merchant_id               326311\n",
       "month_lag                     14\n",
       "purchase_amount           215014\n",
       "purchase_date           16395300\n",
       "category_2                     5\n",
       "state_id                      25\n",
       "subsector_id                  41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how many unique values a column contains\n",
    "historical_transactions.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag           int64\n",
       "card_id                  object\n",
       "city_id                   int16\n",
       "category_1                int64\n",
       "installments              int16\n",
       "category_3              float64\n",
       "merchant_category_id      int16\n",
       "merchant_id              object\n",
       "month_lag                  int8\n",
       "purchase_amount         float32\n",
       "purchase_date            object\n",
       "category_2              float16\n",
       "state_id                   int8\n",
       "subsector_id               int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data types of columns\n",
    "historical_transactions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag               0\n",
       "card_id                       0\n",
       "city_id                       0\n",
       "category_1                    0\n",
       "installments                  0\n",
       "category_3               178159\n",
       "merchant_category_id          0\n",
       "merchant_id              138481\n",
       "month_lag                     0\n",
       "purchase_amount               0\n",
       "purchase_date                 0\n",
       "category_2              2652864\n",
       "state_id                      0\n",
       "subsector_id                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if there are any null values\n",
    "historical_transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that their are 3 features which contains null values we will explore those features and fill the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat3 = historical_transactions[~historical_transactions['category_3'].isnull()].drop(columns=['category_2','merchant_id','card_id','purchase_date']).sample(300000)\n",
    "test_cat3 = historical_transactions[historical_transactions['category_3'].isnull()].drop(columns=['category_2','merchant_id','card_id','purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24591753</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>560</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.703646</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24410144</td>\n",
       "      <td>1</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.683346</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4616781</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>278</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.712497</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6476221</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.690558</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18837610</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>302</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.449383</td>\n",
       "      <td>-1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          authorized_flag  city_id  category_1  installments  category_3  \\\n",
       "24591753                0       69           0             0         0.0   \n",
       "24410144                1      340           0             0         0.0   \n",
       "4616781                 1      158           0             1         1.0   \n",
       "6476221                 0      232           0             1         1.0   \n",
       "18837610                1       -1           1             1         1.0   \n",
       "\n",
       "          merchant_category_id  month_lag  purchase_amount  state_id  \\\n",
       "24591753                   560         -5        -0.703646         9   \n",
       "24410144                   278         -4        -0.683346         9   \n",
       "4616781                    278         -4        -0.712497        15   \n",
       "6476221                     80         -5        -0.690558        13   \n",
       "18837610                   302         -2        -0.449383        -1   \n",
       "\n",
       "          subsector_id  \n",
       "24591753            34  \n",
       "24410144            37  \n",
       "4616781             37  \n",
       "6476221             37  \n",
       "18837610            22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.297615</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>391</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.393785</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>936</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.475694</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>941</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>222</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.551563</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>965</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>514</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     authorized_flag  city_id  category_1  installments  category_3  \\\n",
       "885                0      251           0            -1         NaN   \n",
       "914                1      251           0            -1         NaN   \n",
       "936                1      251           0            -1         NaN   \n",
       "941                1      170           0            -1         NaN   \n",
       "965                1      251           0            -1         NaN   \n",
       "\n",
       "     merchant_category_id  month_lag  purchase_amount  state_id  subsector_id  \n",
       "885                    34         -1        -0.297615         8            38  \n",
       "914                   391          0        -0.393785         8             7  \n",
       "936                   307         -3        -0.475694         8            19  \n",
       "941                   222         -1        -0.551563         8            21  \n",
       "965                   514         -1        -0.114893         8             9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=0,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='(0,0,0,0,0,0,0,0,0)', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='gpu_hist', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_cat3['category_3'].values\n",
    "X = train_cat3.drop(columns='category_3').values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "clf = XGBClassifier(gpu_id=0,tree_method = 'gpu_hist')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "result = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "predicted_cat3 = clf.predict(test_cat3.drop(columns='category_3').values)\n",
    "print(predicted_cat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique items in the list are: 1\n"
     ]
    }
   ],
   "source": [
    "new_set = set(predicted_cat3) \n",
    "print(\"No of unique items in the list are:\", len(new_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions['category_3'].fillna(0.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    15177199\n",
       "3.0     3911795\n",
       "5.0     3725915\n",
       "4.0     2618053\n",
       "2.0     1026535\n",
       "Name: category_2, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling the nan values for category_2   \n",
    "historical_transactions['category_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions['category_2'].fillna(1.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag              0\n",
       "card_id                      0\n",
       "city_id                      0\n",
       "category_1                   0\n",
       "installments                 0\n",
       "category_3                   0\n",
       "merchant_category_id         0\n",
       "merchant_id             138481\n",
       "month_lag                    0\n",
       "purchase_amount              0\n",
       "purchase_date                0\n",
       "category_2                   0\n",
       "state_id                     0\n",
       "subsector_id                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M_ID_00a6ca8a8a    1115097\n",
       "M_ID_e5374dabc0     428619\n",
       "M_ID_9139332ccc     361385\n",
       "M_ID_50f575c681     183894\n",
       "M_ID_fc7d7969c3     177040\n",
       "                    ...   \n",
       "M_ID_7d41f7b4cd          1\n",
       "M_ID_b1430d4bd5          1\n",
       "M_ID_046ec15d51          1\n",
       "M_ID_db7fa90dd6          1\n",
       "M_ID_5e3975b3ce          1\n",
       "Name: merchant_id, Length: 326311, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_transactions.merchant_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the histogram of features present in historical_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001DDB4DF2B48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DE17BFF9C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD01016348>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001DD79210D08>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD0013F248>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DEA49C46C8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001DDEEA8DCC8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001E14E0D9F08>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001E14E0D4148>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001E14E0FCFC8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD006EFB48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD0072A9C8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "historical_transactions.hist(bins=30, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see the distribution of values of categorical features which occurs maximum time and we can see that for category_1 we have 2 values and the value 0 occures for maximum times, for category_2 we have 5 values and the value 1 occures for maximum times, for category_3 we have 3 values and the value 0 occures for maximum times, for authorized_flag we have 2 values and the value 1 occures for maximum times, for the feature month_lag we see that the all the values lies in the negative region.\n",
    "For the features installments and purchase_amount we can see that both have small value which are near 0. We will look into those features to see in what range their values lie\n",
    "Rest of the features are id types which uniqiely identify the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.911236e+07\n",
       "mean     6.484954e-01\n",
       "std      2.795577e+00\n",
       "min     -1.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      1.000000e+00\n",
       "max      9.990000e+02\n",
       "Name: installments, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_transactions.installments.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are seeing similar results like new_transaction maximum values are around 1 but some outliners are there having value close to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.911236e+07\n",
       "mean     6.134567e-02\n",
       "std      1.123521e+03\n",
       "min     -7.469078e-01\n",
       "25%     -7.203559e-01\n",
       "50%     -6.883495e-01\n",
       "75%     -6.032543e-01\n",
       "max      6.010604e+06\n",
       "Name: purchase_amount, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_transactions.purchase_amount.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purchase amount feature we can see that 75% points have value which are negative close to 0 as it is normalised and some outliners value which have values which are very high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling outliners in installments and purchase amount\n",
    "val = historical_transactions.installments.median()\n",
    "historical_transactions['installments'].replace(-1, np.nan,inplace=True)\n",
    "historical_transactions['installments'].replace(999, np.nan,inplace=True)\n",
    "historical_transactions['purchase_amount'] = historical_transactions['purchase_amount'].apply(lambda x: min(x, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions['h_month_diff'] = ((datetime.datetime.today() - historical_transactions['purchase_date']).dt.days)//30\n",
    "historical_transactions['h_month_diff'] += historical_transactions['month_lag']\n",
    "\n",
    "historical_transactions['h_duration'] = historical_transactions['purchase_amount']*historical_transactions['h_month_diff']\n",
    "historical_transactions['h_amount_month_ratio'] = historical_transactions['purchase_amount']/historical_transactions['h_month_diff']\n",
    "historical_transactions['h_price'] = historical_transactions['purchase_amount'] / historical_transactions['installments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions['category_3'] = historical_transactions['category_3'].map({'A':0, 'B':1, 'C':2}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(historical_transactions.category_3, prefix='hist_category_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions['hist_category_3_0.0'] = y['hist_category_3_0.0']\n",
    "historical_transactions['hist_category_3_1.0'] = y['hist_category_3_1.0']\n",
    "historical_transactions['hist_category_3_2.0'] = y['hist_category_3_2.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(historical_transactions.category_2, prefix='hist_category_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions['hist_category_2_1.0'] = y['hist_category_2_1.0']\n",
    "historical_transactions['hist_category_2_2.0'] = y['hist_category_2_2.0']\n",
    "historical_transactions['hist_category_2_3.0'] = y['hist_category_2_3.0']\n",
    "historical_transactions['hist_category_2_4.0'] = y['hist_category_2_4.0']\n",
    "historical_transactions['hist_category_2_5.0'] = y['hist_category_2_5.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1998.99 Mb (30.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "historical_transactions.drop(columns=['category_2','category_3'],inplace=True)\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Christmas : December 25 2017\n",
    "historical_transactions['h_Christmas_Day_2017'] = (pd.to_datetime('2017-12-25')-historical_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "# Mothers Day: May 14 2017\n",
    "historical_transactions['h_Mothers_Day_2017'] = (pd.to_datetime('2017-06-04')-historical_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "# fathers day: August 13 2017\n",
    "historical_transactions['h_fathers_day_2017'] = (pd.to_datetime('2017-08-13')-historical_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "# Childrens day: October 12 2017\n",
    "historical_transactions['h_Children_day_2017'] = (pd.to_datetime('2017-10-12')-historical_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "# Valentine's Day : 12th June, 2017\n",
    "historical_transactions['h_Valentine_Day_2017'] = (pd.to_datetime('2017-06-12')-historical_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "# Black Friday : 24th November 2017\n",
    "historical_transactions['h_Black_Friday_2017'] = (pd.to_datetime('2017-11-24') - historical_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "\n",
    "# 2018\n",
    "# Mothers Day: May 13 2018\n",
    "historical_transactions['h_Mothers_Day_2018'] = (pd.to_datetime('2018-05-13')-historical_transactions['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2193.33 Mb (38.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "historical_transactions = reduce_mem_usage(historical_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking sum of last 10 transaction days as their are some cards performed less then 10 transaction so firstly getting the cards having transaction more 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = historical_transactions[historical_transactions.groupby(['card_id'])['purchase_date'].transform('count') > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sort_values(['card_id','purchase_date'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = (df1.groupby('card_id')['purchase_date'].apply(lambda g: g.iloc[0] - g.iloc[10]).dt.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_diff = pd.DataFrame(num).reset_index()\n",
    "date_diff.columns = ['card_id', 'last_ten_transaction_date_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with train to check if the last 10 transactions days helps for predicting loyalty score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diff = pd.merge(train, date_diff, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>last_ten_transaction_date_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0            2017-06  C_ID_92a2005557          5          2          1   \n",
       "1            2017-01  C_ID_3d0044924f          4          1          0   \n",
       "2            2016-08  C_ID_d639edf6cd          2          2          0   \n",
       "3            2017-09  C_ID_186d6a6901          4          3          0   \n",
       "4            2017-11  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  last_ten_transaction_date_count  \n",
       "0 -0.820283                              8.0  \n",
       "1  0.392913                              4.0  \n",
       "2  0.688056                            177.0  \n",
       "3  0.142495                             16.0  \n",
       "4 -0.159749                              3.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=train_diff['last_ten_transaction_date_count'], y=train_diff['target'], color='red')\n",
    "plt.title('Scatterplot of last_ten_transaction_date_count against the target variable(Loaylty score)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that as the days are increasing loyalty score is getting closer to 0. But still it is not enough to provide good information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the merchants.csv file and and looking the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 30.32 Mb (46.0% reduction)\n",
      "(334696, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>merchant_group_id</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>subsector_id</th>\n",
       "      <th>numerical_1</th>\n",
       "      <th>numerical_2</th>\n",
       "      <th>category_1</th>\n",
       "      <th>most_recent_sales_range</th>\n",
       "      <th>most_recent_purchases_range</th>\n",
       "      <th>avg_sales_lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_sales_lag6</th>\n",
       "      <th>avg_purchases_lag6</th>\n",
       "      <th>active_months_lag6</th>\n",
       "      <th>avg_sales_lag12</th>\n",
       "      <th>avg_purchases_lag12</th>\n",
       "      <th>active_months_lag12</th>\n",
       "      <th>category_4</th>\n",
       "      <th>city_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>category_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M_ID_838061e48c</td>\n",
       "      <td>8353</td>\n",
       "      <td>792</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>-2.320000</td>\n",
       "      <td>13.916667</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>242</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M_ID_9339d880ad</td>\n",
       "      <td>3184</td>\n",
       "      <td>840</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>-0.720000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.740000</td>\n",
       "      <td>1.291667</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.570000</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>M_ID_e726bbae1e</td>\n",
       "      <td>447</td>\n",
       "      <td>690</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>-82.129997</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.129997</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-82.129997</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M_ID_a70e9c5f81</td>\n",
       "      <td>5026</td>\n",
       "      <td>792</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>Y</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>12</td>\n",
       "      <td>Y</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>M_ID_64456c37ce</td>\n",
       "      <td>2228</td>\n",
       "      <td>222</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>Y</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>12</td>\n",
       "      <td>Y</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       merchant_id  merchant_group_id  merchant_category_id  subsector_id  \\\n",
       "0  M_ID_838061e48c               8353                   792             9   \n",
       "1  M_ID_9339d880ad               3184                   840            20   \n",
       "2  M_ID_e726bbae1e                447                   690             1   \n",
       "3  M_ID_a70e9c5f81               5026                   792             9   \n",
       "4  M_ID_64456c37ce               2228                   222            21   \n",
       "\n",
       "   numerical_1  numerical_2 category_1 most_recent_sales_range  \\\n",
       "0    -0.057465    -0.057465          N                       E   \n",
       "1    -0.057465    -0.057465          N                       E   \n",
       "2    -0.057465    -0.057465          N                       E   \n",
       "3    -0.057465    -0.057465          Y                       E   \n",
       "4    -0.057465    -0.057465          Y                       E   \n",
       "\n",
       "  most_recent_purchases_range  avg_sales_lag3  ...  avg_sales_lag6  \\\n",
       "0                           E       -0.400000  ...       -2.250000   \n",
       "1                           E       -0.720000  ...       -0.740000   \n",
       "2                           E      -82.129997  ...      -82.129997   \n",
       "3                           E             NaN  ...             NaN   \n",
       "4                           E             NaN  ...             NaN   \n",
       "\n",
       "   avg_purchases_lag6  active_months_lag6  avg_sales_lag12  \\\n",
       "0           18.666667                   6        -2.320000   \n",
       "1            1.291667                   6        -0.570000   \n",
       "2          260.000000                   2       -82.129997   \n",
       "3            4.666667                   6              NaN   \n",
       "4            0.361111                   6              NaN   \n",
       "\n",
       "   avg_purchases_lag12  active_months_lag12  category_4  city_id state_id  \\\n",
       "0            13.916667                   12           N      242        9   \n",
       "1             1.687500                   12           N       22       16   \n",
       "2           260.000000                    2           N       -1        5   \n",
       "3             3.833333                   12           Y       -1       -1   \n",
       "4             0.347222                   12           Y       -1       -1   \n",
       "\n",
       "   category_2  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         5.0  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.read_csv('merchants.csv')\n",
    "merchant = reduce_mem_usage(m)\n",
    "print(merchant.shape)\n",
    "merchant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of columns provided for merchant.csv file - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merchant_id\t- Unique merchant identifier\n",
    "\n",
    "merchant_group_id -\tMerchant group (anonymized )\n",
    "\n",
    "merchant_category_id - Unique identifier for merchant category (anonymized )\n",
    "\n",
    "subsector_id - Merchant category group (anonymized )\n",
    "\n",
    "numerical_1\t- anonymized measure\n",
    "\n",
    "numerical_2\t- anonymized measure\n",
    "\n",
    "category_1 - anonymized category\n",
    "\n",
    "most_recent_sales_range\tRange of revenue (monetary units) in last active month --> A > B > C > D > E\n",
    "\n",
    "most_recent_purchases_range\tRange of quantity of transactions in last active month --> A > B > C > D > E\n",
    "\n",
    "avg_sales_lag3 - Monthly average of revenue in last 3 months divided by revenue in last active month\n",
    "\n",
    "avg_purchases_lag3 - Monthly average of transactions in last 3 months divided by transactions in last active month\n",
    "\n",
    "active_months_lag3 - Quantity of active months within last 3 months\n",
    "\n",
    "avg_sales_lag6 - Monthly average of revenue in last 6 months divided by revenue in last active month\n",
    "\n",
    "avg_purchases_lag6 - Monthly average of transactions in last 6 months divided by transactions in last active month\n",
    "\n",
    "active_months_lag6 - Quantity of active months within last 6 months\n",
    "\n",
    "avg_sales_lag12\t- Monthly average of revenue in last 12 months divided by revenue in last active month\n",
    "\n",
    "avg_purchases_lag12\t- Monthly average of transactions in last 12 months divided by transactions in last active month\n",
    "\n",
    "active_months_lag12\t- Quantity of active months within last 12 months\n",
    "\n",
    "category_4 - anonymized category\n",
    "\n",
    "city_id\t- City identifier (anonymized )\n",
    "\n",
    "state_id - State identifier (anonymized )\n",
    "\n",
    "category_2 - anonymized category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merchant_id                    334633\n",
       "merchant_group_id              109391\n",
       "merchant_category_id              324\n",
       "subsector_id                       41\n",
       "numerical_1                       954\n",
       "numerical_2                       947\n",
       "category_1                          2\n",
       "most_recent_sales_range             5\n",
       "most_recent_purchases_range         5\n",
       "avg_sales_lag3                   3372\n",
       "avg_purchases_lag3             100003\n",
       "active_months_lag3                  3\n",
       "avg_sales_lag6                   4507\n",
       "avg_purchases_lag6             135202\n",
       "active_months_lag6                  6\n",
       "avg_sales_lag12                  5009\n",
       "avg_purchases_lag12            172917\n",
       "active_months_lag12                12\n",
       "category_4                          2\n",
       "city_id                           271\n",
       "state_id                           25\n",
       "category_2                          5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking the unique value a fetures holds\n",
    "merchant.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merchant_id                     object\n",
       "merchant_group_id                int64\n",
       "merchant_category_id             int64\n",
       "subsector_id                     int64\n",
       "numerical_1                    float64\n",
       "numerical_2                    float64\n",
       "category_1                      object\n",
       "most_recent_sales_range         object\n",
       "most_recent_purchases_range     object\n",
       "avg_sales_lag3                 float64\n",
       "avg_purchases_lag3             float64\n",
       "active_months_lag3               int64\n",
       "avg_sales_lag6                 float64\n",
       "avg_purchases_lag6             float64\n",
       "active_months_lag6               int64\n",
       "avg_sales_lag12                float64\n",
       "avg_purchases_lag12            float64\n",
       "active_months_lag12              int64\n",
       "category_4                      object\n",
       "city_id                          int64\n",
       "state_id                         int64\n",
       "category_2                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data types of features\n",
    "merchant.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merchant_id                        0\n",
       "merchant_group_id                  0\n",
       "merchant_category_id               0\n",
       "subsector_id                       0\n",
       "numerical_1                        0\n",
       "numerical_2                        0\n",
       "category_1                         0\n",
       "most_recent_sales_range            0\n",
       "most_recent_purchases_range        0\n",
       "avg_sales_lag3                    13\n",
       "avg_purchases_lag3                 0\n",
       "active_months_lag3                 0\n",
       "avg_sales_lag6                    13\n",
       "avg_purchases_lag6                 0\n",
       "active_months_lag6                 0\n",
       "avg_sales_lag12                   13\n",
       "avg_purchases_lag12                0\n",
       "active_months_lag12                0\n",
       "category_4                         0\n",
       "city_id                            0\n",
       "state_id                           0\n",
       "category_2                     11887\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking for null values\n",
    "merchant.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    334683.000000\n",
       "mean         13.832993\n",
       "std        2395.489999\n",
       "min         -82.130000\n",
       "25%           0.880000\n",
       "50%           1.000000\n",
       "75%           1.160000\n",
       "max      851844.640000\n",
       "Name: avg_sales_lag3, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant.avg_sales_lag3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the avg_sales_lag3 has some missing value filling the missing value with the median because you can see max value is very which might have affected the mean and doing same for other 2 features which have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = merchant.avg_sales_lag3.median()\n",
    "merchant['avg_sales_lag3'].fillna(val,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.346830e+05\n",
       "mean     2.165079e+01\n",
       "std      3.947108e+03\n",
       "min     -8.213000e+01\n",
       "25%      8.500000e-01\n",
       "50%      1.010000e+00\n",
       "75%      1.230000e+00\n",
       "max      1.513959e+06\n",
       "Name: avg_sales_lag6, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant.avg_sales_lag6.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = merchant.avg_sales_lag6.median()\n",
    "merchant['avg_sales_lag6'].fillna(val,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.346830e+05\n",
       "mean     2.522771e+01\n",
       "std      5.251842e+03\n",
       "min     -8.213000e+01\n",
       "25%      8.500000e-01\n",
       "50%      1.020000e+00\n",
       "75%      1.290000e+00\n",
       "max      2.567408e+06\n",
       "Name: avg_sales_lag12, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant.avg_sales_lag12.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = merchant.avg_sales_lag12.median()\n",
    "merchant['avg_sales_lag12'].fillna(val,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at avg_purchase_lag_3, avg_purchase_lag_6, avg_purchase_lag_12 we saw that they contains infinite value so we converted the infinite value to nan values and then imputed them with median values for all 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.346960e+05\n",
       "mean              inf\n",
       "std               NaN\n",
       "min      3.334953e-01\n",
       "25%      9.236499e-01\n",
       "50%      1.016667e+00\n",
       "75%      1.146522e+00\n",
       "max               inf\n",
       "Name: avg_purchases_lag3, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant.avg_purchases_lag3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all the infinte values to median values\n",
    "val = merchant.avg_purchases_lag3.median()\n",
    "merchant.avg_purchases_lag3.replace([np.inf, -np.inf],val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.346960e+05\n",
       "mean              inf\n",
       "std               NaN\n",
       "min      1.670447e-01\n",
       "25%      9.022475e-01\n",
       "50%      1.026961e+00\n",
       "75%      1.215575e+00\n",
       "max               inf\n",
       "Name: avg_purchases_lag6, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant.avg_purchases_lag6.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = merchant.avg_purchases_lag6.median()\n",
    "merchant.avg_purchases_lag6.replace([np.inf, -np.inf],val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.346960e+05\n",
       "mean              inf\n",
       "std               NaN\n",
       "min      9.832954e-02\n",
       "25%      8.983333e-01\n",
       "50%      1.043361e+00\n",
       "75%      1.266480e+00\n",
       "max               inf\n",
       "Name: avg_purchases_lag12, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant.avg_purchases_lag12.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = merchant.avg_purchases_lag12.median()\n",
    "merchant.avg_purchases_lag12.replace([np.inf, -np.inf],val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    160888\n",
       "5.0     52923\n",
       "3.0     51887\n",
       "4.0     36450\n",
       "2.0     20661\n",
       "Name: category_2, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant['category_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant['category_2'].fillna(1.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merchant_id                    0\n",
       "merchant_group_id              0\n",
       "merchant_category_id           0\n",
       "subsector_id                   0\n",
       "numerical_1                    0\n",
       "numerical_2                    0\n",
       "category_1                     0\n",
       "most_recent_sales_range        0\n",
       "most_recent_purchases_range    0\n",
       "avg_sales_lag3                 0\n",
       "avg_purchases_lag3             0\n",
       "active_months_lag3             0\n",
       "avg_sales_lag6                 0\n",
       "avg_purchases_lag6             0\n",
       "active_months_lag6             0\n",
       "avg_sales_lag12                0\n",
       "avg_purchases_lag12            0\n",
       "active_months_lag12            0\n",
       "category_4                     0\n",
       "city_id                        0\n",
       "state_id                       0\n",
       "category_2                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if it still contains any null value\n",
    "merchant.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as given in description A>B>C>D>E providing larger value to A and smaller value to E\n",
    "merchant['category_1'] = merchant['category_1'].map({'N':0, 'Y':1})\n",
    "merchant['category_4'] = merchant['category_4'].map({'N':0, 'Y':1})\n",
    "merchant['most_recent_sales_range'] = merchant['most_recent_sales_range'].map({'A':5, 'B':4, 'C':3, 'D':2, 'E':1})\n",
    "merchant['most_recent_purchases_range'] = merchant['most_recent_purchases_range'].map({'A':5, 'B':4, 'C':3, 'D':2, 'E':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(merchant.category_2, prefix='me_category_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant['me_category_2_1.0'] = y['me_category_2_1.0']\n",
    "merchant['me_category_2_2.0'] = y['me_category_2_2.0']\n",
    "merchant['me_category_2_3.0'] = y['me_category_2_3.0']\n",
    "merchant['me_category_2_4.0'] = y['me_category_2_4.0']\n",
    "merchant['me_category_2_5.0'] = y['me_category_2_5.0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histogram for features in merchants.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001DD38D07888>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED65502C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED6542608>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED65279C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DEF2199D88>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001DEF30AD308>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED4AC39C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED4AF7FC8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED4AFF108>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED4B34808>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001DED4BA0F48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED4BD6CC8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED4C11A48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED4C4A808>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DED4C835C8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001DED4CBA2C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD007F22C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD243ED988>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD245D2D48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD2460CC08>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001DD24644A88>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD2467E888>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD246B7808>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD246F3748>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001DD2472B6C8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merchant.hist(bins=30, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features such as numerical_1, numerical_2, avg_sale_lag for 3,6,12 months and avg_purchase_lag for 3,6,12 months have values close to 0\n",
    "Category_1 and category_4 have maximum value as 1 and category_2 have maximum values as 1 followed by 3 and 5.\n",
    "As merchant.csv does not have card_id it will not be joined with our train file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see the corelation of our created features with the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging merchant file with historical_transactions file on merchant_id to include all the features present in mercahant file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant.drop(columns=['merchant_category_id','city_id','state_id','subsector_id','category_2'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming column names for category variables\n",
    "merchant.rename(columns={\"category_1\": \"m_category_1\", \"category_4\": \"m_category_4\"}, errors=\"raise\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions = pd.merge(historical_transactions, merchant, on='merchant_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del merchant\n",
    "del historical_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag                     0\n",
       "card_id                             0\n",
       "city_id                             0\n",
       "category_1                          0\n",
       "installments                   185736\n",
       "category_3                          0\n",
       "merchant_category_id                0\n",
       "merchant_id                         0\n",
       "month_lag                           0\n",
       "purchase_amount                     0\n",
       "purchase_date                       0\n",
       "category_2                          0\n",
       "state_id                            0\n",
       "subsector_id                        0\n",
       "h_month_diff                        0\n",
       "h_duration                          0\n",
       "h_amount_month_ratio                0\n",
       "h_price                        185739\n",
       "merchant_group_id                   0\n",
       "numerical_1                         0\n",
       "numerical_2                         0\n",
       "m_category_1                        0\n",
       "most_recent_sales_range             0\n",
       "most_recent_purchases_range         0\n",
       "avg_sales_lag3                      0\n",
       "avg_purchases_lag3                  0\n",
       "active_months_lag3                  0\n",
       "avg_sales_lag6                      0\n",
       "avg_purchases_lag6                  0\n",
       "active_months_lag6                  0\n",
       "avg_sales_lag12                     0\n",
       "avg_purchases_lag12                 0\n",
       "active_months_lag12                 0\n",
       "m_category_4                        0\n",
       "m_category_2                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 3632.58 Mb (26.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "all_transactions = reduce_mem_usage(all_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_purchases_lag3</th>\n",
       "      <th>active_months_lag3</th>\n",
       "      <th>avg_sales_lag6</th>\n",
       "      <th>avg_purchases_lag6</th>\n",
       "      <th>active_months_lag6</th>\n",
       "      <th>avg_sales_lag12</th>\n",
       "      <th>avg_purchases_lag12</th>\n",
       "      <th>active_months_lag12</th>\n",
       "      <th>m_category_4</th>\n",
       "      <th>m_category_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.703125</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082031</td>\n",
       "      <td>3</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.114258</td>\n",
       "      <td>6</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.157227</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.732910</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051758</td>\n",
       "      <td>3</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.058594</td>\n",
       "      <td>6</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974609</td>\n",
       "      <td>3</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.967285</td>\n",
       "      <td>6</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.956543</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.735352</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053711</td>\n",
       "      <td>3</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.897461</td>\n",
       "      <td>6</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.864258</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.722656</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082031</td>\n",
       "      <td>3</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.114258</td>\n",
       "      <td>6</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.157227</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  authorized_flag          card_id  city_id category_1  installments  \\\n",
       "0               Y  C_ID_4e6213e9bc       88          N           0.0   \n",
       "1               Y  C_ID_4e6213e9bc       88          N           0.0   \n",
       "2               Y  C_ID_4e6213e9bc       88          N           0.0   \n",
       "3               Y  C_ID_4e6213e9bc       88          N           0.0   \n",
       "4               Y  C_ID_4e6213e9bc       88          N           0.0   \n",
       "\n",
       "  category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0          A                    80  M_ID_e020e9b302         -8   \n",
       "1          A                   367  M_ID_86ec983688         -7   \n",
       "2          A                    80  M_ID_979ed661fc         -6   \n",
       "3          A                   560  M_ID_e6d5ae8ea6         -5   \n",
       "4          A                    80  M_ID_e020e9b302        -11   \n",
       "\n",
       "   purchase_amount  ... avg_purchases_lag3  active_months_lag3  \\\n",
       "0        -0.703125  ...           1.082031                   3   \n",
       "1        -0.732910  ...           1.051758                   3   \n",
       "2        -0.720215  ...           0.974609                   3   \n",
       "3        -0.735352  ...           1.053711                   3   \n",
       "4        -0.722656  ...           1.082031                   3   \n",
       "\n",
       "   avg_sales_lag6  avg_purchases_lag6  active_months_lag6  avg_sales_lag12  \\\n",
       "0            1.14            1.114258                   6             1.19   \n",
       "1            1.06            1.058594                   6             1.05   \n",
       "2            0.98            0.967285                   6             0.97   \n",
       "3            0.88            0.897461                   6             0.86   \n",
       "4            1.14            1.114258                   6             1.19   \n",
       "\n",
       "   avg_purchases_lag12  active_months_lag12  m_category_4  m_category_2  \n",
       "0             1.157227                   12             1           1.0  \n",
       "1             1.062500                   12             1           1.0  \n",
       "2             0.956543                   12             1           1.0  \n",
       "3             0.864258                   12             1           1.0  \n",
       "4             1.157227                   12             1           1.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions.to_pickle(\"all_trans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions = pd.read_pickle('all_trans.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['authorized_flag', 'card_id', 'city_id', 'category_1', 'installments',\n",
       "       'merchant_category_id', 'merchant_id', 'month_lag', 'purchase_amount',\n",
       "       'purchase_date', 'state_id', 'subsector_id', 'h_month_diff',\n",
       "       'h_duration', 'h_amount_month_ratio', 'h_price', 'hist_category_3_0.0',\n",
       "       'hist_category_3_1.0', 'hist_category_3_2.0', 'hist_category_2_1.0',\n",
       "       'hist_category_2_2.0', 'hist_category_2_3.0', 'hist_category_2_4.0',\n",
       "       'hist_category_2_5.0', 'h_Christmas_Day_2017', 'h_Mothers_Day_2017',\n",
       "       'h_fathers_day_2017', 'h_Children_day_2017', 'h_Valentine_Day_2017',\n",
       "       'h_Black_Friday_2017', 'h_Mothers_Day_2018', 'merchant_group_id',\n",
       "       'numerical_1', 'numerical_2', 'm_category_1', 'most_recent_sales_range',\n",
       "       'most_recent_purchases_range', 'avg_sales_lag3', 'avg_purchases_lag3',\n",
       "       'active_months_lag3', 'avg_sales_lag6', 'avg_purchases_lag6',\n",
       "       'active_months_lag6', 'avg_sales_lag12', 'avg_purchases_lag12',\n",
       "       'active_months_lag12', 'm_category_4', 'me_category_2_1.0',\n",
       "       'me_category_2_2.0', 'me_category_2_3.0', 'me_category_2_4.0',\n",
       "       'me_category_2_5.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag                0\n",
       "card_id                        0\n",
       "city_id                        0\n",
       "category_1                     0\n",
       "installments                   0\n",
       "merchant_category_id           0\n",
       "merchant_id                    0\n",
       "month_lag                      0\n",
       "purchase_amount                0\n",
       "purchase_date                  0\n",
       "state_id                       0\n",
       "subsector_id                   0\n",
       "h_month_diff                   0\n",
       "h_duration                     0\n",
       "h_amount_month_ratio           0\n",
       "h_price                        0\n",
       "hist_category_3_0.0            0\n",
       "hist_category_3_1.0            0\n",
       "hist_category_3_2.0            0\n",
       "hist_category_2_1.0            0\n",
       "hist_category_2_2.0            0\n",
       "hist_category_2_3.0            0\n",
       "hist_category_2_4.0            0\n",
       "hist_category_2_5.0            0\n",
       "h_Christmas_Day_2017           0\n",
       "h_Mothers_Day_2017             0\n",
       "h_fathers_day_2017             0\n",
       "h_Children_day_2017            0\n",
       "h_Valentine_Day_2017           0\n",
       "h_Black_Friday_2017            0\n",
       "h_Mothers_Day_2018             0\n",
       "merchant_group_id              0\n",
       "numerical_1                    0\n",
       "numerical_2                    0\n",
       "m_category_1                   0\n",
       "most_recent_sales_range        0\n",
       "most_recent_purchases_range    0\n",
       "avg_sales_lag3                 0\n",
       "avg_purchases_lag3             0\n",
       "active_months_lag3             0\n",
       "avg_sales_lag6                 0\n",
       "avg_purchases_lag6             0\n",
       "active_months_lag6             0\n",
       "avg_sales_lag12                0\n",
       "avg_purchases_lag12            0\n",
       "active_months_lag12            0\n",
       "m_category_4                   0\n",
       "me_category_2_1.0              0\n",
       "me_category_2_2.0              0\n",
       "me_category_2_3.0              0\n",
       "me_category_2_4.0              0\n",
       "me_category_2_5.0              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.028652e+07\n",
       "mean    -6.150171e-01\n",
       "std      1.929857e-01\n",
       "min     -7.468928e-01\n",
       "25%     -6.719255e-01\n",
       "50%     -6.719255e-01\n",
       "75%     -6.719255e-01\n",
       "max      8.000000e-01\n",
       "Name: h_price, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transactions.h_price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions.h_price.replace([np.inf, -np.inf],-0.6719255, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions.h_price.fillna(-0.6719255,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions.installments.replace([np.inf, -np.inf],-0.6484954, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions.installments.fillna(-0.6719255,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions['purchase_date'] = pd.to_datetime(all_transactions['purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>...</th>\n",
       "      <th>active_months_lag6</th>\n",
       "      <th>avg_sales_lag12</th>\n",
       "      <th>avg_purchases_lag12</th>\n",
       "      <th>active_months_lag12</th>\n",
       "      <th>m_category_4</th>\n",
       "      <th>me_category_2_1.0</th>\n",
       "      <th>me_category_2_2.0</th>\n",
       "      <th>me_category_2_3.0</th>\n",
       "      <th>me_category_2_4.0</th>\n",
       "      <th>me_category_2_5.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.703125</td>\n",
       "      <td>2017-06-25 15:33:07</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.157227</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.732910</td>\n",
       "      <td>2017-07-15 12:10:45</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>2017-08-09 22:04:29</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.956543</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.735352</td>\n",
       "      <td>2017-09-02 10:06:26</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.864258</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.722656</td>\n",
       "      <td>2017-03-10 01:14:19</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.157227</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   authorized_flag          card_id  city_id  category_1  installments  \\\n",
       "0                1  C_ID_4e6213e9bc       88           0           0.0   \n",
       "1                1  C_ID_4e6213e9bc       88           0           0.0   \n",
       "2                1  C_ID_4e6213e9bc       88           0           0.0   \n",
       "3                1  C_ID_4e6213e9bc       88           0           0.0   \n",
       "4                1  C_ID_4e6213e9bc       88           0           0.0   \n",
       "\n",
       "   merchant_category_id      merchant_id  month_lag  purchase_amount  \\\n",
       "0                    80  M_ID_e020e9b302         -8        -0.703125   \n",
       "1                   367  M_ID_86ec983688         -7        -0.732910   \n",
       "2                    80  M_ID_979ed661fc         -6        -0.720215   \n",
       "3                   560  M_ID_e6d5ae8ea6         -5        -0.735352   \n",
       "4                    80  M_ID_e020e9b302        -11        -0.722656   \n",
       "\n",
       "        purchase_date  ...  active_months_lag6  avg_sales_lag12  \\\n",
       "0 2017-06-25 15:33:07  ...                   6             1.19   \n",
       "1 2017-07-15 12:10:45  ...                   6             1.05   \n",
       "2 2017-08-09 22:04:29  ...                   6             0.97   \n",
       "3 2017-09-02 10:06:26  ...                   6             0.86   \n",
       "4 2017-03-10 01:14:19  ...                   6             1.19   \n",
       "\n",
       "   avg_purchases_lag12  active_months_lag12  m_category_4  me_category_2_1.0  \\\n",
       "0             1.157227                   12             1                  1   \n",
       "1             1.062500                   12             1                  1   \n",
       "2             0.956543                   12             1                  1   \n",
       "3             0.864258                   12             1                  1   \n",
       "4             1.157227                   12             1                  1   \n",
       "\n",
       "   me_category_2_2.0  me_category_2_3.0  me_category_2_4.0  me_category_2_5.0  \n",
       "0                  0                  0                  0                  0  \n",
       "1                  0                  0                  0                  0  \n",
       "2                  0                  0                  0                  0  \n",
       "3                  0                  0                  0                  0  \n",
       "4                  0                  0                  0                  0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions['authorized_flag'] = all_transactions['authorized_flag'].map({'N':0, 'Y':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions['category_1'] = all_transactions['category_1'].map({'N':0, 'Y':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying feature engg on all transaction to create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new features from existing features such as taking mean,max,unique values\n",
    "# below function takes a dataframe and a prefix for column name and create new features and return the new dataframe\n",
    "# as their are multiple values for single card id this function uses groupby to group all the cards and then uses the agg\n",
    "# function on top of it to calculate the aggregation functions like min,max,ect\n",
    "\n",
    "def aggregate_all_transactions(new_trans,prefix):    \n",
    "    agg_func = {\n",
    "        'authorized_flag' : ['mean','sum'],\n",
    "        'category_1':   ['mean','sum'],\n",
    "        'm_category_1':   ['mean','nunique','sum'],\n",
    "        'm_category_4':   ['mean','nunique','sum'],        \n",
    "        'me_category_2_1.0': ['mean','sum'],\n",
    "        'me_category_2_2.0': ['mean','sum'],\n",
    "        'me_category_2_3.0': ['mean','sum'],\n",
    "        'me_category_2_4.0': ['mean','sum'],\n",
    "        'me_category_2_5.0': ['mean','sum'],\n",
    "        'hist_category_3_0.0': ['mean','sum'],\n",
    "        'hist_category_3_1.0': ['mean','sum'],\n",
    "        'hist_category_3_2.0': ['mean','sum'],\n",
    "        'hist_category_2_1.0': ['mean','sum'],\n",
    "        'hist_category_2_2.0': ['mean','sum'],\n",
    "        'hist_category_2_3.0': ['mean','sum'],\n",
    "        'hist_category_2_4.0': ['mean','sum'],\n",
    "        'hist_category_2_5.0': ['mean','sum'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'h_Christmas_Day_2017': ['mean','var'],\n",
    "        'h_Mothers_Day_2017': ['mean','var'],\n",
    "        'h_fathers_day_2017': ['mean','var'],\n",
    "        'h_Children_day_2017': ['mean','var'],\n",
    "        'h_Valentine_Day_2017': ['mean','var'],\n",
    "        'h_Black_Friday_2017': ['mean','var'],\n",
    "        'h_Mothers_Day_2018': ['mean','var'],\n",
    "        'purchase_amount': ['sum','min', 'max','mean','var','skew'],\n",
    "        'purchase_date': ['max', 'min'],\n",
    "        'installments': ['sum','min', 'max','mean','var','skew'],\n",
    "        'month_lag': ['sum','min', 'max','mean','var','skew'],\n",
    "        'state_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'merchant_group_id' : ['nunique'],\n",
    "        'numerical_1' : ['sum','min', 'max','mean','var','skew'],\n",
    "        'numerical_2' : ['sum','min', 'max','mean','var','skew'],\n",
    "        'most_recent_sales_range': ['sum','min', 'max','mean','var','skew'],\n",
    "        'most_recent_purchases_range': ['sum','min', 'max','mean','var','skew'],\n",
    "        'avg_sales_lag3': ['sum','min', 'max','mean','var','skew'],\n",
    "        'avg_sales_lag6': ['sum','min', 'max','mean','var','skew'],\n",
    "        'avg_sales_lag12': ['sum','min', 'max','mean','var','skew'],\n",
    "        'avg_purchases_lag3': ['sum','min', 'max','mean','var','skew'],\n",
    "        'avg_purchases_lag6': ['sum','min', 'max','mean','var','skew'],\n",
    "        'avg_purchases_lag12': ['sum','min', 'max','mean','var','skew'],\n",
    "        'active_months_lag3': ['sum','min', 'max','mean','var','skew'],\n",
    "        'active_months_lag6': ['sum','min', 'max','mean','var','skew'],\n",
    "        'active_months_lag12': ['sum','min', 'max','mean','var','skew'],\n",
    "        'h_price' :['sum','mean','max','min','var'],\n",
    "        'h_duration' : ['mean','min','max','var','skew'],\n",
    "        'h_amount_month_ratio':['mean','min','max','var','skew'],\n",
    "        'h_month_diff': ['mean','min','max','var','skew']\n",
    "        }\n",
    "    #computing all the aggs values\n",
    "    agg_new_trans = new_trans.groupby(['card_id']).agg(agg_func)\n",
    "    # giving name to all the calculated values\n",
    "    agg_new_trans.columns = [prefix +'_'+ '_'.join(col).strip() \n",
    "                           for col in agg_new_trans.columns.values]\n",
    "    agg_new_trans.reset_index(inplace=True)\n",
    "    # calculating accuracne of single card_id(how many rows are there with sanme card_id)\n",
    "    df = (new_trans.groupby('card_id').size().reset_index(name='all_transactions_count'))\n",
    "    # merging occurance of card_id with all the calculated aggs features\n",
    "    agg_new_trans = pd.merge(df, agg_new_trans, on='card_id', how='left')\n",
    "    \n",
    "    return agg_new_trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_all_trans = aggregate_all_transactions(all_transactions,'all_trans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>all_transactions_count</th>\n",
       "      <th>all_trans_authorized_flag_mean</th>\n",
       "      <th>all_trans_authorized_flag_sum</th>\n",
       "      <th>all_trans_category_1_mean</th>\n",
       "      <th>all_trans_category_1_sum</th>\n",
       "      <th>all_trans_m_category_1_mean</th>\n",
       "      <th>all_trans_m_category_1_nunique</th>\n",
       "      <th>all_trans_m_category_1_sum</th>\n",
       "      <th>all_trans_m_category_4_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>all_trans_h_amount_month_ratio_mean</th>\n",
       "      <th>all_trans_h_amount_month_ratio_min</th>\n",
       "      <th>all_trans_h_amount_month_ratio_max</th>\n",
       "      <th>all_trans_h_amount_month_ratio_var</th>\n",
       "      <th>all_trans_h_amount_month_ratio_skew</th>\n",
       "      <th>all_trans_h_month_diff_mean</th>\n",
       "      <th>all_trans_h_month_diff_min</th>\n",
       "      <th>all_trans_h_month_diff_max</th>\n",
       "      <th>all_trans_h_month_diff_var</th>\n",
       "      <th>all_trans_h_month_diff_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>149</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>114</td>\n",
       "      <td>0.187919</td>\n",
       "      <td>28</td>\n",
       "      <td>0.187919</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.328859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015045</td>\n",
       "      <td>-0.021210</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>2.841797</td>\n",
       "      <td>34.778523</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>0.173590</td>\n",
       "      <td>-1.355186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>123</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>120</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>2</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017090</td>\n",
       "      <td>-0.021622</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>4.093750</td>\n",
       "      <td>34.463415</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.148553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015602</td>\n",
       "      <td>-0.021744</td>\n",
       "      <td>0.022858</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>2.453125</td>\n",
       "      <td>34.779412</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>0.174495</td>\n",
       "      <td>-1.378313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>222</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>195</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>2</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.707207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007416</td>\n",
       "      <td>-0.019623</td>\n",
       "      <td>0.021057</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>1.316406</td>\n",
       "      <td>38.626126</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0.235151</td>\n",
       "      <td>-0.524918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>149</td>\n",
       "      <td>0.953020</td>\n",
       "      <td>142</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>4</td>\n",
       "      <td>0.134228</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.953020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014961</td>\n",
       "      <td>-0.021652</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>2.605469</td>\n",
       "      <td>34.617450</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>0.237802</td>\n",
       "      <td>-0.488251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  all_transactions_count  all_trans_authorized_flag_mean  \\\n",
       "0  C_ID_00007093c1                     149                        0.765101   \n",
       "1  C_ID_0001238066                     123                        0.975610   \n",
       "2  C_ID_0001506ef0                      68                        0.941176   \n",
       "3  C_ID_0001793786                     222                        0.878378   \n",
       "4  C_ID_000183fdda                     149                        0.953020   \n",
       "\n",
       "   all_trans_authorized_flag_sum  all_trans_category_1_mean  \\\n",
       "0                            114                   0.187919   \n",
       "1                            120                   0.016260   \n",
       "2                             64                   0.000000   \n",
       "3                            195                   0.009009   \n",
       "4                            142                   0.026846   \n",
       "\n",
       "   all_trans_category_1_sum  all_trans_m_category_1_mean  \\\n",
       "0                        28                     0.187919   \n",
       "1                         2                     0.040650   \n",
       "2                         0                     0.058824   \n",
       "3                         2                     0.144144   \n",
       "4                         4                     0.134228   \n",
       "\n",
       "   all_trans_m_category_1_nunique  all_trans_m_category_1_sum  \\\n",
       "0                               2                        28.0   \n",
       "1                               2                         5.0   \n",
       "2                               2                         4.0   \n",
       "3                               2                        32.0   \n",
       "4                               2                        20.0   \n",
       "\n",
       "   all_trans_m_category_4_mean  ...  all_trans_h_amount_month_ratio_mean  \\\n",
       "0                     0.328859  ...                            -0.015045   \n",
       "1                     0.162602  ...                            -0.017090   \n",
       "2                     0.985294  ...                            -0.015602   \n",
       "3                     0.707207  ...                            -0.007416   \n",
       "4                     0.953020  ...                            -0.014961   \n",
       "\n",
       "   all_trans_h_amount_month_ratio_min  all_trans_h_amount_month_ratio_max  \\\n",
       "0                           -0.021210                            0.023529   \n",
       "1                           -0.021622                            0.022598   \n",
       "2                           -0.021744                            0.022858   \n",
       "3                           -0.019623                            0.021057   \n",
       "4                           -0.021652                            0.023529   \n",
       "\n",
       "   all_trans_h_amount_month_ratio_var  all_trans_h_amount_month_ratio_skew  \\\n",
       "0                            0.000054                             2.841797   \n",
       "1                            0.000031                             4.093750   \n",
       "2                            0.000147                             2.453125   \n",
       "3                            0.000154                             1.316406   \n",
       "4                            0.000109                             2.605469   \n",
       "\n",
       "   all_trans_h_month_diff_mean  all_trans_h_month_diff_min  \\\n",
       "0                    34.778523                          34   \n",
       "1                    34.463415                          34   \n",
       "2                    34.779412                          34   \n",
       "3                    38.626126                          38   \n",
       "4                    34.617450                          34   \n",
       "\n",
       "   all_trans_h_month_diff_max  all_trans_h_month_diff_var  \\\n",
       "0                          35                    0.173590   \n",
       "1                          35                    0.250700   \n",
       "2                          35                    0.174495   \n",
       "3                          39                    0.235151   \n",
       "4                          35                    0.237802   \n",
       "\n",
       "   all_trans_h_month_diff_skew  \n",
       "0                    -1.355186  \n",
       "1                     0.148553  \n",
       "2                    -1.378313  \n",
       "3                    -0.524918  \n",
       "4                    -0.488251  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_all_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: all_trans_authorized_flag_sum, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_all_trans.all_trans_authorized_flag_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id                           0\n",
       "all_transactions_count            0\n",
       "all_trans_authorized_flag_mean    0\n",
       "all_trans_authorized_flag_sum     0\n",
       "all_trans_category_1_mean         0\n",
       "                                 ..\n",
       "all_trans_h_month_diff_mean       0\n",
       "all_trans_h_month_diff_min        0\n",
       "all_trans_h_month_diff_max        0\n",
       "all_trans_h_month_diff_var        0\n",
       "all_trans_h_month_diff_skew       0\n",
       "Length: 176, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_all_trans.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_all_trans.all_trans_h_month_diff_skew.fillna(-0.385426,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_all_trans.to_pickle('agg_all_trans.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_all_trans = pd.read_pickle('agg_all_trans.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325540, 176)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_all_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nt = pd.read_pickle('train_nt.pkl')\n",
    "test_nt = pd.read_pickle('test_nt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.merge(train_nt,agg_all_trans,on='card_id',how='left')\n",
    "test_all = pd.merge(test_nt,agg_all_trans,on='card_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 279)\n",
      "(123623, 278)\n"
     ]
    }
   ],
   "source": [
    "print(train_all.shape)\n",
    "print(test_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.fillna(0,inplace=True)\n",
    "test_all.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.read_pickle('train_all.pkl')\n",
    "test_all = pd.read_pickle('test_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 217)\n",
      "(123623, 216)\n"
     ]
    }
   ],
   "source": [
    "print(train_all.shape)\n",
    "print(test_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['first_active_month', 'card_id', 'feature_1', 'feature_2', 'feature_3',\n",
       "       'target', 'year', 'month', 'dayofweek', 'dayofyear',\n",
       "       ...\n",
       "       'all_time_diff', 'transactions_total', 'avg_all_card_use',\n",
       "       'avg_new_card_use', 'total_diff', 'total_avg', 'diff_btw_first_last',\n",
       "       'total_purchase_sum', 'total_install_sum', 'total_month_lag_mean'],\n",
       "      dtype='object', length=177)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target                               1.000000\n",
      "all_trans_h_duration_min             0.079726\n",
      "all_trans_h_Mothers_Day_2018_var     0.076690\n",
      "new_tr_Mothers_Day_2018_mean         0.076574\n",
      "all_trans_h_Mothers_Day_2018_mean    0.062772\n",
      "                                       ...   \n",
      "all_trans_h_month_diff_mean         -0.099798\n",
      "new_tr_month_diff_mean              -0.101452\n",
      "new_tr_month_diff_max               -0.103575\n",
      "all_trans_active_months_lag3_max          NaN\n",
      "all_trans_active_months_lag6_max          NaN\n",
      "Name: target, Length: 273, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#checking correlation with target variable\n",
    "corr = train_all.corr()\n",
    "print(corr[\"target\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAysAAAEXCAYAAACtcNujAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxU1d3/P2eysSNbCKAOiAou+DxW2qR9XHCpVu3TKSit1gWB2sfaUuEHLQWtC1Yptj7RYn1sFTF1FwmlNVopxghYIAQEERIgIZmwJAwQ9iUkmfP743Mv986dO1sIDCHf9+t1XjNzl7PNveee7/0uR2mtIQiCIAiCIAiCcLrhSXYFBEEQBEEQBEEQ3BBhRRAEQRAEQRCE0xIRVgRBEARBEARBOC0RYUUQBEEQBEEQhNMSEVYEQRAEQRAEQTgtEWFFEARBEARBEITTkjYlrCilqpRSN5yisn6rlNqllKptxrlFSqkfG9/vU0otafkati6UUgeVUuclux4nA/v/fTrmJ4SjlNJKqfObcd4wpdRW2+9TNiadriilpiqlXkl2PU4Gzv/7dMtPAJRS65RSw5JQbn9jHEk91WWfCcQ7J4jVz0qpx5VSbyRQ7v8opZ5LpK4tyZn0zFBK/UIp9bt4jo0prCilrlRK/VsptU8pVaeU+lwp9fUTrGDYBFwp9ZpS6rcnkm9LcaIPBKXUOQAmArhYa53VcjWLWmazJk+nI26Tba11J6315mTVqaVIdGBMJkqpdKXU+8bgqJ0PdKXUL5VSXymlDiilKpVSv0xSVc9oWtM1Ewu3sVVr/bTW+owQrlvTOKyUekYptUUptV8p5VdKPZzsOiUDrfUlWuuiE8kjnnv0ZE4yky3EJqP8ZMwJlFLpAB4B8Hvjd1IFzjPg2fAXAHcrpTJjHRhVWFFKdQHwAYCZALoD6AfgCQD1LVDJFuU0ezvhBbBbax1IdkVMTrP+EVoPSwDcDcBNQ6gA3AugG4DvAPi5UuqOU1g3AYAibUpLLrQIswAM1lp3AfAtAD9SSo1Icp2EJNCa5gdJrqsPQJnWelsS69BqUEqlRNuvtT4K4CNwHhEdrXXEBGAogL0xjrkfQCmAAwDWA/iasf3XACps24cb2y8CcBRAE4CDAPYC+AmABgDHjG3/MI7tC2AugJ0AKgH8wlbu4wDeB/AGgP0Afmzb9q5R7ioA/2E7pwrADcb3DADPAdhupOeMbR0BHAEQNOpyEEBfl3Z3BfBXo25+UNr2ALjBcf5rLud2A4XAnQD2GN/Ptu0vAvBj4/t9AJbE+A8WAdAADhll/hDAMABbAUwGJ5qvx1nukwA+N/pvAYCexr52Rl/vNv6zFQB6x6jXaNu1sRnA/zj2+wCsNv6/CnDC+5RxbRw12vKCcawGcD6AHKM9KbZ8hgP40vjugXXt7QbwHoDuMerZ38h/NIAtRt88AODrAL402vuC7XiP8X/7AQSM66CrI69RAKoB7ALwsLHvO+A13mC0bc1J6nf79TMQQKFx/i4AbwI4y3bs1wB8YZQ7B7x3fuuS51YAw2KU+0cAM2McowDkGv22z+jfS531drv2jX59EMAmo75PGu1balxD7wFIj1BurH6oAjDJqM8+ox/a2fb/EkANOFaMMepyfqLXPYz70m1MipBXtGvmKeOaOQLeGzHLBTW+AaMto237bwHH6QMAtgGYFON/jDWWdAcw2+ivPQD+hghjKzhuv2Gc908AP3eUtQbACOP7YAD/AlAHYAOAH0Srp3HOawBeBB+KB40+ywLH/D0AygBcbjv+IqN/9wJYB+B7jrz+BKDA6KvlAAbGMQ63VL87rx/X56yxLwXAs+D1Xgng50b9Ul3y7QdgLYBfxSg/4ngEx7Xs+F/7I4Ex1qXcb4D3+V6jD1+A7V4HcKNxPewz/uvPEP8YeLzeRp3fA8f0A8b/P9R27GTjfzpglHc9Ityjjvq/Dl73R4xjfoUozwrjnLieZYh8X8XqMw3gZ+B4Wmls+xWsce7HsI1z4PzoD0ZddwB4CUD7SOU76hjrud2cutrrdiv4HNsPXl+P2841+/knRrtqAEx0u05tdf23UZc1sD33ALwK4BGXvN3uqb4A/g6OVeUA7o/negbHl2cdef0DwHj79QqX6w7ASAArHedOBPC3CPfVfeCz4gA4Rtxl2xdpbh9rfPw/AB+C4+ANiDKPN865C8CnMcfxGANTF/AmyQNwM4Bujv0jwRv36+Ak5HwAXtu+vuAN90Oj4n1sHbTEkddrsE2SjPNWAngUQDqA84xOvcl2gTUA+L5xbHvbttsBpIGTj0oAaS6D0jQAywBkAugFXpxPuj0QIvTNXwHMB9AZvGA3Ahgbz/kAegC4DUAH4/w59osJCQorzhvXVodGADPAQaZ9nOVWALjQOL4IwO+Mff8D3jAdwIfgFQC6xKjTreCDQgG4BsBhWBf8N8AHy7eN/68f+JYvpP1u7TPq+G3bvjkAfm18H2/8r2cb7f4zgLdj1LO/kf9L4MP4RlBY+ptxffQDJxrXGMePAQef8wB0ApAP4HVHXi8bffgfoCbyIreB8ST1u/36Od/o4wzwOl8E4DljXzoocD0E3i8jwMEvYWHF+I+/APBAjLrdBN7XZxnnXARrXAj53+EurPwdHJcuMfr1E+N/6AoOqKMilBuxH2xjQzE4ZnUHB+kHjH3fAR/Ol4IP5rcQXViJdt0PQwLCSoxrptroh1Tj/4tVbiM47qWBk+TDMMZ08IF5lfG9m3neCYxhBaDA180o7xq39jvbB75h+9y272LwoWi+SNoCTnhTQUF7F4BLYtT1NeO4K8D7uxB8LtwL3lO/hfGwNOpaDmAqeH9cBz6sB9nyqgPHr1Rw4vtOHONwS/W78/qJ9px9ALwnzjbyXgjHxAqcDB80tm+GTeCMUH7E8QjxCStxjbEu5V4BTiJTjbxKYU3eeoKT1BHG/ofAeUDMMdBZb6POR43/KQXAdADLjH2DwOuvr61NA51tjdJ3zv4x+yTSsyLuZ5nzuojVZ7Zr9V/geNceHOdqwTGlAyhg2Z+7z4Hjb3fwnv8HgOmRynepY7TndkJ1dd5rRvlDwPvgMnC8/r6jn98Gx5Ah4MTZ/p+b12k/cM57i5HXt43fvYz9KwCMdPkP3YSVz0DBuR2A/zTKvD6O6/kboFDlsV3fh+HyUgDhglYGOD5dZNv2BYDbXOrXEbxvzLGtD4yxFBHm9ohvfNwH4L+M/uuAKPN445yvAaiLdu1oraMLK0ZGFxkV2AoOun+3ddrHAB6KlYdx7GoAPuP7fYgtrGQDqHYcMwXAbNuftMix/3EYA4vx24PQh4H9T64AcIvt2JsAVMVz44GDWD3ok2IfxIvivXEd+f0ngD2230VoGWHlGGxvh+Ms1/7W4EEA/zS+jwEFusvibZdLeX8zrxdw4M2NcNzx9ru1D5xcvGp87ww+oL3G71IYA4LtBmyAy2BiO6a/kX8/27bdAH5o+z0X1mDyCYAHbfsGmWXY8rK/ZS4GcIftGnWbeLZYv7v1n23f9wF8YXy/GhyQlG3/EjRPWHkCfLOTEaNu14GCfQ6MwThSvZ3XvtGv/2X7vRLAZNvvZ2GbhMSox/F+MH5XAbjb9vsZAC8Z31+FITwavy9EFGElxnU/DC0nrExLsNwjCJ2oBgDkGN+rwTEsqiAcpazjYwl4zwXheLnl1n5n+xB+Pz8F617/IYDFjnP/DOCxGHV7DcDLtt/jAJTafg+BYUEA4Cpwwuax7X8bxptaI69XbPtuAc1Cwsapk9Hvbv3n2G9/zhYiVLt2A1wmVuBk5HLwHu4co/yI45HzWoa7sBLXGBtHP4wHMM/4fi+ApY72bEEcY6Cz3kadF9r2XQzgiPH9fOO/uwHGC1C3tkaps7N/zD6J9KyI+1kW67pw9pntWr3O9vtVGMKHrb3a+FTgfTnQtv+bsLQc8ZQf8bmdaF3d7jXHvudgzC9s/TzYtv8ZALNcrtPJMF482o79GMZLMFCz8x2X/9B5T50DWoh0tm2bDhdLmwjtLYUh2IEa0Q+jXK/OZ8P/AXjK+H4JqMUMey6Dwspe8KVTe5c2h83tEd/4+FfbvqjzeOP3BQCaol07WuvYDvZa61Kt9X1a67PBN4t9jQvB/EMq3M5TSt2rlFqtlNqrlNprnNszVnk2vAD6mucbeUwF0Nt2zBaX845v01oHwUlWX5fj+oJvlU38EY5zoyest9L28/vFc7JSqoNS6s+GU+N+8E3PWbHs+5rBTk2bwETKtfsmHAY1BwDfsnwM4B2l1HbDOTMtWuFKqZuVUsuMwAx7wQe7eQ1EvHbi4C0AI5RSGeDbtFVaa/O/8AKYZ7tmSsFBo7d7ViHssH0/4vLb7Au3ayfVUUakfoxEi/W7HaVUplLqHaXUNuM/fwPWf9AXwDZtjBgGbvdUrDJ+Dk4YbtVaR/Vn01oXgirvPwHYoZT6i+EbFy/x/kfOOkbrB5NI/0FfhPaL/b93Kyvadd+ShPxXcZS7W2vdaPttb+NtxvF+pdRnSqlvRis4xlhyDvimbE+iDdJaHwC1Mqbv0x2g9gLgvZ3teCbcBZp0xSKRe3uL8ewwcY7tid7bLdbvTmI8Z53Xreu9rckXYD88EaPIExqP0Pz790Kl1AdKqVrjensaEdppjGf2iHvx3Pt2nP9vO6VUqta6HJxUPg4gYOQZ75whGpGupxN5lsXqMxP7NRHteukF4y25rT7/NLbHS8TndjPqGoJSKlsp9alSaqdSah+oVYx2fqT5nhfASMcYcyUoKAKc+HeOo619wTHwgKPMfkZ9Y7U3D/QVhfH5ehxl2s/9kVJKAbgHwHtuz2Wt9SHwBdADAGqUUgVKqcHG7kjzs3jGR3s/xzOP7wxqY6KSkFOm1roMlJwutVVqoPM4pZQXVG3+HEAPrfVZAL4CpXOAkmhY9o7fW0Cp/Sxb6qy1viXKOQA72ayHB1Shbnc5bjvYkSbn2o5zy9fOLvANh/P8eJ2uJoJv47M1nRuvNqsc5/nx4mxHs8vVWjdorZ/QWl8MOmN+F1GcoowBaS5o49rbuAY+tJXleu1EqLezLuvBG+RmAD8CB0GTLQBudlw37XTLOsS5XTuNCH3wRiLWtRV6cIL97sJ0o8zLjP/8blj/QQ2AfsagZnIOEkApNQY0Jbleax1XNBit9R+11leAb30uBP1BAL5p62A7tCUj6UXrh1jUILRfzo10YBzXfXOIdM0c336i5WqtV2itfaBJzt9A+/hoRBtLtgDorpQ6K4G22HkbwJ3GxL09gE+N7VsAfOa4tztprX8aR57xsh3AOSo0YEEiY3tCNKPfjxPHc7YGfP6ZxLq3UxF5TDbrG208Opn37/+BvkUXGNfbVERopzGe2dt9Ivd+CFrrt7TWV4LjvwbNrIH4ruuExn4k9ixzyztan7mdF+162QUKk5fY6tJVa20KVjHbFuO5nWhdnbwFWv2co7XuCpobOs93juFu88ItoGbF3ucdtdZmeN0vwWdWLLaDY6BdsLGPI7Ha+wYAn1LqP0Drpr9FKCesT7TWy0CrmqvAfo4o6GitP9ZafxsUxsrA8QSIPD+LZ3x0vvyMNY+/CLTKiEqsaGCDlVITlVJnG7/PAXAnaEcJAK8AmKSUukKR840BtKNR4Z3GeaNhCTgAJ3VnK4aBs2+zx8wuBrBfKTVZKdVeKZWilLpUxQ6bfIVSaoRixIjxoLnWMpfj3gbwiFKql1KqJ2hTZ4aA2wGgh1Kqq1sBWusm8KHylFKqs9Hm/2c7PxadwRt/r1KqO4DH4jwvGs7+a9FylVLXKqWGGG9O94PCWlOUU9JB+8mdABqVUjeDdsomswCMVkpdr5TyKKX62aT6eNryFoBfgJOkObbtL4H/i9eody+llC++VsbN2wAmKKUGKKU6gW9F3nW8PY3EDgD9VZzRm5rR7046wwhkoZTqB0swAOjg1wRG8Uo1+ukbjvIzlFLtjJ/pSql2pnCjlLoLbPu3dZwhJJVSXzfegqWBkxsz2AZAE5YRim/tzwcwNoF2xiJaP8TiPQD3KaUuVkp1QPT7JtZ13xziuWaaXa5iiOq7lFJdtdYN4HUW6xqLOJZorWtAZ/YXlVLdlFJpSilTmIk6thp8CE4Gp4H3lfkW7wMAFyql7jHyTDOup4viaWecLAevy18Z+Q8D8N8A3onz/HjGLgDN7nc7sZ6z7wF4yBhbzwJNXMyyPYrrRXQznt3fAB2YP4lR52jj0WoAdxj9NhT0HW0pOhvlHTSeE3YBtQDAEKXU943n/s8QKiidyL1/HKXUIKXUdcaLgaPg9W+2PZ57NO5rwyCRZ5nbfRWtz9x4D3wmX2SMc4+aO4x78GUAucoIM2tcVzdFKd+NSM/tROvqpDOoyThqXMs/cjnmN8az5RLQ7+1dl2PeAPDfSqmbjDlnO8WwzKYQ9yHoD+gkwzi2nfG83AaaS043tl0GPs9MLXHU9hov/laAgsZcrfWRCO2OdN39FbRgaNRau67Tp5TqrZT6nlKqIzhPPgjreo40t090fIxnHn8N+LyISqwJ0wHQ5my5UuoQOOn/CnyrBq31HNCm+C3j2L+B0SrWg/bjS8HOHAJGYDEpBKMI1CqldhnbZgG4WFFV9DdDIPhv0Ba6EpTsXwEdaaMxH1Rt7QFVYCOMB4GT3wIoASXltWDksN8a7SoDJ6Sbjfq4qQvHgX/aZtDO/y3Q5jMengPfGO4C+/SfcZ4XjccB5Bn1/cFJKDcLjLS2H1RHf4Yowpmh/vwFOADuAQePv9v2F4MDRi6oAvwMlrbieQC3K6X2KKX+GKGIt0E72UKt9S7b9ueNchYopQ4Y7cxOoJ3x8Co4iCwCr82j4PUQD+YAvVsptSqO4xPqdxeeAB3Y9oEP9Xxzh9b6GKiOHwvart4NTgjtKuMN4EO5H2j+cQTW//Rb0NF6heICXQeVUi/FqE8X8KG3B3zLthvUBgC8Fo6BY0YerIG9JYjYD7HQWn8E3juFoHNhYZRjo173zSTmNdMC5d4DoErRJOEBWCYIkYg1ltwDTmTLQDv/8UY9Y46thslCPugb8JZt+wFQALsDfMNXCyuASItg3BPfA9/+7gIdZO816h0PjyP2OGwn0X631zXWc/ZlMLLgl6CT7YegBtickAyHFUnsDXCJgpkxio02Hv0GfBu7B7zf3nLLoJlMAq/pA2C7jk80jfF/JOiHsBv0MymBNY41+953kAHgd+B1UQtqw6Ya++IZ16eDL0j3KqUmxVFe3M+yCPdVxD6LkMdHYETHT8Fxbqmxy+zHycb2Zcb1uhDUrsY7ZwIiP7cTqqsLDwKYZvTTo3DXUH5m1P8TAH/QWi9wHqC13gJGKZ0KvgTYAgq35lz5HwAGu7TvIPhsNNN14Iv9/uBYNQ/0rftXAu3NA+/paCZgka6718EXF9HO9YBz+e2gU/41YD9Gm9snND7Gmscbgt0tRlujorROVDN5+qKUehx0uIp7wBcEwUIptRx0LJ+d7LoIgtByGNq2l7TW3pgHt2KMt8xbwTCsn8Y6XnDH0Fh+BTpnx2M10CZQSv0EDK40/iSXczX4IqC/w0cknnPbgy+Jvqa13nQy6tcSKKXGgaZ7v4p1bKtZCEgQhJZHKXUNqD3ZBTorX4aW0fQJgpBEjAnLtaB2pTdoqjcvqZU6SRjmSMvBt9q/BO3/3cy/hSgopYaD2qeOoNbyHyKohKK1/svJLkPRTPohMPJgQoKKwU8BrDidBRUA0FrH0uQeR1Y9biUopa6ymdqEpCTXy7VOSqmrklkvJ4q24W71XJfsujWHFuz3QaBz2z5QJXy74XNwInU7La/V0xml1EcR+mxq7LNPWp2mRqhTTPviU41Sal2Eut6V7LolSgv2uwJNoPaAZmClsPkhRCm/NY6V3wRN2naBZiffj2LnL0Tmf0DzpwrQXLAlg1cIcWBotPaCTu/PxTjc7fwqUNCZ2LI1Sy5nlBmYIAiCIAiCIAhnDqJZEYRThFLqHMVY8KXGm+CHjO3dlVL/UkptMj67JbuugiAIgiAIpwOiWRGEU4RSqg+APlrrVYrx11eCqynfB4Zd/J1S6tfgyt+To2SFnj176v79+5/sKguCIJxRrFy5cpfWOpHFDAVBSDLiYC8IpwjDF6TG+H5AKVUKhgT2geEcAYbwK4JtTQQ3+vfvj5KSkpNWV0EQhDMRpZQ/2XUQBCExxAxMEJKAUqo/gMvBCDa9Tad24zMzwjk/UUqVKKVKdu7ceaqqKgiCIAiCkDREWBGEU4ziqvdzAYzXWu+P9zyt9V+01kO11kN79RIrBkEQBEEQznxEWBGEU4gRP30ugDe11uZKyjsMfxbTryWQrPoJgiAIgiCcToiwIginCKWUAjALQKnW+n9tu/4OYJTxfRSA+ae6boIgCIIgCKcj4mAvCKeO/wJwD4C1SqnVxrapAH4H4D2l1FgA1QBGJql+giAIgiAIpxUirAjCKUJrvQRcVdqN609FHYKNQQRqGlF/zIOM9CAy+6TCkyoKVkEQBEEQTk9EWBGENkKwMYi1XwbhG5EOvx/weoF5+UH0ztLweBQyMwFPNLklGAQCAaC+HsjIQOwTBEEQBEEQTgyZaQhCGyFQ0wjfiFT4jVUG/H5g+AgPli9XyMkB1q6lPOJKMMgDcnKA/v0R+wRBEARBEIQTR4QVQWgj1B/zHBdUTPx+oHt3fvp8VJy4EgjwALukE/UEQRAEQRCEE0eEFUFoI2SkB+H1hm7zeoG6On73+2nh5Up9PVwlnYgnCIIgCIIgnDgirAhCGyGzTyrm5zceF1i8XmDWLGDGDOt3RkaEkzMy4CrpRDxBEARBEAThxBEHe0FoI3hSPRhyGbBs8THUN3jQqFMwcaLC8uWUO+bPp8+8K5mZPMA0BYt5giAIgiAIwomjtNbJroMgCAkydOhQXVJSckJ5JBzcS6KBCYLQylFKrdRaD012PQRBiB+ZaQiCEBsRVARBEARBSAIy2xCENkhjI7BmTYRIxMEgUFtLc6/aWh4sYYsFQRAEQUgCIqwIQhsjGDTWWBnuFolYhwsm5k4JWywIgiAIwilGhBVBaGPs3g00NESIRHy4Cdi2DcjKsjaaWpawg+tDNTCiaREEQRAEoYURYUUQ2hCNDUHs36+RkuIeibixQSP4l5eBmTOBkhIgPx84fDjCwY1iGiYIgiAIwklFhBVBaCMEG4NYuxa4/nqFe+4BZs9G2JorEyenITDql8DIkUB1NTBhAnDWWcDf/hZ68Lx5wMSJYhomCIIgCMJJRdZZEYQ2QqCmEcNHpMPvp2wxZQrw4ovAgAFASgpw773A8uXA8xP68IDu3fk5ciSwYgWwbJkVDSwY5DordmRFe0EQBEEQWhjRrAhCG6H+mCfE9WT5cuDWW4G6OmDdOhxfHDKjroZf6up4oN9PU7CsLG7PymLYYlnRXhAEQRCEk4wIK4LQRshID7rKFz17AjNmGIvSz9qJzLzf0yZsxgzrIKcQYq5obzcNkxXtBUEQBEFoYWQFe0FohTRnBftgYxDba4JoaExFUxNNv1JSGB2sUyeNzu0bkenZBc+Rw/RHMYWR+fOBIUPCF4GUhSIFQWhlyAr2gtD6kJmFILQRmrQHOwIpuPZa4IILgGuvBXbt0uiT1YQBH72IrN3r4cnsBXTsCPzv/wJVVfRVcRNUAG5zmoYJgiAIgiC0IDK7EIQ2Qk0NcNttKiSA14gRCqu+SMG6b/4YwTfeshaEHDgQuOYaYPv25FZaEARBEIQ2jQgrgtBGiLQQZMeOgG9kBgKjfxVpWftTX1lBEARBEARI6GJBaDOkplL2GDWKUYnr6oC8PH76/UB9WqfIK9ULgiAIgiAkAdGsCEIboUsX4OmnrcBeGRnAU08BH3xgBPzyNFCaseP10hdFVqYXBEEQBCEJiLAiCG2Eo0c1duwAHnwQGDaMn4EAMHo0kP9+ED1f+i3w7LPhy9qPG0dfFhFYBEEQBEE4xYgZmCC0EerrKZjYXVJGjwaKioDx4z14adT3kJWaCixeDFRXU5J5+GGuFrl6NVewz8pKahsEQRAEQWhbiLAiCG2EpiZ3l5SmJi6l8vwvzwEy0ijVXHll+IHiuyIIgiAIwilGzMAEoY2QlgbXFezT0qhdSe/fF/7DPVGrshD0fT/8wA4dgNpaCi61te5mYcFg7GMEQRAEQRDiRIQVQWgjKMXoX3aXlLw8bh81CijbmIIf/igVOVdnYO2jcyyBxesFPv6Ya67k5AD9+/PT6ccSDFrrtEQ6RhAEQRAEIQGU1jrZdRAEIUGGDh2qS0pKEjqnulrjF79QYaGLc3OBO++kIiQ3FxgxgvLJssXHkBWsscKH5eSE2pF5vaF+LLW1sY8RBEFIIkqplVrrocmuhyAI8SM+K4LQRkhLAyZOBO65h/KE1wu8/jqFlsmTKaR0785j/X6g/pgCBpzD0MV+f+w1WOrrZZ0WQRAEQRBaFBFWBKGN0NgIdOsGfPSRtXRKUxPQqRNXt/d6KbgAtnVXqrbQV6VDB250ak1MrQvA77GOEQRBEARBSADxWRGEU4hS6lWlVEAp9ZVtW3el1L+UUpuMz24no+yUFGDnTuDmm4HBg/m5cyeQng5kZgJz5gAzZlC+mD97NzLryoA1a4CKCmD/fuDTT0MdXubP54kmmZncFu0YQRAEQRCEBBCfFUE4hSilrgZwEMBftdaXGtueAVCntf6dUurXALpprSdHy6c5PitVVRrjx4f7rDz3HLUuHdPrcaxyOzIO1SEzKwWe9FSut9KxI3DoEHDeeUDXrsDhw5Rw+vQBUh3K2WCQ67PU11OjkplJNY4gCMJpgPisCELrQ8zABOEUorVepJTq79jsAzDM+J4HoAhAVGGlOaSkcDH6sWMtn5VZs7i9shK48MJ0nNNpDzzeHlS57NzDZe7Ng2fPBnbtAq66ytKaDBkSKox4POJMLwiCIAhCiyGvPAUh+fTWWtcAgPHpajellPqJUqpEKVWyc+fOhAsJBi1BBeDn2LHcPno00NCgENihGcu4e3f35e779eOiLLm5wGOPUYsiCIIgCIJwkhBhRRBaCVrrv2ith2qth/bq1Svh8yOtYB8MWp/BIf9BVYu50SCYnYPa3LfgbzobtXVpCOb9lWqa02kNFVmQUq79B0IAACAASURBVBAEQRDOOERYEYTks0Mp1QcAjM+Toq5ITXVfwT4lBZg0iQqVjA4pqG3oAX/wHNQWlCCYnYNgdg7WPvV35Ez4FvpfkIacCd/C2nF/QfCfC+js0hzhoKUFC1mQUhAEQRDOSERYEYTk83cAo4zvowDMPxmFpKTQ7cQerGv2bEBr4Gc/ozvK4cMKOde2R//B7ZDz4BVYO/0D7J7+Z/jG9gqxCPON7YXAj6cAV19N4eCBB+j4Eo/wcTIEi0AA8PlCzdZ8PjFTEwRBEIRWjggrgnAKUUq9DWApgEFKqa1KqbEAfgfg20qpTQC+bfxucY4eBaZMobuJ6XYyZQqDezU2AiNH8nPuXGDdOuDvfwfSs3rggHcIcnOB7GwrL78fqN91gF+ys2kSdv314cKHmwbFLlhkZ7MiBw8C27ZZAkuimhdZkFIQBEEQzkhEWBGEU4jW+k6tdR+tdZrW+myt9Syt9W6t9fVa6wuMz7qTUXZaGuf9M2YwbHH37sCjj1prPmZlUSY4eBCYOtVak2XgQIUJE4CnnrIEFq8XyOjWgRsmT6anflYWkJ/PeMjbtgF794ZrUNassfxhsrOZ6YQJwJVXMsrY2rWUmBLVvJgLUtqRBSkFQRAEofWjtZYkSVIrS1dccYVOlL17g3rdOq0XLdLa69Ua4OfKlVqXl2u9eLHWGzZwW36+dYyZ7NtXLwzoJt/3tV64UOulS7XOzuZ3e8arVmnt84VnUlkZvZDqavftNTWRG9fUpPXq1aHlr17N7YIgCAYASvRpMIZLkiQp/iSLQgpCK6Q5i0L6/RoHDig88gjCFob83/+lEiIYBM49l2Ziw4aF51FertEx9RgyU3bDs28PtSd9+wKlpdaaLCamU8zevVZhM2YAM2fS2//wYWpUwgsBzj8/fHtVVbj2xI4sSCkIQgxkUUhBaH3IopCC0EZIT6fMkJtLS6vGRm6fOpWyg1Kc5/t8lCu83nDZIz0liMxpP4Nn9H3A2WcD7dpx5yWXhPuMZGUBXbpY67WYwsvBg8CgQYyl7FaIGbbMuT2SSZdTSDnnHBFSBEEQBOEMQZ7ogtBG0BrYt48Kim9/G7j4YmpY0tKAjh0pOwDAH/8I/PvfXN3eHjls1ixg3PgUrP3ZSwj2OwcYP54akGuvZSixSZPos1JUxM8//AG47bbwhSU9HuDIEaBPH2D+/NBC5swBXn89PGzZ/PnUlDiRkMWCIAiCcEYjZmCC0AppjhlYVZXG+vXK1Vpr4ULKGqbsMG8e0LMn5/x79jAq8YwZwPLl3L/sxZXIytgLPPwwN/p89NYfMcLSosybB7zwAvDqq8CYMcDEiYyf3K4dcOgQ0LkzK3DsGAvauhV4/nlGFnvrLQo6gwfT+z+SSVdtLQUUZ4OWLaNmRxAEwYaYgQlC60M0K4LQRtCaGhS3CL87dlDLYv4ePhwoKQGuuQbYvdsSVMz99R27MwLYq69Sk/L005agYs9kyhTglVf4uWcPsH498NBDrEwgwAhg559PVY8ZrnjsWOC73wVuvZXCTVZWZLMuCVksCIIgCGc0IqwIQhvB46FSwy3CbyBAfxYTv5+//X7KDpMnhx6fcewgd3o83Llnj7vQ0NQE3HgjcMMNdKafMIGak127wk3EzILMwr1eOtY0J2RxenriHSQIgiAIwmmHCCuC0Ebo0oWWV3PmhPui5OXRqd7E67V++/3ARRdxWRSvl+4o7byZ/OHxAG+/DfTu7S40VFRwNUqnUJKZ6S7cmELKoUOs2MSJVO1EWiAyJYU+LvYGzZ7NMhNZVFIQBEEQhNMSEVYEoY2wfz8jfykFfPIJsHkzP//5T7qb5OXxOFOAmTHD+r15M/CnP1EOmDYNqDyUieCH/wR+9St67E+fTinGKQVNm2aFHTPx+62IX3ZMIeX99+n9//DDFDS2bo3sQH/4MPN/8UWao+XmAm+8wTqJ070gCIIgtHrEwV4QWiHNcbDfskVj82aFUaNCIwn36QN06kS/lS5dOKefPNlytp81y5IbcnPpmuL1Ass+O4qswFquQv/008zkq6/oGGOuqVJbSynIvmiL1wssWgRs2QLcdVeoQ36XLsCBAzTjGjOGUpRbRADTgb62ltob+3ot+fk0NxOne0EQHIiDvSC0PkSzIghthGAQxwUVwIokvHkz5YPqavq9v/IK8PvfA5s2AS+/bAX8Mq20zHOP+7BPncqIXj/4Ae3MRo2iRFNbC8ydy1UmfT4eawolSrGQ3FxgyRKGI+vRg2Zfl1/OPPPygAsvjO5An5lJAcSupTGdbSKdIwiCIAhCq0EWhRSENkJTk/scvmNHrrVy6aXUrtx/P4896yzgnXcoqGRnU8mRmUnFRV4e4MlIQ7C+AZ72GUDXrsBzzwG9egGffgo0NiK4YycCdWmoP5qKjD+8gcynt8KTlsLM582jNiY1lYXX1wMNDYwUVltLJ/ybbqIw4/UimNUHgcnPor57H2QcqkOmJwWeYJA+M6YANHw4BZfMTApAgUBovOWMjNa1yn1rquvphPSbIAjCGYWYgQlCK6Q5ZmDV1RpXX63CrKNefJHzugkTgDffBPr25ffp0+m/vnMnrbJGjrQstubOpebl8oH70LVnOup37UfG3gBS2qfhcO8B6LC/BtsPdoVvVLfj58yfU48hB5fC82EBcOedoWuy5OVRMHnkEap3du6kFHXsGIJ9+mLtziz4Rvew8np9H4YMboSnVw82JBikI/7WrRRazANnzQJmzgR+8xuubH/gALU3po3b/PnAkCGJT2bjnRA3d+JsLnbp81ltaW5d2xLSb0IMxAxMEFohWmtJkiS1snTFFVfoRNmxI6hXrtTa69Ua4OeiRVqXlmo9Zoy1rbJS68JCrYuLQ4/LzuZvc1tVFbfb8yss5HEFBdZ2+zk1a2q13rTJfWdZmdaTJmm9alVIpjUb97nnVXUktIE1Ne75rluntc+ndX4+fy9caDXG6+V5idDUpPXq1aENX72a25tznBuR2pJoXdsa0m9CDACU6NNgDJckSVL8STQrgtAKaY5mZft2jW3bFOrr+YI/GKTGpEsX4OBBHlNZyQBadXV0/bjzTsuK6uWXuWSKSXk5cP314X7subk81+5Tb1K1sR7e1O3AeeeF7ywtpVnYDTeEZOpfUo3+V54TnldFI7zn2SxZ/X5W3klREStjfpqVHDHCyKgqPDJZNGprGWEslgN/vMe5Eaktida1rSH9JsRANCuC0PoQvbggtBGOHWPgrvp6Ch0XXQRcdx0d68ePp6DSqROXKHnySbqQTJ/Oc/1+YMAAzvfz82llk5oaPuc2nfDr6twjE2ds+sryM8nOZmZFRUBBAaUmMxMbGYEt7nl5Gln5hgZu7NCB+ZiVNBeGMSsTDFoON5dcYu3PyEisI+vr43Pgj/c4NyItdploXdsa0m+CIAhnHslW7UiSJCnx1BwzsPLyoC4u1nr9elpcrVtH8y+v17KQWryY+9ev13rjRn6axxQU6ONWNStW0GLLNPuyW9zk53NbYaHDAqqoTjcVfqp1eTlTcXHoAatWaV1dzYJsmTb5vq9Xr2oMzatwl27KzuGPkhKt6+vDTa4KC7VevpwmYMuXa11UFLq/uFjrzZvjM8uyE6+p0YmYJJ2ICVlbRvpNiAHEDEySpFaXkl4BSZIkJZ6a67NSUhI6j1uxgsJISQnlgxUrwuf7mzdzXu8mlDiFGFN48Xq1Lltep2uKSnVV6WFdU7ZXN3213t3BxS1Te0aFhbpp63Zds2CNrio/pmsKSiioOB1o3AQDv5+CkV1Qse8vL098InsqfFbM82tq2LaaGplwx4v0mxAFEVYkSWp9SXxWBKEV0hyfFb9f45prwqOBffQR0K4dXUbc1l8sKgL27uXyJ3bWr2egK69XI0U3Acfq0XF/DQ4cy0BGtw7InPpjeB79DU1w/H73zO2+I4DlV+LzMRTy0aM8PyODldizJ3QBSJPycuD888O3V1UxClhVFTBwYPj+0lKu79Krl7UtnghejY1ATQ1t69LTubJmqkskeAmjKwinFeKzIgitD3lqCkIbobGRPiamm0h+Pn+npXGNxoED3V0stm3jnDs729ru9dLHZdgwYNgwhY2bUzFuckf44UXfc1OBTp2x5Q/vobbnJQg+/AjDELtlbq4yaWZaV8eCxo1DcPwE1JbWwb89FbWHuyDYvoMpHYXm4/UyxnIkXwWPh/4sbvs3b2a44+3b6RDf2MjQtzk5dNTOyeHvYNA6LxgE1q0DrrqKAtJVV/H3zp1sU22tdbzHYy1amZVlCSrBII9zHi9I3wiCIAihJFu1I0mSpMRTc8zAtm0LhvmRFBZqXVtLi5ny8jB3kRDLrKIiHdWCa/Nmrb/6SutVq4Khlk8r6nVTpd/dDGvDBmZcUEC/kuxsrfPz6aeyMBCaz6pG3fT8TB0Wf3nhQteQx3rVKq0DAaZt28L3FxVZpmZmeOPy8th+JoEA61tUZDno2O3hzHwimSGJX0VkpG+EkwzEDEySpFaXRLMiCG2ExkZg9GhLweH3A88/T6XCNddQSfDgg4wAZgbKmjuXK9lnZQFnn01tSlER0L49MHmypW3x+5nPxo3A8OEqpAzf7ekIbNoLzJ5taTfMzAMBq4KmGdWAAQg8/Qp8Y3uF5jM8BQHf/UC3bjQfKykBPvyQWptvfYsmVi+/DJSVcaXLn/4U+PrXaQK2axdNvRYu5GqWn30GDBpEU7OsLJqXTZgA7N8fOYJXMEjtya5d1r6MDOCPf2QeHTse1wrh+usja2YCAWvRwuON84X2RVtF+kYQBEFwIMKKILQRGhrC5+GjRlkLvgP8HD0aeOcdzuu7d6flUl4ezcXS0mgWVlPDbU89ZQk2gQCPd53r9x/EH3l59C9ZtIgT+Lvvpi3ZX/7Cyf5bbwGdO6P+UKN7Po0pPO/yy+kn0r49V6XPy2MFzj8fuOkm4NZbeVJuLv1KMjJY6RtuAC64gNJZaSnNx2bO5DG5uUDnzpHNydauBTZsoGnSgw+y3g8+CBw6BPzhD6zPq68CY8dGn2wfPuzeSYcPiwnUiYR7FgRBEM5IRFgRhDZCWhowaRLdK8rKKDNcdhnn+eayJADnhsEg5/EeDwWawYOBq6+m5mTiRCohxo3jPP/114GPPwY++CDy+iqN2oNgWgbQuzczTkmxBIQxY5jZTTfRceb665HRJcNdZtiwhgLJsGGUmg4dAv70J1boiSfofPPhh8Arr7ByEybQIf+mm7jypbkwjCmV7dzJ1NjIhk6aBMyaZa0DU1AA/OtfrOsbb1B741RPjR4N9OsH3HsvNTSxJtuR/Gs8HqquHnggslbmTEfWSREEQRAcSDQwQWiFNCca2IEDGhs3Ktx2G+fs06db826vl3P0hx/mC/1PPqFwozWVAuPGha9k7/XSsqtfP873e/fmnDIQwPEyHn2UssWePcB5DWXoddVF1olvvMEDL7yQE/KjR2kKduQIgkfqsbbdUPhuTz9ev/mzd2PIlO/Cs3wZG+T1Uv3T1ETTrG7dgCNHmOfChdSixIo+VlHBRm7dSif8b3yDQsr06dSy3H671UEFBVw1s6qKUtmMGewUgFqaiy6i1DdhAhs/eTJVTYcO0RytVy+2c8cOSov2zp89G5gyhefNmMEOM9VXL70Ue8X7M4VgkAKaaQrm9QLz5wNDhkgUNaFFkGhggtD6cIm1KQjCmUhdHefxfj/NvOrqOBeuq6NWpL4eeO01CikvvUQ3kLw8Wji9+SaFmIkTgfPOYxAtgHPqG2+05pX5+cx79uzwuX5+/iCgcA26vTETe7oMwOHfvIymow3oULkRmX96FJ5xP6c2ZNw4eGbOxJCnpmPZyw2o79ANGX17IPPNP8Pz6ixqJpqagGef5edNN1mFzJnDif2BA9yWnW0JDXV1wLnnsuLZ2ZSktGZ+gwbRTs58q9+7NxuXm0vhAaAUduut7tLdli08ZsYM4L33KKDYhZF584CuXSnUPPYYMHUq/WoGDKA2ZcoUnm9qmMzz8vKia1ZOJDSy89yePSn0JTPMssdDwWTZMgn3LAiCIAAQzYogtEqao1mpqNC46y6FZ5/l/G/TJmDaNM7tH3kkVLDIy6NG5OBBKh+mTeOc/P33qcBobOQ8f/Nm+sl/97uWEmHQIKC6OtRaCmC+L74IDOivsWu3wj332Obyc4M4+8hG9GiohWf0fVTtbN1KtU1KCjPYvTu0ku+/T01HaakljOTl0Wm+qYnnHD0aKmDMmUNJ7O67GV1g1Ch2hqkWqq+n4OFUOQWDwP33uzeof3+utdLQwDp3726pluzalUsvZRt++lOeP3kycPHFtLEDLK2Ms4zFiylBOifvJ6KFcJ7r81F4GzEidl6ydozQihHNiiC0QpIdjkySJEmJp5YKXbxwodYLFrhH67WvTL9iBcMV+3xaV1aGRv1dsYLbzWNLSrhw/NKlVmRfM9+lS7Vevz5yeatXNuim4hJm4gxD7PMdD218PNyx3x/eoC++4HEFBVqXlbHQBQusc7ZvZ14LF4aXsX27e+U2bQrdZqbq6vBQyqtWaT1mTHj+JSUMZ7xihdbFxVovWcJ8zXjRZmxoZyovZ6d/8QVDNG/erHVFBfOKFWZZa60bGljP6mr2V0UF81u82PpzzPjUsfKS0MJCKwcSuliSpFaXRLMiCK2Q5mhWtmzRGDdOYdSoUEXE9Ol8we/EXEwesJQIGRkMplVdTQ3LvHnA175Ga6ayMlpB1dYC775L/3DTNKxbNyo5unal1ZPbIvRFRVR0LPtoD7Juvjxcw/Dmm9RgjBxpvf2fO5fhhj0eOsG3b2+ZctXX0wfG4wF+8QtqCswK7dtnaVbsnfH739OHxklVFSMTdOxo+avU1gIffQTcfHN4XYuKgPHjWaZz+5/+BPzoR1YYNq+XUQqcsaXNcxYsoK3dnDlAjx7UGinFttXWshzTdwagKqx/f7a7sZEqtN272TemHaDpJ5OZybzS0/nHOrHnBbC8nJzwOi5b1nb8aoRWjWhWBKEVkmxpSZIkSUwAvgNgA4ByAL+OdmxzNCvV1UFdUsIX6pWVfEFfXs6X7faX7PbFIO0v2ouKuH39empZuABkuGIjO5trPZr52ReWLCnRes0a95f4Cxbwe9XGo8d3NGXn6Jr8z3VV0WZdU3lEN/m+H37i+vWWmqe4WOt//zt85UtzwUn7CpZO7c2SJewYW+WasnN0TVGprtp4VNcUlOim7Bwrz3XrqLlx04YsWcJUWBi6eOSmTVpv2eLeAX4/O9Xc5/Px+PJyllVTE97hhYVsh71tBQU8bvduLoZZWMhtkdRZZWXR99s1J1VV7u01NT1ui2C2FE1NzP9klyOcvrTANQDRrEiS1OqSGBoLwmmAUioFwJ8A3AzgYgB3KqVc9B3NJzWV7gYZGdRuXHst/VKuvpozzpkzrTVTZs+2/MoBbqur4wv19HS+aDeXLrFHAx47lq4P5eV0yTC3DxxIX3VTuzJnTuj6kLNns35eL6DT0lGzrAp1xZuw5oUlyJnwLfQfNgA5w9ph7bi/IJidY1XM72fFnnqKCzF26sRG5uayMWZo4V27QisUDFp+Jfn51Krs28dG5ecDXi+C2TlYO/0D5IwajP4XZiDnwSuw9qm/I5jVh3lu20bNg1uo3UAAuOsuRicbNoy+KNOnM+JYpLVEtmzhvjfeANasYUfecAP/pFtuoQOR26I4O3YAf/0rfVvMxXFqarhuS0MDj+nY0b3Mjh3ZN9OmWSGbzTbMmsXtPh/bal48bu0tKwsNt9zYGP96MfGsLWP62OTktN2wzm0duQYEoe2SbGlJkiRJGgC+CeBj2+8pAKZEOr45mpXKyqAuKIj+En3jRr7MX7cu9AX+ihV0w/B6Q10l7NoUM6+yMssFw/zcuNFyzTCVGE6lg7nNPGbTpghuFPmfh27Iz9dNvu/rmsrDumpJta7J/5waGHvFioosnxBTs2JWzulvUlKidXm5rik/EL18U6Ph5ghkL9d+clERNSVuGZvqp82b3f1Rlizhp91vJz+f9SgpCa9HSQn9XKL5pBQUWCo0UyVm/1PsfjNbt2pdXx/us2L+aeaxPl+4BiiSX0s0Hxj7W/Tq6vh8apKJaH5OLjU1LXINQDQrkiS1upT0CkiSJEkDwO0AXrH9vgfAC5GOb46wUl4eDJmzO5O5b9Mmzjft82Gfj/PahQtpKeU2z7ZbU5lz2EjzeKeZmdfLfJcs4f7s7MgWVlVLqkMybBozVq9eGAid7y4MUGAxJ+nmpNycxJtRAtwmP0VFWq9fr6vKjriXX7TZkqbMypqVt0/y7bZt9k52m8zbBZwlS9wbb/4RTsf94uLIApApdWZnu59XUWFFR4gl1Jimb0eP0mStvJwT8zFjwusZ76Qy0gQ0EAgVYkxBLezPqEr4PjgpSOCBk08kE8QErwERViRJan0p6RWQJEmSBoCRLsLKTMcxPwFQAqDk3HPP1Yni98fWrJjaFbc5wfr1nNeuWxe+z5z3L1pE/5eVK8PcP8IEG3P+6fNZQbsKCph/cXHketZsPhQiGNTkfx5ZA2Kqa776ikJKQYHlbBMpwldpqdYFBbqmoMQ934ISS+gwBYjSUnfNRnGxe+NLStihbgJOfn6oasuusYikborUlqVLLSHFHiFtwQLmt3Il/XnsfjIrVkSWMM0/1+lXs2ED812zhn98SUm4dsZtUhlpAuq8eBIRgJJBC731F6IgmhVJktpsSnoFJEmSpE+JGdiuXcHjgoBzXr1oEbcvXx66zynMlJQweq5z34YN1sv3TZssyx23eagp2GzezDlpcXG4VdHWre7Rf1eVNOqmMWNDKlm1pPp43nYLqaqNR3XTtu3u0QM2bYosTRnO903ZOXp18dHQl+Ur6nXT4s9ZvilxmVoNZ1jlxYvZYWPG8HdpqSUkmBN55x9hqpbGjKFQVVBg5WcKWZEkyUiSoVkvQwgL64sFC7h/wwZ+jhkT2RxswwarHDdtjSnELVxofZqCTiKaldLS0G1uZZ1Omot43/qLqVjzaSHtlQgrkiS1vpT0CkiSJEkDQCqAzQAGAEgHsAbAJZGOb240MJ+P82MzGlhZGedNW7dargdu88KVKzkn37AhuouGqSgwz7FbGDmFnjFjWAe3uWplpTWvts//A+V7WYmtW4/brdWs2xXR0mn1qkZG8HJOIouLacrkbExhIYUMY/LfVLLSikaW/7mVlz00WiR7tUgmX6YDkDkJr6yk8GQ3yTKdeOznff45y3LrsAULwtuyciV9Vkztz4YN7vU0o4EtXmxti6TJsAsRkY4xt9tN8KL5rLiZxLkt/uPzUQI+HSf68bz1F1OxE0eigUmS1CZT0isgSZIkJgC3ANgIoALAw9GObY6wUlERDPPNzs6m2ZdTW+LzcXtRkRWG2KZ00H6/uwWT6Vxv/x2iGVnFPCZN4pzU79eu8+fycpYfcm7xMfqhlJVxYm9Mzpuyc/Tqwl2RzcYKSsI3btjAie/69aHaCzPE8YYNVDdFs5krLrb8X9yksvz86BN687vpTG/XtEQ6r6Qk3Exr5Uq2pbaWddm40epke8dHWvDS7stjtsM0EXOatdkX4Yzm/GT/rKiIPqkMBKz/wLygEnHSPx2IRxARU7HTAhFWJElqfSnpFZAkSVLiqSVWsDd9RTZs4It9+9zWtEayz2XtCoEvvrDmtvn51mLsTz6pQ+Zi5ir29sBV5stzny/yIuym/7uZd3nZMd0waTJPHDPGkoqMzJsKP9UVpfXuljgbj4ZPurdsOR71K2yibJozrVzJyblz0r5+PSteXGxpLVassCb6dnVTJMdwUzOzcCH9PEwzsfJyK8qB23mRoh9s2xa+voxd5WW2yal6ch5j11w0NFDAMSVHc02XWAKVU7MSazIeaaLf0NC6TKZivfVvIQdx4cQQYUWSpNaXkl4BSZIkJZ6aI6z4/cGo7gZm1F5TwWC+XDe3mW4a5nz9ySfD/U2cc19nxC+7QiE/n3NS59qMK1dqvaXiiA4UrtFVS7fpmnW7dNMXq0M1GC4aj4gO8ZVHQm3enAsvumkqli611E52iczvdzdbMs2sTJOqWPGXTf8QM8xaYSE7dc0amkBFkuIiRT+IFg7Z/F1RQaGmstIq3+6P4pw4u5lolZbynAUL2KfOC8DpsxKvNqQt+HKIZuW0QIQVSZJaX0p6BSRJkpR4am7oYnOOFI91UmVlqKbEHvHL9F+J9mI9krLBPNY0I5s0iXNUMxLurl1Bdz8T03O/vJwSjmONlKblxXp1UV3oC/qVDbqpZgeFjI0b3Z3qfb7IoYcLCkKPjWQWlp/Pevn9nMRv3MiIXq+8Ei4M2ReTWbWKAsS2bdQYmRqT8nJ2tP28zz8PNcOyl19eHt5f5p/mnBQ3NcW3bonb5NreftNsbeNGCkLV1WyH+XmmCh3NRXxWTgtEWJEkqfWlpFdAkiRJiacT0axkZ/MlfrS5rV2YsCsD7G4dkVwWNmygTLFjB+ewkYJQlZXp4w7/5ty9pETrwNajx31Rjju3F5QwCteCBVbB5ht+s2LZ2VwcsmyPriqu1TWbDzNy2JIlVsSrSM7wGzaECxUrVoRrHiI12tS6VFSEq4qWL7ecf/x+TuQrKkIn84GADrPRc0YDW7eO25z1XL068lt7e7SDhgbrYohn4uxmtpSdHd6+kzXhPhO1LWdim1oZIqxIktT6UmozF74XBKGV0a4d8OGHwI4dQGUl4PUCfr+13+sF6uqs74EA0L07v8+Zw/MB4Be/AJYv57FueXg8QEoKz9+7Fzj7bCArC6ittY7Jz+fsd8YMYPt2fh46BGRmavTw7EHwnx9jbU1P+Eb3gN8PeL0DMD9vD4Z0r4Sn2s9Mli8HbrwRKCkB6uuBGTPgqatD1qjvcN/SpcAnC4Hv3sqGjBgBFBS4VzolhZUsKgK2bWPlDxywKm1y6JD7+T17AkoB7duzoxYtAhoagGPHnHfPawAAIABJREFUgMOHeV5TE9C3L5DqMuw2NQGjR1v5zp/Pz5kzgaNHgU2bgDFjWJ/33gPy8phX585AZqZ1js8Ho8P4p3k8QG4uMG0a8NJLbCPA7UOGAMuWse8yMpiPx2PVKSMjvK21tTwu2nktQTAIrF0b2p7581nnli7rVOLxWP+BIAiCEB/JlpYkSZKUeGqOZmXr1uBxyyk3nxW7hsN0OaistFwrFiwIPcfN3WPFCpp1Odc0NNcIdC7dYfqfe72M9mU60deUH3C3UlpfF/52P1rELrMhpoZh+fJw86riYqbSUq2ff97yw3BbB6W4OLzRxcVs9MaNNIFqamIy/VdMzUhZWeQ36dGcr93aZpZjx3xrX14e2x8lHty0L6tWhWpoThbi3yGcJCCaFUmSWl1SWutky0uCICTI0KFDdUlJSULnVFRobN2qMGwYf2dnA5MnW9qTlBQqAqqrgeefBx56iMeNHk1NyLRpfLH+6KPABRdQiZCeTsVBUxMVBi+8ANxxB9CxI3DRRVY5r74K3HJLuEJi8acNCG6vRUZgCzJnTIRn+TLA64X/41L0H9w+rA1VG47Cq/0suLSUBQWDfGM9apT1Fn7uXGD/fjbksceAbt1Y0dmzgR/8gCqfDh2oEXnmGeCTT4B332W+TzzBvDIzqb0IBIAePYCNG9kJl1wCTJkCNDay3ECAGoZx49hB8+YBvXsD3/pWeIOXLXN/s15bC+TkhB9fWAgMHBh+/MaN3O7xsP2BgKXpANzzilR2NJx5nwwtiht+P9C/f/j2qiq2RRCaiVJqpdZ6aLLrIQhC/LRifbogCImQkmJZMQG0lBoxgvPy9euBc88Frr8e6NoV+M1vOK/t0oVWRD168LhnnwUuvBD46CPg4EGgogIYNgw4/3zgmmuAO+8E3nmHllBeLwWVp54Cpk4FZs2yyvZ6gfl5e9Bv33p4rzwXWSP+i4IKAPj9xy2Q7Hi9QIY+SiFhwgROnkeNAq67jpX8+GOafr38MgWVTp1Y4SeeAAYMoLR05520S+venZPwUaMoSfn9fH/fvj3whz9wUh4IsJzDh4F9+4Bbb2WnrVtHU7HvfAcYNAi4+24eY9Qdw4ezc+zCgrmvvt79z8nMpJlTSAfNp0Dl1hGbNrF+prlUTg4n9zk5rKtbXqa5WCKYZkteLz9PlQlWxAsg49SULwiCIJw+JFu1I0mSpMRTc83ASkvDLZsWLQp3fq+spKXRmDHW79JSmoKZx0YLjPXll1qvWhUMCx5lRgCurmrSTRWbIy5U2FT4qV69siHUj3thgItCVlYyrVljhc9dsiQ0opfPFzlssBkq2M3jv7CQeZr5LljAT3tDYoVSAxjBIFEzJjfn60grvGdnW8e5lRMItG5HbomcJZwkIGZgkiS1uiRmYILQCmmOGVhNjUZ6usLhw/TZbmyk1dNdd1FhYGfjRr68Nx3mu3ShQsJOURGOm5TZWbKEVlCdO2vs2aOOm4PZqVq6Hd661VTJZGTQ5szUBsyZA7z3HoK33IpAv8tRv3M/Mrp1QObUH8Mz7ud0On/mGTrXZ2Xx98GDloO61wu8/z4rPWhQeOFFRdSovPgitSVeL9U+M2dSk9K/P+tyzjnURpx7Luu4bRu1Jnl57g03O8TrpXbH4wHGjnV3EG9sBGpqaHeXng706ePueA8AO3cCK1bQ5K2ujtEIamstJ/cz1VwqWSZowhmNmIEJQutDooEJQhuhsZFz4y1baCXVsSPQq1d4wCuvF/jqK87bZ8/mfL+pKTwwVKTAWFlZDDy1eLFCXp77MRndOgB3PGhN5PPzgccfZ5iyp54CHnkEnnffRda1h5nhMQ8w6l4KFOPGccKem0tzrt69gZEjrUL8fuD222kWFinkmd9P07CiIv5+6y0KMP368bi772Y0MPskuWdP4LPPOHmOlK8p+Dz8MLe/+CIweDDNucx8GhuBL7+kDZ69/Zdd5i6w9OjBejkjY5mmaq4dfAaYS0nkLEEQBAEQMzBJklpjau46K1VVXO7DjMo1Zkx4VDDnKvSmdZXzOHNtRvu2khIG1DItksaMCV/kfHXxUZpzRTOj8nppxlVYyEhb5eVcm6SoiNvMBpjmXm6RtEpKwm3ezMbZF3x0C422apW7yVFNDevjjAhWUsKFZcrLQ1fCdDNdirQgY3V15D8v0vocYi4lCAkBMQOTJKnVJTEDEwQHSqkBWuvKWNuSSXPMwOrqNPx+heHDrRf0s2ZRqXDbbdSg1NYCEyeGmoWVl/Ml95tvMhBW9+7UqlxyCa23Ro3itro6WkiNGkWlgUl2NvDuX48CTU3IqCxDZm8Fz9ArwivotCurqGBUgMZGIC0N2L2b6qDycis02dy53P/DH4ZrF158kaqjY8f4aT8vL4/ajpEjqaGZMCG+6FnBILU/EyeGN/yllyxtRzTTpYoKmr85KS93j/wVCzGXEoS4ETMwQWh9yBNNEMKZ67Lt/VNeixbmwAEcF1QAfo4dS0GlTx9G93X6r3i9wObNwLXXMvjVBx9wjp6Vxbnx/PkUTIYN4+f8+QxZXFREy6bsbMoGGetWwTv6emRl7IVnR617pCdzRUrzd0MDQ4zddRcn+MOHU6J68EGaimVlsfJmSGJ79Ku5c4GLL6YvC8DFEwcNYnSw3FwmgL4lF18cf+Quj4emWm4Nr68Pj54FsAP8fn4Gg/RRcWt/enqc/6RLnZIRsUsQBEEQTgXJVu1IknS6JACDAdwGoALACFu6D8C6ZNfPnppjBlZeHnS1liovpwWTaWVltygqKgo3Cdu4kdsWLIgcbMu+0GRZyT7dlJ3DjT6f1lu3ar1yZfhqknbzqeJi63es6FtmJe32bdnZ/O6MkFVeTpu2DRt4THZ2+AqWzshdThOseBcsjGSidexYePtXrjw1iy0KQhsHYgYmSVKrS+JgLwgWgwB8F8BZAP7btv0AgPuTUqMWJDXV3Rd7wwYqFw4ftpQOl1zC5UQmT7Y0LX4/LarMF/ldu1KhYQ/C9frrwC9/aR0/ejSwLG/78cUeMXEi1wHp14/O6nv2UKPg8QDPPcc1Ttau5e/585lR9+7umg9zNcu6Omot1q2z7M+8Xmox8vMtU62jR7mQjN/P7VlZdNafPZvRw26/PdThvUcPRuLauhUhtnMff8y6uTm82wkErGPMOvt8NC+77DJg8eL4ooEJgiAIQlsm2dKSJEmnWwLwzWTXIVZqjmalujoY5hdu+puXl1NrUlVFDUtlpbvyoLKS/uWmMsJcO6WoyFq+xKm5qSo/RnVMUZHWy5dTY7JgAT+dHvplZZbWJNa6JgUFbIDPR82EUzPjVBOtWmWpibKzQ8vy+ayGmL/LyyMvJhPPOiZVVeGdAXC7IAhJAaJZkSSp1SVxsBcEB0qpCwH8H4DeWutLlVKXAfie1vq3Sa7acZrjYF9VpbF1qzoetti+ZMeiRYwKfOONwP33A4WF3G9XNsydy7VWsrKir7Fy5ZXWb68XWPbiSmR1PEg1TW2tFXK4ri7csd3nAx57jKvOjxtHp5qsLGD69FAVzty5wFlnAXv3AtXVwNCh1EwcO8Y4yykp9Hdxc7q/9Vb+LinhedEa09jovi+edUxqa7mifDyO+4IgnBLEwV4QWh/iiSkI4bwMYAqABgDQWn8J4I6k1qgFSEtjsKj27a2IXbW1wLx5QLt2wJ13Au+8w7n1dddZQsmmTbTY6t+fllT2JUXseL1A3z46xM99/qydyJz2cxb45JMUVC6+mNG5zj033Lxr/nxAKR7fowfw6aeMsnXBBYy4tWkTBY6f/YwRtYYOpcBTVsb00EPAmjWsaG4uPfxN/H7mY1awQ4fojQkEIu/zeGhmFo3MTGuhy+Md4mIuJgiCIAhCRERYEYRwOmitix3bGpNSkxbEDBKVlgYsWACUlgILFwJ9+3KRyBEjgO9+l8f4/QxPfMcdwA030B3kwAHghRfo3pGXx7DH9nn47NlA/dEmrFhyFFVFlViW+28Mefh79Ffx+ymcTJjARRJvuYWTfZ8vtJJeL0MDjxgBXH45w5BVVrIyw4YBu3ZR4jJXsjS1LKmpwPPPUxtjljFhAqOGmQKL10upbNkyakY6dWIj3Bozbx63z5gRvm/WLJazdm10gcXj4Yr1ZnnLllkr2AuCIAiCEBfi0SkI4exSSg0EoAFAKXU7gJrkVqnl2L+fllLmCvRdutBqKiuLft4At1dUAI8+Stng4YeBN96g/3tdHfD001RM2H3kx4wBamtTsezjg/COujbc/KmiItTZfORISkurV4cu/GKu/m4el5nJCptakGnTLFOyQ4f4CVAbM3ZseGxmcx2V2bMp1NhDCs+cyfPOOgv48EPmZ3bEE09QmHr4YeCjj1h2IMDfy5ez3rFMumQVdkEQBEE4IeQVnyCE8zMAfwYwWCm1DcB4AD9NbpVOnMOHaVE1cCDn7PX1nHdv3coAXY8+SsHFlBmmTQMGDOAxtbXAjh3M59VXGS1swACeu3s3BZXly43lSfbXU/1i10bk5zNDO6b6JjeXIcmKiig8OBd66d2bgkZeHnDeeazMiBEUMjIyKIi0b0+hxi1q2MUXs4wpU+jTYpKZSYFkwgSak91yC6Wufv3YQaZW5N13Wc6VV7Jce3g0t7VYBEEQBEFoMUSzIggOtNabAdyglOoIwKO1PpDsOrUEKSlcQ/Gmm0Ln9KtXMxrvwIGcq+fmWgJKWZnl1/LEE6H5eb00IbvzTmv+7vUCGZldgWlTQx3p9+2zTLfsGaSlUWhobOQCjY89FqppmTePPizf+hbzmzkzNF9Ty/HrXwM9e7rHZl6/nkKG10uhw8RupuW2+rtdK1Jb6563PT9BEARBEFocEVYEwYFS6v85fgPAPgArtdark1KpFiA9nQKJm/LB46F52I4d1rx+zhzKEp98Arz9Nt007HLE3LkaOHQAtbVdANgc6jev40mvvmoV4vMxw5EjQyN6TZ1qOaHn5VGL8umn1ICkpACTJln7581jhZwRxLxemm117sxj7GuizJ5NjYp5vtO5PV4zLdNZPtbaKoIgCIIgtCgSulgQHCil3gIwFMA/jE23AlgBrnA/R2v9TLLqZtKc0MWBgMaxYwpffhkeuvijjyjMtGsHbN9O864ZM6i08HqBN98Efv974NlnuVjIsWNAT08det53KwKPvoD6Cy5FhqcBmdUl8HxYAPzwh+Fxjz0eFtzUxO+TJ1sLPwKhoYW9XpqSaU37tbo6OspnZdGx3Sk09O3LCADt2lFLs307f6emsizz/L59m9/pwSB9Vty0MIIgtAokdLEgtD5EWBEEB0qpjwHcprU+aPzuBOB9AMNB7crFyawf0DxhpaZGo7ZWhSkeOnakEqNrV/qsfP65ZWVlCizl5ZQDKiuBbt2A114DJv78KLLqq5n5r35laUDmzKGmY9s2Zpiaysn9D35AAaV7d+6/995Q/xQgdM0Tc7X4UaMoUZnO7HahwQwhvG4dfWJqa9moTp2oCrLbp8n6JoLQ5hFhRRBaH/JaUBDCOReAzRMbDQC8WusjAFqtR3Vjo2UhBfBz9GjgyBGaf6Wn07UkI4MyhRn51+ejPLB+PXD33ZQTxj8URGbNl8zoxhstDYkZ5WvPHpp0paQADQ3AwYNc2HHCBAojN97I3/Z1UMxoXyZ+P0MVP/poqMmVx8Pve/cCV13FBWAefJCVzcpio3bu5HlmvmKyJQiCIAitEhFWBCGctwAsU0o9ppR6DMDnAN42HO7XJ7dqzefYMXd/lawsrtFYXQ1ceGHovH/sWOCZZ2gWlp5uCTgNjQqe3z1Nky5npllZ1HoMGwYMGsQoW/X1XAfFKSnZBYrZs6nKMTEXZhw8OHx9kkDAMgUz8xs7llKW30910eDBsr6JIAiCILRy5OktCDYUvelfA3A/gL2gY/0DWutpWutDWuu7klm/EyE11X0xdoAWU01N/O6c9wOUM0ylh98PBBs18MgjdHh3Zvroo5a/innC8OE057Lj91OYKS8Hli6laZh9sUdzwcYOHcIFjfp6d8mre3eee+iQtUJ9VpYIKoIgCILQSpFoYIJgQ2ut/3979x5lZ1kfevz7m5lkcuOWwBBIwnAJ2opQFIR45GZhFS+njdeWqi2lLl0WKJdqT3WxqiClSqWlq1iPxcaYWjhUSDAWagUpWrUmGBRzk1tKpgQSJxBBMoFJMvOcP553M3sme2aSyczsd9jfz1rvmvf2PO9vvyFk/+a5RcTXU0qnAA/WO57RNGVKHrNePe590aK+ISEDe2DNnNm3wPxnPwtPPpl7bW3ZAlNbe+DSS/PFRYv6FmNsb89rodRKJAZ2w2pvz33Tzj8/t37Mn59nEduyJbec3HRTni+5uTmXrwxqh5x8fP/7+b7qmQC6unILzZFH2u1LkqRXAJMVaU8rIuINKaUf1TuQ0dTbmwfH33tvPn7ssb71VCoz/FZUGkv+/M/z8JLqAflHzt7N4b1bcsGOjlzJjTfm5GDmzJzV1FqTpHodlEqmtH173+KKLS15pcnp02HuXHjjG/Mgmje8oa/Mt74FL73UfzawRYtyYvOpT+VxMpMmwaxZtqZIkvQK4Gxg0gARsR54FdABdAFBbnQ5aT/qfC9wNfCrwGkppVVV1z4BfBDoAS5LKX1ruPpGMhvYk08menqC9evzd/qpU/PaKt3dOY94+9v7vv8vW5ZzjzPO2DPn+N53e5jELrpfSrRuWE/bpy+lacvmvI7Jc8/lGcB6e/uvqXLnnXDrrTnzmTs3t5Z0dubB9xddVHumri1bYMGC/gHcfXceVLNHUN/L3cieeWbfphZ2OmKpoTgbmDTx2LIi7emtY1DnWuBdwD9Un4yI1wAXACcARwLfjohXpZR6RjuA3l74xjdyUrJlSx5Qv2RJHq/yN3+TZw3u7c2r1l98cV5TpVZvrh0vNXP++c1FHnIKy+/8PifOfY4mevumGzv99L7WlqOO6hutv3kzvPWtfUnMV7+aW0tqddmqNS5l+vTaQVWmLx64/spQA+t7e2uv2eJgfEmSSsN/kaUBUkodKaUO4EUgVW37U+fPUkqP1Li0ELgtpdSdUnoCeBw4bX+eNZiDD4Y3vQnOPTe3mFx5Ze7BdeuteahISvAnf5KTmZUrc4NDrQH5Gzb0Hzu/8J3NdPbMyl2vKmutrFyZHzBjRm7xWL8+z4980UX9C//e7+UFXmolB62tewbQ1VU7qKamPWcHW7gwf4jB1JpRbLgykiRpXJmsSANExG9FxGPAE8B3gY3AN8focXOAJ6uONxXnasX14YhYFRGrtm7dus8Pev55ePe7+383f+9787k778y5QfWC8tdfn4eDVHKDyqLyn/50/3rzkJOUE4YTT8xduqqnDH7mmb6R+rVaRboHWbqmra0v+akEcNxxe55bvrxvEP7e1g2Dzyg2VBlJkjSu7AYm7elaYAHw7ZTS6yLizcDvDlcoIr4N1Foi/aqU0vIa5yGPhxmoZitOSulm4GbIY1aGi2egXbtqfzd/9avhgANgx47+4+JXrszj1r/73cSmTUFnJ7zwQt/swhXt7dC6ewf0Ts0Jy8CxJ5WkYNu22gPvW1trB1yd/FSPKYE9z1Wagfa2buhrudmXMpIkaVzZsiLtaVdK6VmgKSKaUkr3AycPVyildF5K6bU1tsESFcgtKfOqjucCT+9f+LXVWhKlvT1PwgXwz/+cZ/uqbrT41Cd7mdO8hRkzEldemWcMG3jP8kVbafvoBwbvPlVJCmo11Qy3snwl+aleL6XWuVqtMMPVPZIykiRpXDkbmDRA0ULyDuAzwKFAJ3BqSulNo1D3d4CPVWYDi4gTgFvJ41SOBO4Djh9ugP1IZgN79tnExo3xclew9nZYuhTmzcsLQh55ZB4X/0//BFu3wuzDE0fNeoFJB82gl6aXJ82aNqmbnnWP0j15Bq3bNtN2/UdpWll0/RqYDfX25jmSn346j1eZPTsvGnn88bk5ZzRn3xrJzF7OBiY1FGcDkyYeu4FJe/opsAO4Eng/cBAwY38qjIh3AjcBhwF3R8RDKaXzU0rrIuJrwHpgN3DJWMwEBtDVFVx7bZ6ka+bM3Cvr2mvzOPijjsr3VLp4dXbC5z4XfPGmKcw+pIkmqnp3bfkFfOg39677VGdnXvRx9uy+B3d15dH+hx02uh+wVhe0sSgjSZLGjS0r0gAR8eOU0usHnFu9P+usjLaRtKxs2JAXiR/oO9/JucPChbmX1lVX5fEqABs3JtrbBwyr2Zcpfzs64Oij93xorVYYSRpjtqxIE48tK1IhIv4IuBg4LiJWV106APhBfaIaPS0ttceTd3XB0UcnvvCF6Jeo5MaSGuP/Bxv4PtT0ww5ilyRJI2DnbKnPrcBvAsuLn5XtlJTSB+oZ2GiYOjWvTF89nnzx4rya/aTYzZzpv3i5G9iwY81rDXKvxUHskiRpP9gNTJqARtIN7Pnnc0PIjh15QH1LSz73yU/CF69/nrbtG+ic2k53125aZx9C25zJozPW3EHskkrCbmDSxGM3MKlBdHXBpk3w27/dN9Tk9tvhxhsTbf/6VZrmzWF224u5peSIWfSSB9zvd46xv4PYTXYkSWpY/osvNYidO/sSFehbwb63F3jnO/K0YGecAeeeS++GJ1izJrFgQR4fv2BBHlPf2zvOQVcG89c9EEmSVA8mK1KD6OnpS1ROPz2PX1myBHp7g2fi0L6Ls2fT2XsoCxdGv8Rm4cLB130cM52dfbOO1TUQSZJUD3YDkxrE5Ml94+Gvuw4++MG+7mDLlrVyyLV/yaS7lsN119G9bTsdHYf0K9/RAd3dCagxQ9hY6e7uP5NYXyDjF4MkSaobkxWpQbS05DEqW7f2JSqQf77rXcF/3v+nHHXCr8AHP0jrjbfS3j5vzxmHm3YBk8cvaKc+liSpodkNTGoQO3fCF78Ir3pVbl1ZtiwvCLlsWT7e1dOcV5jv6KDtri+z/Pbu/jMOL9pKW/Oz4xu0Ux9LktTQbFmRGkRTE9x3H3zoQ/CZz8BFF/V1A1u8GKZNS3DEEbBwIU3v+11OvO4CVtz4p3S3zaP18ENo+4cbaDrhyvEPem8XoJQkSa84rrMiTUAjWWfl5z9PPPVU8MILcOGFe/as+uEdmzjiLy6FG26A887b84b77oNjjjFRkDRhuc6KNPH4rUNqEC++CN//fs47lizJ3b9OPz1f6+iAnS3T4G//FiJqD2pvaTFRkSRJ48pvHlKDaG6Gs8+G9evzcWsr/N3f5YSlvR1aD54G55wDq1f3jRGpcFC7JEmqA5MVqUG0tMC2bXDxxTknufjivKr9DTfAnXcmDt29OY+0v/56WLRoz0Htzc25hWXLFhdllCRJ48JkRWoQ3d19g+oh/7zoIpgzB665Jlj35IH0fuazsHIlXHUV3HgjPP54Htw+ZQq84Q2uIi9JksaVyYrUIHp6YtD1FZcvh4UXzaJzzuvyhZUr4cor80qSAOef7yrykiRp3JmsSA1i0qTaQ1GiWJC+owO6eyf1XVi2LE9l7CrykiSpTkxWpAbR0pJnAaseirJkCWzf3nfcOq0ld/363vfgpJNyocoq8tUccC9JksaBi0JKDaKpKQ9DufHGvFD9tm15/8ILizH0X++lbe5kaDquf8HKKvILF/atIukq8pIkaRy4KKQ0AY1kUcje3jwuvjrnuPP2XRw+7QV6ph9E8+Qmmpqi9gLxvb15jMrAVeQHOy9JJeSikNLEY8uK1CCamuCEE3IPr507E5MnJWZPeYH1Tx3Ewrc392s0OfHEXKYvD2mirW12/zykVvZTKTxaCYvJkCRJDc1/9aUG0dsL69bBmWfC/PnBmWc1se7JA/nUNc01J/pasybPUjzobMWdnX2JysDCoxXwsEFIkqRXMpMVqUHUyi3e8e4WLrmk/30dHbBjx17kIWM9S9hYJ0OSJKn0TFakBrFjR+3cYt68/ufa2/sWqx94b788ZKxnCXPKZEmSGp7JitQgmptr5xZTWlO/6YyXL4dp0/YiD6nMEjaw8GjNEuaUyZIkNTyTFalBTJsGixf3zy0WL4bpP9/Aii88yMZHu1mxInHiiTBr1l7kIU1NeTD9ihWwcWP+OZqD68c6GZIkSaXn1MXSBDTSqYsfeww2bIDp06GrC45r38nxu35G0wEzcjLQ0tLv/rpPxFWKICS9Ujh1sTTxOHWx1CCamuD44+Ggg6C7O9HatIu25mdpajq8ZhLQ1ASzZ9cp2FIFIUmS6sVkRWogfd/9A5gMHFHfgCRJkoZgfwpJkiRJpWSyIo2DiPhcRDwcEasj4s6IOLjq2ici4vGIeCQizq9nnJIkSWVisiKNj3uB16aUTgIeBT4BEBGvAS4ATgDeAnwhIprrFqUkSVKJmKxI4yCldE9KaXdxuAKYW+wvBG5LKXWnlJ4AHgdOq0eMkiRJZWOyIo2/PwS+WezPAZ6surapOLeHiPhwRKyKiFVbt24d4xAlSZLqz9nApFESEd8Gas2ze1VKaXlxz1XAbuCWSrEa99dc/CildDNwM+R1VvY7YEmSpJIzWZFGSUrpvKGuR8SFwP8Gzk19q7FuAuZV3TYXeHpsIpQkSZpY7AYmjYOIeAvwZ8BvpZR2VF36BnBBRLRGxDHA8cAD9YhRkiSpbGxZkcbH54FW4N6IAFiRUvpISmldRHwNWE/uHnZJSqmnjnFKkiSVhsmKNA5SSvOHuHYdcN04hiNJkjQh2A1MkiRJUimZrEiSJEkqJZMVSZIkSaVksiJJkiSplExWJEmSJJWSyYokSZKkUjJZkSRJklRKJiuSJEmSSslkRZIkSVIpmaxIkiRJKiWTFUmSJEmlZLIiSZIkqZRMViRJkiSVksmKJEmSpFIyWZEkSZJUSiYrkiRJkkrJZEWSJElSKZmsSJIkSSolkxVJkiRJpWSyIkmSJKmUTFYkSZIklZLJiiRJkqRSMlmRJEmSVEomK5IkSZJKyWRFkiRJUimZrEiSJEkqJZPqsiQWAAAQf0lEQVQVSZIkSaVksiJJkiSplExWJEmSJJWSyYo0DiLi2ohYHREPRcQ9EXFk1bVPRMTjEfFIRJxfzzglSZLKxGRFGh+fSymdlFI6GbgL+CRARLwGuAA4AXgL8IWIaK5fmJIkSeVhsiKNg5TSL6sOpwOp2F8I3JZS6k4pPQE8Dpw23vFJkiSVUUu9A5AaRURcB/w+8Dzw5uL0HGBF1W2binOSJEkNz5YVaZRExLcjYm2NbSFASumqlNI84Bbg0kqxGlWlGueIiA9HxKqIWLV169ax+RCSJEklYsuKNEpSSuft5a23AncDnyK3pMyrujYXeHqQ+m8GbgY49dRTayY0kiRJryS2rEjjICKOrzr8LeDhYv8bwAUR0RoRxwDHAw+Md3ySJEllZMuKND4+GxGvBnqBDuAjACmldRHxNWA9sBu4JKXUU78wJUmSysNkRRoHKaV3D3HtOuC6cQxHkiRpQrAbmCRJkqRSMlmRJEmSVEomK5IkSZJKyWRFkiRJUik5wF5qIC+9tJvOzmZ27YLmZpg2DV56iZePW1vzfd3deb+pCXbuhJSgpycfNzVBby/MPrCLX744iR07J9PTk5g2uYdDZ+zgmRem0r2ridbJvbS1/IKmnS/lAs3NEJErqjxo5858PGkStLT0nas8pKcHpk7NAe7ale+bPh26uvLxlCn5nl27cvmpU+HFF2H37nzv7NmwbRvs2JHrnDw5n581Kx8Pp7cXOjvzC5k2LT+r8nLa2vaujlp1jaS8JEkNyH8ppQbx0ku7Wb++mbPOCubPD664Ivif/4mXj885J3j44eC554K///u8v3173z3HHhucfXbw6KPB5ZcHa/97Op2/aOXsc4Lj5jex4MxJrH7iQD5y2WSOnt/CgjMns+bpmfRefgUceyycdRY8+ihccQVs2gRPPw1nnw3HHQdnnglPPJETi8svz/edfTa8733w8MO57Pz5+efGjXDTTfD+9+f7KtfOPhuefDKXnz8fLrsM1q6FBQvyM845Bx55JJd/7LGcPAyltxfWrMnlf+d3+uo6+uj8c82a4euoVddIykuS1KhSSm5ubhNsO+WUU9K+2rixN7W3p5TbSVJatiz1O4Z8fPfdKa1bl/fXr699T6Xs+vW1r1Ufb172gz1vuPvuwR9eHdhgQa5bN/i1SgBDfcC7705p8+ahX9jmzcPHMVwdteoaSXlJowJYlUrw/3A3N7e93+wGJjWI3buho6PveObM/seQj6dPzz22OjpyL6Va91TKDuzFVLlWfdw984jaNwz28OnT+64NFmRz8+DXKvUP9QEhd8caSnf38HEMV0etukZSXpKkBmU3MKlBtLRAe3vf8bZt/Y8hH3d15aEZ7e25l1KteyplB/ZiqlyrPm7dtnnPG7q6Bn94dWCDBdnTM/i1SgBDfcCurr5xM4NpbR0+juHqqFXXSMpLktSgTFakBnH44T0sW5Ze/s68ZAnccUffd+j2dli8GI45Jv9cvDiPR7/llv73LFqUyy5dmvolM+3tsGxZYsmSvuPlS3fRtuRzexY+7DBYurR/4VtvzT+XLMn3tbfD9dfnQKrvW7o0nxvsWiWAJUtg2bI9P+Bhh+UxLG1tQ7+wtjZYvnzwOJYvH76OWnWNpLwkSQ0qUkr1jkHSPjr11FPTqlWr9rnc+M0GFrROTuM3G9ju3bn+ymxgPT25PmcDk1QlIh5MKZ1a7zgk7T3HrEgNZMqUFo46arRqm8Fhh1T2g9xQexCzD6m+5/DRelh/s2bt/b2zZ4/8OU1N+1d+rOqSJKlB+Gs9SZIkSaVksiJJkiSplExWJEmSJJWSyYokSZKkUjJZkSRJklRKTl0sTUARsRXoGPbG2g4FnhnFcMbaRIp3IsUKEyteYx07Eyne/Y21PaV02GgFI2nsmaxIDSYiVk2kdQYmUrwTKVaYWPEa69iZSPFOpFgljQ67gUmSJEkqJZMVSZIkSaVksiI1npvrHcA+mkjxTqRYYWLFa6xjZyLFO5FilTQKHLMiSZIkqZRsWZEkSZJUSiYrkiRJkkrJZEVqIBHxloh4JCIej4iP1zGOjRGxJiIeiohVxbmZEXFvRDxW/Dyk6v5PFDE/EhHnV50/pajn8Yj4u4iIUYjtyxHRGRFrq86NWmwR0RoR/1KcXxkRR49BvFdHxFPF+30oIt5WhngjYl5E3B8RP4uIdRFxeXG+dO93iFhL924jYkpEPBARPy1ivaY4X7r3Oky8pXu3kkogpeTm5tYAG9AMbACOBSYDPwVeU6dYNgKHDjj3V8DHi/2PA9cX+68pYm0Fjik+Q3Nx7QHgjUAA3wTeOgqxnQW8Hlg7FrEBFwNfLPYvAP5lDOK9GvhYjXvrGi9wBPD6Yv8A4NEiptK93yFiLd27LeqdUexPAlYCC8r4XoeJt3Tv1s3Nrf6bLStS4zgNeDyl9N8ppZ3AbcDCOsdUbSGwpNhfAryj6vxtKaXulNITwOPAaRFxBHBgSumHKaUE/FNVmRFLKf0nsG0MY6uu6w7g3Mpvg0cx3sHUNd6U0uaU0o+L/ReAnwFzKOH7HSLWwdQz1pRS2l4cTiq2RAnf6zDxDqbuf88k1Y/JitQ45gBPVh1vYugvX2MpAfdExIMR8eHi3OEppc2QvygCbcX5weKeU+wPPD8WRjO2l8uklHYDzwOzxiDmSyNideRuYpXuP6WJt+iW8zryb9VL/X4HxAolfLcR0RwRDwGdwL0ppVK/10HihRK+W0n1ZbIiNY5av1Ws19zlb0opvR54K3BJRJw1xL2DxV2GzzOS2MYj7v8LHAecDGwG/nqYZ49rvBExA1gKXJFS+uVQtw7y7HGLt0aspXy3KaWelNLJwFxyq8Nrh7i97u91kHhL+W4l1ZfJitQ4NgHzqo7nAk/XI5CU0tPFz07gTnIXtZ8X3ToofnYWtw8W96Zif+D5sTCasb1cJiJagIPY+25ceyWl9PPiy2Av8CXy+y1FvBExifzl/5aU0rLidCnfb61Yy/xui/ieA74DvIWSvtfB4i37u5VUHyYrUuP4EXB8RBwTEZPJg06/Md5BRMT0iDigsg/8BrC2iOXC4rYLgeXF/jeAC4rZfY4BjgceKLq1vBARC4q+6L9fVWa0jWZs1XW9B/iPor/9qKl8QS28k/x+6x5vUfci4Gcppb+pulS69ztYrGV8txFxWEQcXOxPBc4DHqaE73WoeMv4biWVwEhH5ru5uU28DXgbeVajDcBVdYrhWPLMPj8F1lXiIPcnvw94rPg5s6rMVUXMj1A14xdwKvkLzQbg80CMQnz/j9wFZRf5t7MfHM3YgCnA7eRBwg8Ax45BvF8F1gCryV/ajihDvMAZ5K44q4GHiu1tZXy/Q8RauncLnAT8pIhpLfDJ0f47Ncr/HQwWb+nerZubW/23yl9qSZIkSSoVu4FJkiRJKiWTFUmSJEmlZLIiSZIkqZRMViRJkiSVksmKJEmSpFIyWZEkSZJUSiYrkjRARGyMiEOL/e1D3Hd0RLxv/CIbuYi4IiKmVR3/W2VhvrKKiIMj4uKq43Mi4q79rPPqiPjYCMu2R8SDEfFQRKyLiI/sTyySpOGZrEjSyB0N1ExWIqJlfEMZ1hXAy8lKSultKaXn6hjP3jgYuHjYu8bPZuB/pZROBk4HPh4RR9Y5Jkl6RTNZkdTQIuLrxW/L10XEh/ex+GeBM4vftF8ZEX8QEbdHxL8C90TEjIi4LyJ+HBFrImJh8cyjI+JnEfGl4rn3RMTU4tplEbE+IlZHxG1DxH1aRPxXRPyk+Pnq4nxzRNxQPG91RPxxRFwGHAncHxH3F/dtjIhDI+L6Aa0XV0fER4v9P42IHxX1XDNELEdHxMMR8Y8RsTYibomI8yLiBxHxWEScVtw3s3jfqyNiRUScVPXML0fEdyLiv4t4K+/3uOL9fq44NyMi7iied0tERFHHZ6ve2w1784cXER8qPt9PI2JppeUpIo4r4vtRRHy60rqWUtqZUuouircyzL+htWKKiK9ExHuq7tle/DwnIr4bEV+LiEeLsu+PiAeKP8vj9uYzSdIrzkiWvXdzc3N7pWzAzOLnVGAtMAvYCBxanN8+RNlzgLuqjv8A2FRVZwtwYLF/KPA4EOQWmd3AycW1rwEfKPafBlqL/YOHePaBQEuxfx6wtNj/I2Bp1bVKLC9/pupj4HXAd6vOrweOAn4DuLmItwm4CzhrkFgqn+fE4t4HgS8XZRcCXy/uuwn4VLH/68BDxf7VwH+RE4BDgWeBSUW9awe87+eBucVzfgicAcwEHgFiL97b1cDHiv1ZVef/AvjjYv8u4HeL/Y9U/zcAzANWAzuAS4b676pWTMBXgPdU3be96rM9BxxRvIengGuKa5cDf1vvvytubm5u9dhsWZHU6C6LiJ8CK8hfRI/fz/ruTSltK/YD+MuIWA18G5gDHF5ceyKl9FCx/yD5iznkL8K3RMQHyAnAYA4Cbo+ItcCNwAnF+fOAL6aUdgNUxVJTSuknQFtEHBkRvwb8IqX0P+Rk5TeAnwA/Bn6Fod/NEymlNSmlXmAdcF9KKQFrqj7bGcBXi+f+BzArIg4qrt2dUupOKT0DdNL3ngZ6IKW0qXjOQ0XdvwReAv4xIt5FTiT2xmsj4nsRsQZ4P33v8I3A7cX+rdUFUkpPppROAuYDF0bEYHGOJKYfpZQ2p9x6swG4pzhf/Q4lqaGYrEhqWBFxDvnL/RtTSr9G/mI+ZT+r7arafz9wGHBKyuMcfl5Vf3fVfT3kVhiAtwN/D5wCPDjE2JdrgftTSq8FfrOq3gDSPsZ8B/Ae4HeAStezAD6TUjq52OanlBYNUUf15+mtOu6l77NFjXKVWAd7H0M9p4fcgrQbOI3covQO4N+HiLPaV4BLU0onAtewD3/2KaWnyUnZmYNcHyym3RT/9hZd2CZXFdubdyhJDcVkRVIjO4jckrAjIn4FWLCP5V8ADhim/s6U0q6IeDPQPlRlEdEEzEsp3Q/8H/IA8xlD1P1Usf8HVefvAT5SSXIiYuZexHobcAE5YbmjOPct4A8jYkZRz5yIaBsq/r3wn+QErpIoPpNS+uUQ9w/3finqmgEclFL6N/JEAifvZTwHAJsjYlIlrsIK4N3F/gVVz5lbNbboEOBN5K5e+xLTRnIiCrmL3KS9jFWSGpK/qZHUyP6d/MV+NflL54p9LL8a2F10I/sK8IsB128B/jUiVpG7LD08TH3NwD8XXaMCuDENPmPXXwFLIuJPgP+oOv+PwKuA1RGxC/gS8Hny+JNvRsTmlNKbqytKKa2LiAOAp1JKm4tz90TErwI/LMawbwc+QO6iNVJXA4uL970DuHCom1NKzxaD9NcC3wTuHuTWA4DlETGF/N6u3Mt4/hxYCXSQu1pVEqMryH8OHy2e+Xxx/leBv46IVDznhpTSmn2M6UvF+QeA++jfEidJGqAy8E+SJAHFrGAvppRSRFxAHmy/sN5xSVIjsmVFkqT+TgE+X4wpeQ74wzrHI0kNy5YVSRpGRJxIMYtVle6U0unj8OyLyFPXVvtBSumSsX52jVhmkbsuDXRuSunZ8Y5nKBFxFfDeAadvTyldNwbPuhM4ZsDpP0spfWu0nyVJjcZkRZIkSVIpORuYJEmSpFIyWZEkSZJUSiYrkiRJkkrJZEWSJElSKf1/HdYsnlTLo14AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a scatter plot to check if can see some relation\n",
    "sns.scatterplot(x=train_all['all_trans_active_months_lag12_sum'], y=train_all['target'], color='red')\n",
    "sns.scatterplot(x=train_all['all_trans_active_months_lag3_sum'], y=train_all['target'], color='blue')\n",
    "plt.title('Scatterplot of all_trans_active_months_lag12_sum and all_trans_active_months_lag3_sum against the target variable(Loaylty score)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this plot we can see as the values of month lag is increasing loyalty score on getting close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a scatter plot to check if can see some relation\n",
    "sns.scatterplot(x=train_all['new_tr_month_lag_min'], y=train_all['target'], color='red')\n",
    "plt.title('Scatterplot of new_tr_month_lag_min against the target variable(Loaylty score)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By seeing this it is not possible to conclude anything as range of target variable is looking same for 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a scatter plot to check if can see some relation\n",
    "sns.scatterplot(x=train_all['new_tr_purchase_amount_max'], y=train_all['target'], color='red')\n",
    "plt.title('Scatterplot of new_tr_purchase_amount_max against the target variable(Loaylty score)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see as the value of new_tr_purchase_amount_max is increasing the target variable is getting close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a scatter plot to check if can see some relation\n",
    "sns.scatterplot(x=train_all['year'], y=train_all['target'], color='red')\n",
    "plt.title('Scatterplot of year against the target variable(Loaylty score)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot it looks like we have outliners in every year the recent years have wide range of loyalty score as compared to earlier years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a scatter plot to check if can see some relation\n",
    "sns.scatterplot(x=train_all['new_tr_purchase_amount_std'], y=train_all['target'], color='red')\n",
    "plt.title('Scatterplot of new_tr_purchase_amount_std against the target variable(Loaylty score)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can se that the lower the value of new_tr_purchase_amount_std is more the negative loyalty score points can be seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=train_nt_ht['elapsed_time'], y=train_nt_ht['target'], color='red')\n",
    "plt.title('Scatterplot  against the target variable(Loaylty score)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the elapsed_time increasing we can see more number of points getting closer to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating more fearures based on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['all_trans_purchase_date_max'] = pd.to_datetime(train_all['all_trans_purchase_date_max'])\n",
    "train_all['all_trans_purchase_date_min'] = pd.to_datetime(train_all['all_trans_purchase_date_min'])\n",
    "train_all['all_time_diff'] = (train_all['all_trans_purchase_date_max'].dt.date - train_all['all_trans_purchase_date_min'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all['all_trans_purchase_date_max'] = pd.to_datetime(test_all['all_trans_purchase_date_max'])\n",
    "test_all['all_trans_purchase_date_min'] = pd.to_datetime(test_all['all_trans_purchase_date_min'])\n",
    "test_all['all_time_diff'] = (test_all['all_trans_purchase_date_max'].dt.date - test_all['all_trans_purchase_date_min'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['transactions_total'] = train_all['all_transactions_count'] + train_all['new_transactions_count']\n",
    "test_all['transactions_total'] = test_all['all_transactions_count'] + test_all['new_transactions_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['avg_all_card_use'] = train_all['all_time_diff']/train_all['all_transactions_count']\n",
    "test_all['avg_all_card_use'] = test_all['all_time_diff']/test_all['all_transactions_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['avg_new_card_use'] = train_all['new_time_diff']/train_all['new_transactions_count']\n",
    "test_all['avg_new_card_use'] = test_all['new_time_diff']/test_all['new_transactions_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_diff'] = train_all['new_time_diff'] + train_all['all_time_diff']\n",
    "test_all['total_diff'] = test_all['new_time_diff']+test_all['all_time_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_avg'] = train_all['total_diff'] / train_all['transactions_total']\n",
    "test_all['total_avg'] = test_all['total_diff']/test_all['transactions_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2017-04-01\n",
       "1   2017-01-01\n",
       "2   2017-08-01\n",
       "3   2017-12-01\n",
       "4   2015-12-01\n",
       "Name: first_active_month, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all['first_active_month'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['first_active_month'] = pd.to_datetime(train_all['first_active_month'])\n",
    "# test_all['first_active_month'] = pd.to_datetime(test_all['first_active_month'])\n",
    "test_all['first_active_month'] = pd.to_datetime(test_all['first_active_month'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['first_active_month'] = pd.to_datetime(train_all['first_active_month'])\n",
    "train_all['diff_btw_first_last'] = (train_all['all_trans_purchase_date_max'].dt.date - train_all['first_active_month'].dt.date).dt.days\n",
    "\n",
    "test_all['first_active_month'] = pd.to_datetime(test_all['first_active_month'])\n",
    "test_all['diff_btw_first_last'] = (test_all['all_trans_purchase_date_max'].dt.date - test_all['first_active_month'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating more features from the set of features which are present in new and history transactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_purchase_sum'] = train_all['new_tr_purchase_amount_sum'] + train_all['all_trans_purchase_amount_sum']\n",
    "test_all['total_purchase_sum'] = test_all['new_tr_purchase_amount_sum'] + test_all['all_trans_purchase_amount_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_install_sum'] = train_all['all_trans_installments_sum'] + train_all['new_tr_installments_sum']\n",
    "test_all['total_install_sum'] = test_all['all_trans_installments_sum'] + test_all['new_tr_installments_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_month_lag_mean'] = train_all['all_trans_month_lag_mean'] + train_all['new_tr_month_lag_mean']\n",
    "test_all['total_month_lag_mean'] = test_all['all_trans_month_lag_mean'] + test_all['new_tr_month_lag_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['hist_first_buy'] = (train_all['all_trans_purchase_date_min'].dt.date - train_all['first_active_month'].dt.date).dt.days\n",
    "test_all['hist_first_buy'] = (test_all['all_trans_purchase_date_min'].dt.date - test_all['first_active_month'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_month_lag_min'] = train_all['all_trans_month_lag_min'] + train_all['new_tr_month_lag_min']\n",
    "test_all['total_month_lag_min'] = test_all['all_trans_month_lag_min'] + test_all['new_tr_month_lag_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_month_lag_max'] = train_all['all_trans_month_lag_max'] + train_all['new_tr_month_lag_max']\n",
    "test_all['total_month_lag_max'] = test_all['all_trans_month_lag_max'] + test_all['new_tr_month_lag_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_install_max'] = train_all['all_trans_installments_max'] + train_all['new_tr_installments_max']\n",
    "test_all['total_install_max'] = test_all['all_trans_installments_max'] + test_all['new_tr_installments_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_install_min'] = train_all['all_trans_installments_min'] + train_all['new_tr_installments_min']\n",
    "test_all['total_install_min'] = test_all['all_trans_installments_min'] + test_all['new_tr_installments_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_install_ratio'] = train_all['all_trans_installments_sum'] / train_all['new_tr_installments_sum']\n",
    "test_all['total_install_ratio'] = test_all['all_trans_installments_sum'] / test_all['new_tr_installments_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_install_mean'] = train_all['all_trans_installments_mean'] + train_all['new_tr_installments_mean']\n",
    "test_all['total_install_mean'] = test_all['all_trans_installments_mean'] + test_all['new_tr_installments_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_purchase_max'] = train_all['new_tr_purchase_amount_max'] + train_all['all_trans_purchase_amount_max']\n",
    "test_all['total_purchase_max'] = test_all['new_tr_purchase_amount_max'] + test_all['all_trans_purchase_amount_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_purchase_min'] = train_all['new_tr_purchase_amount_min'] + train_all['all_trans_purchase_amount_min']\n",
    "test_all['total_purchase_min'] = test_all['new_tr_purchase_amount_min'] + test_all['all_trans_purchase_amount_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_purchase_mean'] = train_all['new_tr_purchase_amount_mean'] + train_all['all_trans_purchase_amount_mean']\n",
    "test_all['total_purchase_mean'] = test_all['new_tr_purchase_amount_mean'] + test_all['all_trans_purchase_amount_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['total_purchase_ratio'] = train_all['new_tr_purchase_amount_sum'] / train_all['all_trans_purchase_amount_sum']\n",
    "test_all['total_purchase_ratio'] = test_all['new_tr_purchase_amount_sum'] / test_all['all_trans_purchase_amount_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['active_purchase_lag_mean'] = train_all['all_trans_avg_purchases_lag3_mean'] + train_all['all_trans_avg_purchases_lag12_mean'] + train_all['all_trans_avg_purchases_lag6_mean']\n",
    "test_all['active_purchase_lag_mean']  = test_all['all_trans_avg_purchases_lag3_mean'] + test_all['all_trans_avg_purchases_lag12_mean'] + test_all['all_trans_avg_purchases_lag6_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['active_sales_lag_max'] = train_all['all_trans_avg_sales_lag3_max'] + train_all['all_trans_avg_sales_lag12_max'] + train_all['all_trans_avg_sales_lag6_max']\n",
    "test_all['active_sales_lag_max']  = test_all['all_trans_avg_sales_lag3_max'] + test_all['all_trans_avg_sales_lag12_max'] + test_all['all_trans_avg_sales_lag6_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['active_sales_lag_min'] = train_all['all_trans_avg_sales_lag3_min'] + train_all['all_trans_avg_sales_lag12_min'] + train_all['all_trans_avg_sales_lag6_min']\n",
    "test_all['active_sales_lag_min']  = test_all['all_trans_avg_sales_lag3_min'] + test_all['all_trans_avg_sales_lag12_min'] + test_all['all_trans_avg_sales_lag6_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['active_sales_lag_mean'] = train_all['all_trans_avg_sales_lag3_mean'] + train_all['all_trans_avg_sales_lag12_mean'] + train_all['all_trans_avg_sales_lag6_mean']\n",
    "test_all['active_sales_lag_mean']  = test_all['all_trans_avg_sales_lag3_mean'] + test_all['all_trans_avg_sales_lag12_mean'] + test_all['all_trans_avg_sales_lag6_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['price_total'] = train_all['total_purchase_sum'] / train_all['total_install_sum']\n",
    "train_all['price_mean'] = train_all['total_purchase_mean'] / train_all['total_install_mean']\n",
    "train_all['price_max'] = train_all['total_purchase_max'] / train_all['total_install_max']\n",
    "\n",
    "test_all['price_total'] = test_all['total_purchase_sum'] / test_all['total_install_sum']\n",
    "test_all['price_mean'] = test_all['total_purchase_mean'] / test_all['total_install_mean']\n",
    "test_all['price_max'] = test_all['total_purchase_max'] / test_all['total_install_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['new_tr_purchase_date_max'] = pd.to_datetime(train_all['new_tr_purchase_date_max'],errors='coerce')\n",
    "train_all['new_tr_year_max'] = train_all['new_tr_purchase_date_max'].dt.year\n",
    "train_all['new_tr_month_max'] = train_all['new_tr_purchase_date_max'].dt.month\n",
    "train_all['new_tr_dayofweek_max'] = train_all['new_tr_purchase_date_max'].dt.dayofweek\n",
    "train_all['new_tr_dayofyear_max'] = train_all['new_tr_purchase_date_max'].dt.dayofyear\n",
    "train_all['new_tr_week_max'] = train_all['new_tr_purchase_date_max'].dt.week\n",
    "\n",
    "test_all['new_tr_purchase_date_max'] = pd.to_datetime(test_all['new_tr_purchase_date_max'],errors='coerce')\n",
    "test_all['new_tr_year_max'] = test_all['new_tr_purchase_date_max'].dt.year\n",
    "test_all['new_tr_month_max'] = test_all['new_tr_purchase_date_max'].dt.month\n",
    "test_all['new_tr_dayofweek_max'] = test_all['new_tr_purchase_date_max'].dt.dayofweek\n",
    "test_all['new_tr_dayofyear_max'] = test_all['new_tr_purchase_date_max'].dt.dayofyear\n",
    "test_all['new_tr_week_max'] = test_all['new_tr_purchase_date_max'].dt.week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['new_tr_purchase_date_min'] = pd.to_datetime(train_all['new_tr_purchase_date_min'],errors='coerce')\n",
    "train_all['new_tr_year_min'] = train_all['new_tr_purchase_date_max'].dt.year\n",
    "train_all['new_tr_month_min'] = train_all['new_tr_purchase_date_max'].dt.month\n",
    "train_all['new_tr_dayofweek_min'] = train_all['new_tr_purchase_date_max'].dt.dayofweek\n",
    "train_all['new_tr_dayofyear_min'] = train_all['new_tr_purchase_date_max'].dt.dayofyear\n",
    "train_all['new_tr_week_min'] = train_all['new_tr_purchase_date_max'].dt.week \n",
    "\n",
    "test_all['new_tr_purchase_date_min'] = pd.to_datetime(test_all['new_tr_purchase_date_min'],errors='coerce')\n",
    "test_all['new_tr_year_min'] = test_all['new_tr_purchase_date_min'].dt.year\n",
    "test_all['new_tr_month_min'] = test_all['new_tr_purchase_date_min'].dt.month\n",
    "test_all['new_tr_dayofweek_min'] = test_all['new_tr_purchase_date_min'].dt.dayofweek\n",
    "test_all['new_tr_dayofyear_min'] = test_all['new_tr_purchase_date_min'].dt.dayofyear\n",
    "test_all['new_tr_week_min'] = test_all['new_tr_purchase_date_min'].dt.week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['all_trans_purchase_date_min'] = pd.to_datetime(train_all['all_trans_purchase_date_min'],errors='coerce')\n",
    "train_all['all_tr_year_min'] = train_all['all_trans_purchase_date_min'].dt.year\n",
    "train_all['all_tr_month_min'] = train_all['all_trans_purchase_date_min'].dt.month\n",
    "train_all['all_tr_dayofweek_min'] = train_all['all_trans_purchase_date_min'].dt.dayofweek\n",
    "train_all['all_tr_dayofyear_min'] = train_all['all_trans_purchase_date_min'].dt.dayofyear\n",
    "train_all['all_tr_week_min'] = train_all['all_trans_purchase_date_min'].dt.week \n",
    "\n",
    "test_all['all_trans_purchase_date_min'] = pd.to_datetime(test_all['all_trans_purchase_date_min'],errors='coerce')\n",
    "test_all['all_tr_year_min'] = test_all['all_trans_purchase_date_min'].dt.year\n",
    "test_all['all_tr_month_min'] = test_all['all_trans_purchase_date_min'].dt.month\n",
    "test_all['all_tr_dayofweek_min'] = test_all['all_trans_purchase_date_min'].dt.dayofweek\n",
    "test_all['all_tr_dayofyear_min'] = test_all['all_trans_purchase_date_min'].dt.dayofyear\n",
    "test_all['all_tr_week_min'] = test_all['all_trans_purchase_date_min'].dt.week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['all_trans_purchase_date_max'] = pd.to_datetime(train_all['all_trans_purchase_date_max'],errors='coerce')\n",
    "train_all['all_tr_year_max'] = train_all['all_trans_purchase_date_max'].dt.year\n",
    "train_all['all_tr_month_max'] = train_all['all_trans_purchase_date_max'].dt.month\n",
    "train_all['all_tr_dayofweek_max'] = train_all['all_trans_purchase_date_max'].dt.dayofweek\n",
    "train_all['all_tr_dayofyear_max'] = train_all['all_trans_purchase_date_max'].dt.dayofyear\n",
    "train_all['all_tr_week_max'] = train_all['all_trans_purchase_date_max'].dt.week \n",
    "\n",
    "test_all['all_trans_purchase_date_max'] = pd.to_datetime(test_all['all_trans_purchase_date_max'],errors='coerce')\n",
    "test_all['all_tr_year_max'] = test_all['all_trans_purchase_date_max'].dt.year\n",
    "test_all['all_tr_month_max'] = test_all['all_trans_purchase_date_max'].dt.month\n",
    "test_all['all_tr_dayofweek_max'] = test_all['all_trans_purchase_date_max'].dt.dayofweek\n",
    "test_all['all_tr_dayofyear_max'] = test_all['all_trans_purchase_date_max'].dt.dayofyear\n",
    "test_all['all_tr_week_max'] = test_all['all_trans_purchase_date_max'].dt.week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.fillna(0,inplace=True)\n",
    "test_all.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "test_all.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target                               1.000000\n",
      "all_tr_year_max                      0.132301\n",
      "all_trans_h_duration_min             0.079726\n",
      "all_trans_h_Mothers_Day_2018_var     0.076690\n",
      "all_trans_h_Mothers_Day_2018_mean    0.062772\n",
      "                                       ...   \n",
      "all_tr_dayofyear_max                -0.134844\n",
      "all_tr_week_max                     -0.134905\n",
      "all_trans_active_months_lag3_max          NaN\n",
      "all_trans_active_months_lag6_max          NaN\n",
      "all_tr_year_min                           NaN\n",
      "Name: target, Length: 321, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr = train_all.corr()\n",
    "print(corr[\"target\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.to_pickle(\"train_all.pkl\")\n",
    "test_all.to_pickle(\"test_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.read_pickle('train_all.pkl')\n",
    "test_all = pd.read_pickle('test_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>...</th>\n",
       "      <th>all_tr_year_min</th>\n",
       "      <th>all_tr_month_min</th>\n",
       "      <th>all_tr_dayofweek_min</th>\n",
       "      <th>all_tr_dayofyear_min</th>\n",
       "      <th>all_tr_week_min</th>\n",
       "      <th>all_tr_year_max</th>\n",
       "      <th>all_tr_month_max</th>\n",
       "      <th>all_tr_dayofweek_max</th>\n",
       "      <th>all_tr_dayofyear_max</th>\n",
       "      <th>all_tr_week_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820312</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>26</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392822</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687988</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142456</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>269</td>\n",
       "      <td>39</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159790</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>305</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>316</td>\n",
       "      <td>45</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0         2017-06-01  C_ID_92a2005557          5          2          1   \n",
       "1         2017-01-01  C_ID_3d0044924f          4          1          0   \n",
       "2         2016-08-01  C_ID_d639edf6cd          2          2          0   \n",
       "3         2017-09-01  C_ID_186d6a6901          4          3          0   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  year  month  dayofweek  dayofyear  ...  all_tr_year_min  \\\n",
       "0 -0.820312  2017      6          3        152  ...             2017   \n",
       "1  0.392822  2017      1          6          1  ...             2017   \n",
       "2  0.687988  2016      8          0        214  ...             2017   \n",
       "3  0.142456  2017      9          4        244  ...             2017   \n",
       "4 -0.159790  2017     11          2        305  ...             2017   \n",
       "\n",
       "   all_tr_month_min  all_tr_dayofweek_min  all_tr_dayofyear_min  \\\n",
       "0                 6                     1                   178   \n",
       "1                 1                     4                     6   \n",
       "2                 1                     2                    11   \n",
       "3                 9                     1                   269   \n",
       "4                11                     6                   316   \n",
       "\n",
       "   all_tr_week_min  all_tr_year_max  all_tr_month_max  all_tr_dayofweek_max  \\\n",
       "0               26             2018                 2                     6   \n",
       "1                1             2018                 1                     2   \n",
       "2                2             2018                 2                     1   \n",
       "3               39             2018                 2                     2   \n",
       "4               45             2018                 2                     2   \n",
       "\n",
       "   all_tr_dayofyear_max  all_tr_week_max  \n",
       "0                    56                8  \n",
       "1                    31                5  \n",
       "2                    58                9  \n",
       "3                    59                9  \n",
       "4                    59                9  \n",
       "\n",
       "[5 rows x 327 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating X and Y to fit in model from the final test_all and train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleting the features and removing features which are of date type\n",
    "y = train_all['target'].values\n",
    "X = train_all.drop(columns=['target','card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating LGBM regressor and performing hyper-parameter tunning on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': list(range(60, 150, 15)),\n",
    "    'min_data_in_leaf': [90, 100, 110,120,130,140],\n",
    "    'min_child_samples': [20,25,30],\n",
    "    'max_depth': [8, 12, 16, 20,-1],\n",
    "    'learning_rate': [0.1, 0.01, 0.005],\n",
    "    'feature_fraction': [0.7,0.8,0.9],\n",
    "    'bagging_freq': [1,3, 4, 5, 6, 7],\n",
    "    'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    'lambda_l1':[0.1,0.01,0.2],\n",
    "    'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    'reg_lambda': np.linspace(0.1, 0.95, 10),\n",
    "    'n_estimators': [200, 400,600]\n",
    "}\n",
    "\n",
    "model = LGBMRegressor(metric='rmse',objective='regression',nthread=-1,boosting_type='rf')\n",
    "\n",
    "clf_1 = RandomizedSearchCV(model, param_grid, cv=10, scoring='neg_root_mean_squared_error',return_train_score=True)\n",
    "clf_1.fit(X_train,y_train)\n",
    "\n",
    "best_params_lgbm = clf_1.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6831172858215147\n"
     ]
    }
   ],
   "source": [
    "model_1 = LGBMRegressor(learning_rate= best_params_lgbm['learning_rate'],bagging_fraction=best_params_lgbm['bagging_fraction'],\n",
    "                        reg_alpha=best_params_lgbm['reg_alpha'],num_leaves =best_params_lgbm['num_leaves'],\n",
    "                        min_data_in_leaf =best_params_lgbm['min_data_in_leaf'],max_depth =best_params_lgbm['max_depth'],\n",
    "                        reg_lambda=best_params_lgbm['reg_lambda'],bagging_freq=best_params_lgbm['bagging_freq'],metric='rmse',\n",
    "                        feature_fraction=best_params_lgbm['feature_fraction'],lambda_l1=best_params_lgbm['lambda_l1'])\n",
    "\n",
    "\n",
    "model_1.fit(X_train,y_train)\n",
    "\n",
    "pred = model_1.predict(X_test)\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new variable for outliners to see if can improve performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_out = train_all.copy()\n",
    "train_all_out['outliers'] = 0\n",
    "train_all_out.loc[train_all['target'] < -10, 'outliers'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = train_all_out['target'].values\n",
    "X_out = train_all_out.drop(columns=['target','card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_o, X_test_o, y_train_o, y_test_o = train_test_split(X_out, y_out, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating LGBM regressor and performing hyper-parameter tunning on the model with outliner feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7555555555555555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7555555555555555\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6388888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6388888888888888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "2.042159454087001\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': list(range(8, 92, 4)),\n",
    "    'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [3, 4, 5, 6, 8, 12, 16, 20],\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005],\n",
    "    'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    'reg_lambda': np.linspace(0.1, 0.95, 10),\n",
    "    'n_estimators': [200, 400,600]\n",
    "}\n",
    "\n",
    "model = LGBMRegressor()\n",
    "\n",
    "clf_1 = RandomizedSearchCV(model, param_grid, cv=20, scoring='neg_root_mean_squared_error',return_train_score=True)\n",
    "clf_1.fit(X_train_o,y_train_o)\n",
    "\n",
    "best_params_lgbm_o = clf_1.best_params_\n",
    "\n",
    "model_2 = LGBMRegressor(learning_rate= best_params_lgbm_o['learning_rate'],bagging_fraction=best_params_lgbm_o['bagging_fraction'],\n",
    "                        reg_alpha=best_params_lgbm_o['reg_alpha'],num_leaves =best_params_lgbm_o['num_leaves'],\n",
    "                        min_data_in_leaf =best_params_lgbm_o['min_data_in_leaf'],max_depth =best_params_lgbm_o['max_depth'],\n",
    "                        reg_lambda=best_params_lgbm_o['reg_lambda'],bagging_freq=best_params_lgbm_o['bagging_freq'],metric='rmse')\n",
    "\n",
    "\n",
    "model_2.fit(X_train_o,y_train_o)\n",
    "\n",
    "pred = model_2.predict(X_test_o)\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_test_o, pred))\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw the error reduced my a large margin if we use outliner as a feature so we will create a binary model which will predict the outliner for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m = train_all_out['outliers'].values\n",
    "X_m = train_all_out.drop(columns=['target','card_id','outliers', 'first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_m, y_m, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3816, 320) (3816,)\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# as the number of points for outliner are less we are under sampling \n",
    "import imblearn\n",
    "rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=.8)\n",
    "X_rus, y_rus = rus.fit_resample(X_train_m, y_train_m)\n",
    "print(X_rus.shape, y_rus.shape)\n",
    "print(y_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing XGBClassifier model with hyper-parameter tuning to predict a point is outliner or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=20,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=0, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None,\n",
       "                                           tree_method='gpu_hist',\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   param_distributions={'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1, 0.2, 0.3],\n",
       "                                        'n_estimators': [50, 75, 100, 125]},\n",
       "                   return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], \n",
    "    'n_estimators' : [50, 75, 100, 125]\n",
    "}\n",
    "\n",
    "xb1 = XGBClassifier(tree_method = 'gpu_hist', gpu_id=0)\n",
    "clf = RandomizedSearchCV(xb1, param_grid, cv=20, scoring='f1',return_train_score=True)\n",
    "clf.fit(X_rus,y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = clf.best_params_\n",
    "xb1 = XGBClassifier(tree_method = 'gpu_hist', gpu_id=0,learning_rate=best_params['learning_rate'],n_estimators=best_params['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=0,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)',\n",
       "              n_estimators=50, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb1.fit(X_rus,y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xb1.predict(X_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91     49913\n",
      "           1       0.05      0.77      0.09       567\n",
      "\n",
      "    accuracy                           0.83     50480\n",
      "   macro avg       0.52      0.80      0.50     50480\n",
      "weighted avg       0.99      0.83      0.90     50480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_m, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41493,  8420],\n",
       "       [  128,   439]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_m, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = test_all.drop(columns=['card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = xb1.predict(final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing LGBMClassifier model with hyper-parameter tuning to predict a point is outliner or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:00:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:01:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:01:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:01:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:01:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:02:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:02:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:02:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:02:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:03:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:03:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:03:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:03:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:04:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:04:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:04:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:04:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:05:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:05:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:05:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:05:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:06:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:07:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:09:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:10:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:11:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:12:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:13:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:14:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:15:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:16:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:17:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:18:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:19:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:20:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:22:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:23:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:24:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:25:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:26:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:27:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:28:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:29:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:29:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:29:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:29:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:29:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:29:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:30:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:30:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:30:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:30:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:30:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:30:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:31:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:31:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:31:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:31:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:31:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:32:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:32:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:33:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:33:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:33:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:34:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:34:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:35:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:35:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:36:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:36:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:37:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:37:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:38:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:38:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:38:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:39:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:39:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:40:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:40:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:41:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:41:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:41:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:42:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:42:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:43:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:43:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:43:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:44:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:44:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:45:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:45:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:45:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:46:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:46:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:46:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:49:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:49:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:49:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:49:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:50:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:50:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:50:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:50:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:51:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:51:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:51:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:51:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:51:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:52:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:52:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:52:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:53:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 824, in fit\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 212, in train\n",
      "    xgb_model=xgb_model, callbacks=callbacks)\n",
      "  File \"C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 75, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1369, in update\n",
      "    dtrain.handle))\n",
      "  File \"C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 190, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value -1 for Parameter max_depth should be greater equal to 0\n",
      "max_depth: Maximum depth of the tree; 0 indicates no limit; a limit is required for depthwise policy\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:53:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:53:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:53:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:54:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:54:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:54:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:54:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:55:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:55:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:55:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:55:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:56:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:56:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:56:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:57:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:57:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:57:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:57:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bagging_fraction, bagging_freq, feature_fraction, min_data_in_leaf, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400,600], \n",
    "    'num_leaves':list(range(8, 92, 4)),\n",
    "    'feature_fraction' : [0.8, 0.9],\n",
    "    'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [4,8, 12, 16, 20,-1],\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.001],\n",
    "    'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "}\n",
    "\n",
    "lbgm = LGBMClassifier()\n",
    "clf = RandomizedSearchCV(xb1, param_grid, cv=20, scoring='f1',return_train_score=True)\n",
    "clf.fit(X_rus,y_rus)\n",
    "\n",
    "best_params = clf.best_params_\n",
    "lbgm = LGBMClassifier(num_leaves=best_params['num_leaves'],n_estimators=best_params['n_estimators'],\n",
    "                     feature_fraction=best_params['feature_fraction'],min_data_in_leaf=best_params['min_data_in_leaf'],\n",
    "                     max_depth=best_params['max_depth'],learning_rate=best_params['learning_rate'],\n",
    "                     bagging_freq=best_params['bagging_freq'],bagging_fraction=best_params['bagging_fraction'],\n",
    "                     reg_alpha=best_params['reg_alpha'],reg_lambda=best_params['reg_lambda'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91     49913\n",
      "           1       0.05      0.77      0.09       567\n",
      "\n",
      "    accuracy                           0.83     50480\n",
      "   macro avg       0.52      0.80      0.50     50480\n",
      "weighted avg       0.99      0.83      0.90     50480\n",
      "\n",
      "[[41559  8354]\n",
      " [  128   439]]\n"
     ]
    }
   ],
   "source": [
    "lbgm.fit(X_rus,y_rus)\n",
    "pred = lbgm.predict(X_test_m)\n",
    "print(classification_report(y_test_m, pred))\n",
    "print(confusion_matrix(y_test_m, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test_lgbm = lbgm.predict(final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider only points which are predicted outliner by both the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['model1'] = out_test\n",
    "df['model2'] = out_test_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    101826\n",
       "1     21797\n",
       "Name: model1, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    102026\n",
       "1     21597\n",
       "Name: model2, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final'] = df['model1'] + df['model2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['final'] > 1, 'target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = pd.read_pickle('test_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all['outliers'] = out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 327)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all.fillna(0,inplace=True)\n",
    "test_all.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all.to_pickle('test_all_outliner.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = test_all.drop(columns=['card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values\n",
    "final_test_out = test_all.drop(columns=['card_id','outliers','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model for Linear regression with L1 and L2 regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1083443.620376189, tolerance: 226.390649578765\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=ElasticNet(), n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
       "                                        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]},\n",
       "                   return_train_score=True,\n",
       "                   scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "parameters = {'alpha': [0.1,0.3,0.5,0.7,0.9],'l1_ratio':[0.1,0.3,0.5,0.7,0.9]}\n",
    "\n",
    "en = ElasticNet()\n",
    "\n",
    "clf = RandomizedSearchCV(en, parameters,cv=10, scoring='neg_root_mean_squared_error',return_train_score=True, n_jobs=-1)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_en = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en = ElasticNet(alpha= best_params_en['alpha'],l1_ratio = best_params_en['l1_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1083443.620376189, tolerance: 226.390649578765\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.3, l1_ratio=0.1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.778766786161649\n"
     ]
    }
   ],
   "source": [
    "pred = model_en.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model for Linear regression with L1 and L2 regularizer with outliner features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1096072.6078795192, tolerance: 224.90272119558125\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1096072.6078795192, tolerance: 224.90272119558125\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7902283514327926\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha': [0.1,0.3,0.5,0.7,0.9],'l1_ratio':[0.1,0.3,0.5,0.7,0.9]}\n",
    "\n",
    "en = ElasticNet()\n",
    "\n",
    "clf = RandomizedSearchCV(en, parameters,cv=10, scoring='neg_root_mean_squared_error',return_train_score=True, n_jobs=-1)\n",
    "clf.fit(X_train_o,y_train_o)\n",
    "best_params_en_o = clf.best_params_\n",
    "model_en_o = ElasticNet(alpha= best_params_en_o['alpha'],l1_ratio = best_params_en_o['l1_ratio'])\n",
    "model_en_o.fit(X_train_o,y_train_o)\n",
    "pred = model_en_o.predict(X_test_o)\n",
    "rmse = sqrt(mean_squared_error(y_test_o, pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating SGD Regressor and performing hyper-parameter tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:282: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2629283275626014e+28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "parameters = {'penalty': ['l1','l2','elasticnet'],'learning_rate':['invscaling','optimal','constant']}\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "\n",
    "clf = RandomizedSearchCV(sgd, parameters,cv=10, scoring='neg_root_mean_squared_error',return_train_score=True, n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "best_params_sgd = clf.best_params_\n",
    "\n",
    "model = SGDRegressor(penalty= best_params_sgd['penalty'],learning_rate = best_params_sgd['learning_rate'],n_iter_no_change=9000,max_iter=5000000)\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Decision Tree model and performing hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7060775554389696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "param_grid = {\"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [6, 8, 10, 12],\n",
    "              \"min_samples_leaf\": [20, 40, 100],\n",
    "              \"max_leaf_nodes\": [5, 20, 100]\n",
    "             }\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "clf = RandomizedSearchCV(model, param_grid,cv=10, scoring='neg_root_mean_squared_error',return_train_score=True, n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "best_params_dtr = clf.best_params_\n",
    "\n",
    "dtr = DecisionTreeRegressor(min_samples_split= best_params_dtr['min_samples_split'],max_depth = best_params_dtr['max_depth'],min_samples_leaf = best_params_dtr['min_samples_leaf'],max_leaf_nodes = best_params_dtr['max_leaf_nodes'])\n",
    "\n",
    "\n",
    "dtr.fit(X_train,y_train)\n",
    "pred = dtr.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Decision Tree model and performing hyper-parameter tuning with outliner feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.593197244209849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "param_grid = {\"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [6, 8, 10, 12],\n",
    "              \"min_samples_leaf\": [20, 40, 100],\n",
    "              \"max_leaf_nodes\": [5, 20, 100]\n",
    "             }\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "clf = RandomizedSearchCV(model, param_grid,cv=10, scoring='neg_root_mean_squared_error',return_train_score=True, n_jobs=-1)\n",
    "clf.fit(X_train_o,y_train_o)\n",
    "\n",
    "best_params_dtr_o = clf.best_params_\n",
    "\n",
    "dtr_o = DecisionTreeRegressor(min_samples_split= best_params_dtr_o['min_samples_split'],max_depth = best_params_dtr_o['max_depth'],min_samples_leaf = best_params_dtr_o['min_samples_leaf'],max_leaf_nodes = best_params_dtr_o['max_leaf_nodes'])\n",
    "\n",
    "\n",
    "dtr_o.fit(X_train_o,y_train_o)\n",
    "pred = dtr_o.predict(X_test_o)\n",
    "rmse = sqrt(mean_squared_error(y_test_o, pred))\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Ada boost model and performing hyper-parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7269912403273437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 75, 100],\n",
    "    'learning_rate' : [0.01,0.1,0.3,1],\n",
    "    'loss' : ['square', 'exponential']\n",
    "    }\n",
    "\n",
    "model = AdaBoostRegressor()\n",
    "\n",
    "clf = RandomizedSearchCV(model, param_grid,cv=5, scoring='neg_root_mean_squared_error',return_train_score=True, n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "best_params_ada = clf.best_params_\n",
    "\n",
    "ada = AdaBoostRegressor(n_estimators= best_params_ada['n_estimators'],learning_rate = best_params_ada['learning_rate'],loss = best_params_ada['loss'])\n",
    "\n",
    "\n",
    "ada.fit(X_train,y_train)\n",
    "pred = ada.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "print(rmse) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Ada boost model and performing hyper-parameter tuning with outliner feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6306770711424232\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 75, 100],\n",
    "    'learning_rate' : [0.01,0.1,0.3,1],\n",
    "    'loss' : ['square', 'exponential']\n",
    "    }\n",
    "\n",
    "model = AdaBoostRegressor()\n",
    "\n",
    "clf = RandomizedSearchCV(model, param_grid,cv=5, scoring='neg_root_mean_squared_error',return_train_score=True, n_jobs=-1)\n",
    "clf.fit(X_train_o,y_train_o)\n",
    "\n",
    "best_params_ada_o = clf.best_params_\n",
    "\n",
    "ada_o = AdaBoostRegressor(n_estimators= best_params_ada_o['n_estimators'],learning_rate = best_params_ada_o['learning_rate'],loss = best_params_ada_o['loss'])\n",
    "\n",
    "\n",
    "ada_o.fit(X_train_o,y_train_o)\n",
    "pred = ada_o.predict(X_test_o)\n",
    "rmse = sqrt(mean_squared_error(y_test_o, pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Xgb regressor model and performing hyper-parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6501076773868677\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [ 0.01, 0.1,0.15, 0.2,0.25, 0.3] \n",
    "n_estimators=[50,60,65,70, 75,80,85, 100]\n",
    "min_child_weight = [6,8,9,10,11,12]\n",
    "subsample=[0.7,0.8,0.9,0.95,0.99,1]\n",
    "reg_alpha=[0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "parameters = {'learning_rate':learning_rate,'n_estimators':n_estimators,'min_child_weight':min_child_weight,'subsample':subsample,'reg_alpha':reg_alpha}\n",
    "xb1 = XGBRegressor(tree_method = 'gpu_hist', gpu_id=0)\n",
    "clf_1 = RandomizedSearchCV(xb1, parameters, cv=10, scoring='neg_root_mean_squared_error',return_train_score=True)\n",
    "clf_1.fit(X_train,y_train)\n",
    "best_params_xgb = clf_1.best_params_\n",
    "\n",
    "xgb = XGBRegressor(learning_rate = best_params_xgb['learning_rate'],n_estimators = best_params_xgb['n_estimators'],min_child_weight=best_params_xgb['min_child_weight'],subsample= best_params_xgb['subsample'],reg_alpha = best_params_xgb['reg_alpha'],gpu_id=0,tree_method = 'gpu_hist')\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "pred = xgb.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating XGB regressor model and performing hyper-parameter tuning with outliner feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.554238042708256\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [ 0.01, 0.1,0.15, 0.2,0.25, 0.3] \n",
    "n_estimators=[50,60,65,70, 75,80,85, 100]\n",
    "min_child_weight = [6,8,9,10,11,12]\n",
    "subsample=[0.7,0.8,0.9,0.95,0.99,1]\n",
    "reg_alpha=[0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "parameters = {'learning_rate':learning_rate,'n_estimators':n_estimators,'min_child_weight':min_child_weight,'subsample':subsample,'reg_alpha':reg_alpha}\n",
    "xb1 = XGBRegressor(tree_method = 'gpu_hist', gpu_id=0)\n",
    "clf_1 = RandomizedSearchCV(xb1, parameters, cv=10, scoring='neg_root_mean_squared_error',return_train_score=True)\n",
    "clf_1.fit(X_train_o,y_train_o)\n",
    "best_params_xgb_o = clf_1.best_params_\n",
    "\n",
    "xgb_o = XGBRegressor(learning_rate = best_params_xgb_o['learning_rate'],n_estimators = best_params_xgb_o['n_estimators'],min_child_weight=best_params_xgb_o['min_child_weight'],subsample= best_params_xgb_o['subsample'],reg_alpha = best_params_xgb_o['reg_alpha'],gpu_id=0,tree_method = 'gpu_hist')\n",
    "xgb_o.fit(X_train_o,y_train_o)\n",
    "\n",
    "pred = xgb_o.predict(X_test_o)\n",
    "rmse = sqrt(mean_squared_error(y_test_o, pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Bayesian model and performing hyper-parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7402949666454823\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_iter': [500,1000,2000],\n",
    "    'alpha_1' : [0.001,0.01,0.1,0.3,1],\n",
    "    'alpha_2' : [0.001,0.01,0.1,0.3,1],\n",
    "    'lambda_1' : [0.001,0.01,0.1,0.3,1],\n",
    "    'lambda_2' : [0.001,0.01,0.1,0.3,1]\n",
    "    }\n",
    "\n",
    "model = linear_model.BayesianRidge()\n",
    "\n",
    "clf = RandomizedSearchCV(model, param_grid,cv=5, scoring='neg_root_mean_squared_error',return_train_score=True, n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "best_params_br = clf.best_params_\n",
    "\n",
    "br = linear_model.BayesianRidge(n_iter= best_params_br['n_iter'],alpha_1 = best_params_br['alpha_1'],alpha_2 = best_params_br['alpha_2'],lambda_1 = best_params_br['lambda_1'],lambda_2 = best_params_br['lambda_2'])\n",
    "\n",
    "\n",
    "br.fit(X_train,y_train)\n",
    "pred = br.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating bayesian model and performing hyper-parameter tuning with outliner feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5993641916243255\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_iter': [500,1000,2000],\n",
    "    'alpha_1' : [0.001,0.01,0.1,0.3,1],\n",
    "    'alpha_2' : [0.001,0.01,0.1,0.3,1],\n",
    "    'lambda_1' : [0.001,0.01,0.1,0.3,1],\n",
    "    'lambda_2' : [0.001,0.01,0.1,0.3,1]\n",
    "    }\n",
    "\n",
    "model = linear_model.BayesianRidge()\n",
    "\n",
    "clf = RandomizedSearchCV(model, param_grid,cv=5, scoring='neg_root_mean_squared_error',return_train_score=True, n_jobs=-1)\n",
    "clf.fit(X_train_o,y_train_o)\n",
    "\n",
    "best_params_br_o = clf.best_params_\n",
    "\n",
    "br_o = linear_model.BayesianRidge(n_iter= best_params_br_o['n_iter'],alpha_1 = best_params_br_o['alpha_1'],alpha_2 = best_params_br_o['alpha_2'],lambda_1 = best_params_br_o['lambda_1'],lambda_2 = best_params_br_o['lambda_2'])\n",
    "\n",
    "\n",
    "br_o.fit(X_train_o,y_train_o)\n",
    "pred = br_o.predict(X_test_o)\n",
    "rmse = sqrt(mean_squared_error(y_test_o, pred))\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating varible which will predict the testing output for the test.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_out = test_all.drop(columns=['card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values\n",
    "final_test = test_all.drop(columns=['card_id','outliers','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting values with every model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_o_r = br_o.predict(final_test_out)\n",
    "br_r = br.predict(final_test)\n",
    "\n",
    "xgb_o_r = xgb_o.predict(final_test_out)\n",
    "xgb_r = xgb.predict(final_test)\n",
    "\n",
    "ada_o_r = ada_o.predict(final_test_out)\n",
    "ada_r = ada.predict(final_test)\n",
    "\n",
    "dtr_o_r = dtr_o.predict(final_test_out)\n",
    "dtr_r = dtr.predict(final_test)\n",
    "\n",
    "model_en_o_r = model_en_o.predict(final_test_out)\n",
    "model_en_r = model_en.predict(final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creting a data frame to store the result of predicted values with their respected card Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "submission = df[['card_id']]\n",
    "submission['br_o_r'] = br_o_r\n",
    "submission['br_r'] = br_r\n",
    "\n",
    "submission['xgb_o_r'] = xgb_o_r\n",
    "submission['xgb_r'] = xgb_r\n",
    "\n",
    "submission['ada_o_r'] = ada_o_r\n",
    "submission['ada_r'] = ada_r\n",
    "\n",
    "submission['dtr_o_r'] = dtr_o_r\n",
    "submission['dtr_r'] = dtr_r\n",
    "\n",
    "submission['model_en_o_r'] = model_en_o_r\n",
    "submission['model_en_r'] = model_en_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_pickle(\"target.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating stacking regressor model with  hyper-parameter tunned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1083443.620376189, tolerance: 226.390649578765\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 963046.9493537602, tolerance: 201.18117438479075\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 974732.3553838358, tolerance: 203.7087790016957\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 979067.653005082, tolerance: 204.74505313545177\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 985488.8138675529, tolerance: 205.96116145191888\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 976877.7739909192, tolerance: 204.15440534451753\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 973415.0224726897, tolerance: 203.32219486524414\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 971111.6828058077, tolerance: 203.0340797998514\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 980192.4652175003, tolerance: 204.74019332275049\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 969650.8591119559, tolerance: 202.70517670835454\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 976253.1695792788, tolerance: 203.96236427140335\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "3.664839674032196\n"
     ]
    }
   ],
   "source": [
    "level0 = list()\n",
    "level0.append(('en', ElasticNet(alpha= best_params_en['alpha'],l1_ratio = best_params_en['l1_ratio'])))\n",
    "level0.append(('br', linear_model.BayesianRidge(n_iter= best_params_br['n_iter'],alpha_1 = best_params_br['alpha_1'],alpha_2 = best_params_br['alpha_2'],lambda_1 = best_params_br['lambda_1'],lambda_2 = best_params_br['lambda_2'])))\n",
    "level0.append(('dtr', DecisionTreeRegressor(min_samples_split= best_params_dtr['min_samples_split'],max_depth = best_params_dtr['max_depth'],min_samples_leaf = best_params_dtr['min_samples_leaf'],max_leaf_nodes = best_params_dtr['max_leaf_nodes'])))\n",
    "level0.append(('ada', AdaBoostRegressor(n_estimators= best_params_ada['n_estimators'],learning_rate = best_params_ada['learning_rate'],loss = best_params_ada['loss'])))\n",
    "level0.append(('xgb', XGBRegressor(learning_rate = best_params_xgb['learning_rate'],n_estimators = best_params_xgb['n_estimators'],min_child_weight=best_params_xgb['min_child_weight'],subsample= best_params_xgb['subsample'],reg_alpha = best_params_xgb['reg_alpha'])))\n",
    "# define meta learner model\n",
    "level1 = LGBMRegressor(learning_rate= best_params_lgbm['learning_rate'],bagging_fraction=best_params_lgbm['bagging_fraction'],\n",
    "                       reg_alpha=best_params_lgbm['reg_alpha'],num_leaves =best_params_lgbm['num_leaves'],\n",
    "                       min_data_in_leaf =best_params_lgbm['min_data_in_leaf'],max_depth =best_params_lgbm['max_depth'],\n",
    "                       reg_lambda=best_params_lgbm['reg_lambda'],bagging_freq=best_params_lgbm['bagging_freq'],metric='rmse')\n",
    "# define the stacking ensemble\n",
    "f_model = StackingRegressor(estimators=level0, final_estimator=level1, cv=10)\n",
    "# fit the model on all available data\n",
    "f_model.fit(X_train, y_train)\n",
    "# make a prediction \n",
    "yhat = f_model.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, yhat))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating stacking regressor model with  hyper-parameter tunned models with outliner feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 993365.1851247031, tolerance: 224.90272119558125\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 867513.4599036118, tolerance: 196.3356294855271\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 866826.3498980346, tolerance: 196.12935009137306\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 867776.5063355251, tolerance: 196.52952019837517\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 880738.1817730789, tolerance: 199.81953530736274\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 868456.6968221765, tolerance: 196.56565526528007\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 866966.1514907833, tolerance: 196.1718464811538\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 872630.8708914635, tolerance: 197.78563052428464\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 861919.0081195429, tolerance: 194.9801130314288\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "1.5547978267610942\n"
     ]
    }
   ],
   "source": [
    "level0 = list()\n",
    "level0.append(('en', ElasticNet(alpha= best_params_en_o['alpha'],l1_ratio = best_params_en_o['l1_ratio'])))\n",
    "level0.append(('br', linear_model.BayesianRidge(n_iter= best_params_br_o['n_iter'],alpha_1 = best_params_br_o['alpha_1'],alpha_2 = best_params_br_o['alpha_2'],lambda_1 = best_params_br_o['lambda_1'],lambda_2 = best_params_br['lambda_2'])))\n",
    "level0.append(('dtr', DecisionTreeRegressor(min_samples_split= best_params_dtr_o['min_samples_split'],max_depth = best_params_dtr_o['max_depth'],min_samples_leaf = best_params_dtr_o['min_samples_leaf'],max_leaf_nodes = best_params_dtr_o['max_leaf_nodes'])))\n",
    "level0.append(('ada', AdaBoostRegressor(n_estimators= best_params_ada['n_estimators'],learning_rate = best_params_ada_o['learning_rate'],loss = best_params_ada_o['loss'])))\n",
    "level0.append(('xgb', XGBRegressor(learning_rate = best_params_xgb_o['learning_rate'],n_estimators = best_params_xgb_o['n_estimators'],min_child_weight=best_params_xgb_o['min_child_weight'],subsample= best_params_xgb_o['subsample'],reg_alpha = best_params_xgb_o['reg_alpha'],gpu_id=0,tree_method = 'gpu_hist')))\n",
    "# define meta learner model\n",
    "level1 = LGBMRegressor(learning_rate= best_params_lgbm_o['learning_rate'],bagging_fraction=best_params_lgbm_o['bagging_fraction'],\n",
    "                        reg_alpha=best_params_lgbm_o['reg_alpha'],num_leaves =best_params_lgbm_o['num_leaves'],\n",
    "                        min_data_in_leaf =best_params_lgbm_o['min_data_in_leaf'],max_depth =best_params_lgbm_o['max_depth'],\n",
    "                        reg_lambda=best_params_lgbm_o['reg_lambda'],bagging_freq=best_params_lgbm_o['bagging_freq'],metric='rmse')\n",
    "# define the stacking ensemble\n",
    "f_model_o = StackingRegressor(estimators=level0, final_estimator=level1, cv=8)\n",
    "# fit the model on all available data\n",
    "f_model_o.fit(X_train_o, y_train_o)\n",
    "# make a prediction \n",
    "yhat = f_model_o.predict(X_test_o)\n",
    "rmse = sqrt(mean_squared_error(y_test_o, yhat))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = f_model_o.predict(final_test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_o = f_model.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['stacking'] = result_o\n",
    "submission['stacking_o'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_pickle(\"target.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering their are no outliner in test and giving 0 to every outliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all['outliers'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_temp = test_all.drop(columns=['card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_out = f_model_o.predict(final_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['temp_out'] = temp_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Out of fold model with  hyper-parameter tunned models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1027910.016048406, tolerance: 214.81769880411514\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1028341.734835623, tolerance: 214.86106669502175\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1028066.8167800317, tolerance: 214.7607729524388\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1030719.5298464347, tolerance: 215.3929861907167\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1034399.0484804828, tolerance: 216.1179324447671\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1019802.2895177675, tolerance: 213.05606776855225\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1026465.6211066679, tolerance: 214.46725826861962\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1035692.0438792561, tolerance: 216.56061588817286\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1032284.6727322227, tolerance: 215.76493520922523\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1027245.6605040927, tolerance: 214.62251265743947\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1031900.763342582, tolerance: 215.53810720208708\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1038202.3048599215, tolerance: 217.09699145424608\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1025264.2974604941, tolerance: 214.29650509800305\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1028038.8265407867, tolerance: 214.83960732501524\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1027525.7754783656, tolerance: 214.74790503628617\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1030550.3083988307, tolerance: 215.24659179588878\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1027098.198391915, tolerance: 214.5815692693714\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1028238.7783281069, tolerance: 214.90186540186426\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1025118.7357180219, tolerance: 214.27619090661216\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1031380.9738834011, tolerance: 215.47402428769848\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Meta  (151437, 10) (151437,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1083443.620376189, tolerance: 226.390649578765\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "LinearRegression: RMSE 3.693\n",
      "ElasticNet: RMSE 3.779\n",
      "BayesianRidge: RMSE 3.740\n",
      "DecisionTreeRegressor: RMSE 3.706\n",
      "XGBRegressor: RMSE 3.649\n",
      "AdaBoostRegressor: RMSE 3.735\n",
      "BaggingRegressor: RMSE 3.937\n",
      "RandomForestRegressor: RMSE 3.947\n",
      "ExtraTreesRegressor: RMSE 3.893\n",
      "LGBMRegressor: RMSE 3.674\n",
      "Super Learner: RMSE 3.678\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import hstack\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    " \n",
    "# create a list of base-models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LinearRegression())\n",
    "    models.append(ElasticNet(alpha= best_params_en['alpha'],l1_ratio = best_params_en['l1_ratio']))\n",
    "    models.append(linear_model.BayesianRidge(n_iter= best_params_br['n_iter'],alpha_1 = best_params_br['alpha_1'],alpha_2 = best_params_br['alpha_2'],lambda_1 = best_params_br['lambda_1'],lambda_2 = best_params_br['lambda_2']))\n",
    "    models.append(DecisionTreeRegressor(min_samples_split= best_params_dtr['min_samples_split'],max_depth = best_params_dtr['max_depth'],min_samples_leaf = best_params_dtr['min_samples_leaf'],max_leaf_nodes = best_params_dtr['max_leaf_nodes']))\n",
    "    models.append(XGBRegressor(learning_rate = best_params_xgb['learning_rate'],n_estimators = best_params_xgb['n_estimators'],min_child_weight=best_params_xgb['min_child_weight'],subsample= best_params_xgb['subsample'],reg_alpha = best_params_xgb['reg_alpha']))\n",
    "    models.append(AdaBoostRegressor(n_estimators= best_params_ada['n_estimators'],learning_rate = best_params_ada['learning_rate'],loss = best_params_ada['loss']))\n",
    "    models.append(BaggingRegressor(n_estimators=10))\n",
    "    models.append(RandomForestRegressor(n_estimators=10))\n",
    "    models.append(ExtraTreesRegressor(n_estimators=10))\n",
    "    models.append(LGBMRegressor(learning_rate= best_params_lgbm['learning_rate'],bagging_fraction=best_params_lgbm['bagging_fraction'],reg_alpha=best_params_lgbm['reg_alpha'],num_leaves =best_params_lgbm['num_leaves'],min_data_in_leaf =best_params_lgbm['min_data_in_leaf'],max_depth =best_params_lgbm['max_depth'],reg_lambda=best_params_lgbm['reg_lambda'],bagging_freq=best_params_lgbm['bagging_freq'],metric='rmse'))\n",
    "    return models\n",
    " \n",
    "# collect out of fold predictions form k-fold cross validation\n",
    "def get_out_of_fold_predictions(X, y, models):\n",
    "    meta_X, meta_y = list(), list()\n",
    "    # define split of data\n",
    "    kfold = KFold(n_splits=20, shuffle=True)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        fold_yhats = list()\n",
    "        # get data\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        meta_y.extend(test_y)\n",
    "        # fit and make predictions with each sub-model\n",
    "        for model in models:\n",
    "            model.fit(train_X, train_y)\n",
    "            yhat = model.predict(test_X)\n",
    "            # store columns\n",
    "            fold_yhats.append(yhat.reshape(len(yhat),1))\n",
    "        # store fold yhats as columns\n",
    "        meta_X.append(hstack(fold_yhats))\n",
    "    return vstack(meta_X), asarray(meta_y)\n",
    " \n",
    "# fit all base models on the training dataset\n",
    "def fit_base_models(X, y, models):\n",
    "    for model in models:\n",
    "        model.fit(X, y)\n",
    "\n",
    "# fit a meta model\n",
    "def fit_meta_model(X, y):\n",
    "    model = ElasticNet()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    " \n",
    "# evaluate a list of models on a dataset\n",
    "def evaluate_models(X, y, models):\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        mse = mean_squared_error(y, yhat)\n",
    "        print('%s: RMSE %.3f' % (model.__class__.__name__, sqrt(mse)))\n",
    "\n",
    "# make predictions with stacked model\n",
    "def super_learner_predictions(X, models, meta_model):\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        meta_X.append(yhat.reshape(len(yhat),1))\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return meta_model.predict(meta_X)\n",
    " \n",
    "\n",
    "models = get_models()\n",
    "# get out of fold predictions\n",
    "meta_X, meta_y = get_out_of_fold_predictions(X_train, y_train, models)\n",
    "print('Meta ', meta_X.shape, meta_y.shape)\n",
    "# fit base models\n",
    "fit_base_models(X_train, y_train, models)\n",
    "# fit the meta model\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "# evaluate base models\n",
    "evaluate_models(X_test, y_test, models)\n",
    "# evaluate meta model\n",
    "yhat = super_learner_predictions(X_test, models, meta_model)\n",
    "print('Super Learner: RMSE %.3f' % (sqrt(mean_squared_error(y_test, yhat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: RMSE 44.520\n",
      "ElasticNet: RMSE 52.950\n",
      "BayesianRidge: RMSE 47.298\n",
      "DecisionTreeRegressor: RMSE 3.700\n",
      "XGBRegressor: RMSE 3.646\n",
      "AdaBoostRegressor: RMSE 3.727\n",
      "BaggingRegressor: RMSE 3.921\n",
      "RandomForestRegressor: RMSE 3.917\n",
      "ExtraTreesRegressor: RMSE 3.895\n",
      "LGBMRegressor: RMSE 3.674\n",
      "Super Learner: RMSE 3.762\n"
     ]
    }
   ],
   "source": [
    "def fit_meta_model(X, y):\n",
    "    model = XGBRegressor()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "# evaluate base models\n",
    "evaluate_models(X_test, y_test, models)\n",
    "# evaluate meta model\n",
    "yhat = super_learner_predictions(X_test, models, meta_model)\n",
    "print('Super Learner: RMSE %.3f' % (sqrt(mean_squared_error(y_test, yhat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: RMSE 44.520\n",
      "ElasticNet: RMSE 52.950\n",
      "BayesianRidge: RMSE 47.298\n",
      "DecisionTreeRegressor: RMSE 3.700\n",
      "XGBRegressor: RMSE 3.646\n",
      "AdaBoostRegressor: RMSE 3.727\n",
      "BaggingRegressor: RMSE 3.921\n",
      "RandomForestRegressor: RMSE 3.917\n",
      "ExtraTreesRegressor: RMSE 3.895\n",
      "LGBMRegressor: RMSE 3.674\n",
      "Super Learner: RMSE 3.674\n"
     ]
    }
   ],
   "source": [
    "def fit_meta_model(X, y):\n",
    "    model = LGBMRegressor()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "# evaluate base models\n",
    "evaluate_models(X_test, y_test, models)\n",
    "# evaluate meta model\n",
    "yhat = super_learner_predictions(X_test, models, meta_model)\n",
    "print('Super Learner: RMSE %.3f' % (sqrt(mean_squared_error(y_test, yhat))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Out of fold model without hyper-parameter tunned models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import hstack\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LinearRegression())\n",
    "    models.append(ElasticNet())\n",
    "    models.append(DecisionTreeRegressor())\n",
    "    models.append(XGBRegressor())\n",
    "    models.append(AdaBoostRegressor())\n",
    "    models.append(BaggingRegressor(n_estimators=10))\n",
    "    models.append(RandomForestRegressor(n_estimators=10))\n",
    "    models.append(ExtraTreesRegressor(n_estimators=10))\n",
    "    models.append(LGBMRegressor(metric='rmse'))\n",
    "    return models\n",
    " \n",
    "# collect out of fold predictions form k-fold cross validation\n",
    "def get_out_of_fold_predictions(X, y, models):\n",
    "    meta_X, meta_y = list(), list()\n",
    "    # define split of data\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        fold_yhats = list()\n",
    "        # get data\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        meta_y.extend(test_y)\n",
    "        # fit and make predictions with each sub-model\n",
    "        for model in models:\n",
    "            model.fit(train_X, train_y)\n",
    "            yhat = model.predict(test_X)\n",
    "            # store columns\n",
    "            fold_yhats.append(yhat.reshape(len(yhat),1))\n",
    "        # store fold yhats as columns\n",
    "        meta_X.append(hstack(fold_yhats))\n",
    "    return vstack(meta_X), asarray(meta_y)\n",
    " \n",
    "# fit all base models on the training dataset\n",
    "def fit_base_models(X, y, models):\n",
    "    for model in models:\n",
    "        model.fit(X, y)\n",
    "\n",
    "# fit a meta model\n",
    "def fit_meta_model(X, y):\n",
    "    model = BayesianRidge()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    " \n",
    "# evaluate a list of models on a dataset\n",
    "def evaluate_models(X, y, models):\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        mse = mean_squared_error(y, yhat)\n",
    "        print('%s: RMSE %.3f' % (model.__class__.__name__, sqrt(mse)))\n",
    "\n",
    "# make predictions with stacked model\n",
    "def super_learner_predictions_out(X, models, meta_model):\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        meta_X.append(yhat.reshape(len(yhat),1))\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return meta_model.predict(meta_X)\n",
    " \n",
    "\n",
    "models = get_models()\n",
    "# get out of fold predictions\n",
    "meta_X, meta_y = get_out_of_fold_predictions(X_train, y_train, models)\n",
    "print('Meta ', meta_X.shape, meta_y.shape)\n",
    "# fit base models\n",
    "fit_base_models(X_train, y_train, models)\n",
    "# fit the meta model\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "# evaluate base models\n",
    "evaluate_models(X_test, y_test, models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super Learner: RMSE 3.855\n"
     ]
    }
   ],
   "source": [
    "yhat_non_out_no_para = super_learner_predictions_out(X_test, models, meta_model)\n",
    "print('Super Learner: RMSE %.3f' % (sqrt(mean_squared_error(y_test, yhat_non_out_no_para))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat_oof = super_learner_predictions(final_test_out, models, meta_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Out of fold model with  hyper-parameter tunned models with outliner feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 994451.3559277557, tolerance: 204.13538118492397\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 978856.9715615674, tolerance: 200.8376809454645\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 986576.1029607884, tolerance: 202.49483051242174\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 982498.9362816437, tolerance: 201.58477688097267\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 992826.694715264, tolerance: 203.6579347307069\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 985523.1870759464, tolerance: 202.28540224618857\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 984554.5605624662, tolerance: 202.11557545349305\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 989323.1759190705, tolerance: 202.96905704539856\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 989645.3792412402, tolerance: 202.9021656206729\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 979818.2404786986, tolerance: 201.14100415202947\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Meta  (151437, 10) (151437,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1096072.6078795192, tolerance: 224.90272119558125\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "LinearRegression: RMSE 1.598\n",
      "ElasticNet: RMSE 3.790\n",
      "BayesianRidge: RMSE 1.599\n",
      "DecisionTreeRegressor: RMSE 1.593\n",
      "XGBRegressor: RMSE 1.554\n",
      "AdaBoostRegressor: RMSE 1.631\n",
      "BaggingRegressor: RMSE 1.653\n",
      "RandomForestRegressor: RMSE 1.651\n",
      "ExtraTreesRegressor: RMSE 1.653\n",
      "LGBMRegressor: RMSE 1.554\n",
      "Super Learner: RMSE 1.551\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# create a list of base-models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LinearRegression())\n",
    "    models.append(ElasticNet(alpha= best_params_en_o['alpha'],l1_ratio = best_params_en_o['l1_ratio']))\n",
    "    models.append(linear_model.BayesianRidge(n_iter= best_params_br_o['n_iter'],alpha_1 = best_params_br_o['alpha_1'],alpha_2 = best_params_br_o['alpha_2'],lambda_1 = best_params_br_o['lambda_1'],lambda_2 = best_params_br_o['lambda_2']))\n",
    "    models.append(DecisionTreeRegressor(min_samples_split= best_params_dtr_o['min_samples_split'],max_depth = best_params_dtr_o['max_depth'],min_samples_leaf = best_params_dtr_o['min_samples_leaf'],max_leaf_nodes = best_params_dtr_o['max_leaf_nodes']))\n",
    "    models.append(XGBRegressor(learning_rate = best_params_xgb_o['learning_rate'],n_estimators = best_params_xgb_o['n_estimators'],min_child_weight=best_params_xgb_o['min_child_weight'],subsample= best_params_xgb_o['subsample'],reg_alpha = best_params_xgb_o['reg_alpha'],gpu_id=0,tree_method = 'gpu_hist'))\n",
    "    models.append(AdaBoostRegressor(n_estimators= best_params_ada_o['n_estimators'],learning_rate = best_params_ada_o['learning_rate'],loss = best_params_ada_o['loss']))\n",
    "    models.append(BaggingRegressor(n_estimators=10))\n",
    "    models.append(RandomForestRegressor(n_estimators=10))\n",
    "    models.append(ExtraTreesRegressor(n_estimators=10))\n",
    "    models.append(LGBMRegressor(learning_rate= best_params_lgbm_o['learning_rate'],bagging_fraction=best_params_lgbm_o['bagging_fraction'],reg_alpha=best_params_lgbm_o['reg_alpha'],num_leaves =best_params_lgbm_o['num_leaves'],min_data_in_leaf =best_params_lgbm_o['min_data_in_leaf'],max_depth =best_params_lgbm_o['max_depth'],reg_lambda=best_params_lgbm_o['reg_lambda'],bagging_freq=best_params_lgbm_o['bagging_freq'],metric='rmse'))\n",
    "    return models\n",
    " \n",
    "# collect out of fold predictions form k-fold cross validation\n",
    "def get_out_of_fold_predictions(X, y, models):\n",
    "    meta_X, meta_y = list(), list()\n",
    "    # define split of data\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        fold_yhats = list()\n",
    "        # get data\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        meta_y.extend(test_y)\n",
    "        # fit and make predictions with each sub-model\n",
    "        for model in models:\n",
    "            model.fit(train_X, train_y)\n",
    "            yhat = model.predict(test_X)\n",
    "            # store columns\n",
    "            fold_yhats.append(yhat.reshape(len(yhat),1))\n",
    "        # store fold yhats as columns\n",
    "        meta_X.append(hstack(fold_yhats))\n",
    "    return vstack(meta_X), asarray(meta_y)\n",
    " \n",
    "# fit all base models on the training dataset\n",
    "def fit_base_models(X, y, models):\n",
    "    for model in models:\n",
    "        model.fit(X, y)\n",
    "\n",
    "# fit a meta model\n",
    "def fit_meta_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    " \n",
    "# evaluate a list of models on a dataset\n",
    "def evaluate_models(X, y, models):\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        mse = mean_squared_error(y, yhat)\n",
    "        print('%s: RMSE %.3f' % (model.__class__.__name__, sqrt(mse)))\n",
    "\n",
    "# make predictions with stacked model\n",
    "def super_learner_predictions_out(X, models, meta_model):\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        meta_X.append(yhat.reshape(len(yhat),1))\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return meta_model.predict(meta_X)\n",
    " \n",
    "\n",
    "models = get_models()\n",
    "# get out of fold predictions\n",
    "meta_X, meta_y = get_out_of_fold_predictions(X_train_o, y_train_o, models)\n",
    "print('Meta ', meta_X.shape, meta_y.shape)\n",
    "# fit base models\n",
    "fit_base_models(X_train_o, y_train_o, models)\n",
    "# fit the meta model\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "# evaluate base models\n",
    "evaluate_models(X_test_o, y_test_o, models)\n",
    "# evaluate meta model\n",
    "yhat = super_learner_predictions_out(X_test_o, models, meta_model)\n",
    "print('Super Learner: RMSE %.3f' % (sqrt(mean_squared_error(y_test_o, yhat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_pickle('test_all_outliner.pkl')\n",
    "final_test = temp.drop(columns=['card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values\n",
    "y_hat_with_out = super_learner_predictions_out(final_test, models, meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['stack_oof_o'] = y_hat_with_out\n",
    "target['stack_oof'] = yhat_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.to_pickle('target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbgm_pred = model_1.predict(final_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_pickle('target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['lbgm_pred'] = lbgm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>br_o_r</th>\n",
       "      <th>br_r</th>\n",
       "      <th>xgb_o_r</th>\n",
       "      <th>xgb_r</th>\n",
       "      <th>ada_o_r</th>\n",
       "      <th>ada_r</th>\n",
       "      <th>dtr_o_r</th>\n",
       "      <th>dtr_r</th>\n",
       "      <th>model_en_o_r</th>\n",
       "      <th>model_en_r</th>\n",
       "      <th>stacking</th>\n",
       "      <th>stacking_o</th>\n",
       "      <th>stack_oof_o</th>\n",
       "      <th>stack_oof</th>\n",
       "      <th>oof_non_out</th>\n",
       "      <th>oof_non_out_nopara</th>\n",
       "      <th>stack_no_out</th>\n",
       "      <th>stack_no_out_para</th>\n",
       "      <th>lbgm_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-33.700006</td>\n",
       "      <td>-2.150192</td>\n",
       "      <td>-33.158463</td>\n",
       "      <td>-3.967904</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-2.538394</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-2.210368</td>\n",
       "      <td>-5.183550</td>\n",
       "      <td>-1.959440</td>\n",
       "      <td>-2.900542</td>\n",
       "      <td>-33.024661</td>\n",
       "      <td>-33.222214</td>\n",
       "      <td>-3.360535</td>\n",
       "      <td>-0.220527</td>\n",
       "      <td>-0.341691</td>\n",
       "      <td>-0.395160</td>\n",
       "      <td>-0.311781</td>\n",
       "      <td>-1.595954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.630376</td>\n",
       "      <td>-1.209783</td>\n",
       "      <td>-0.250791</td>\n",
       "      <td>-0.199351</td>\n",
       "      <td>-0.200819</td>\n",
       "      <td>-0.228062</td>\n",
       "      <td>-0.231458</td>\n",
       "      <td>-3.204083</td>\n",
       "      <td>-0.965219</td>\n",
       "      <td>-1.018610</td>\n",
       "      <td>-0.233773</td>\n",
       "      <td>-0.283789</td>\n",
       "      <td>-0.296430</td>\n",
       "      <td>-0.335824</td>\n",
       "      <td>-0.252786</td>\n",
       "      <td>-0.207790</td>\n",
       "      <td>-0.282106</td>\n",
       "      <td>-0.129126</td>\n",
       "      <td>-0.203021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.603817</td>\n",
       "      <td>-1.188017</td>\n",
       "      <td>-0.215734</td>\n",
       "      <td>-1.306369</td>\n",
       "      <td>-0.741702</td>\n",
       "      <td>-0.801687</td>\n",
       "      <td>-0.987153</td>\n",
       "      <td>-1.620944</td>\n",
       "      <td>-0.477401</td>\n",
       "      <td>-0.510554</td>\n",
       "      <td>-1.133542</td>\n",
       "      <td>-0.298779</td>\n",
       "      <td>-0.452169</td>\n",
       "      <td>-1.241228</td>\n",
       "      <td>-0.781512</td>\n",
       "      <td>-0.503496</td>\n",
       "      <td>-0.484446</td>\n",
       "      <td>-0.410551</td>\n",
       "      <td>-0.912625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.187282</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>0.014168</td>\n",
       "      <td>-0.137127</td>\n",
       "      <td>-0.200819</td>\n",
       "      <td>-0.228062</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>-3.204083</td>\n",
       "      <td>-0.254504</td>\n",
       "      <td>-0.227652</td>\n",
       "      <td>-0.178881</td>\n",
       "      <td>-0.013869</td>\n",
       "      <td>-0.084705</td>\n",
       "      <td>0.039719</td>\n",
       "      <td>-0.057083</td>\n",
       "      <td>-0.065306</td>\n",
       "      <td>-0.062662</td>\n",
       "      <td>-0.103893</td>\n",
       "      <td>-0.204388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-2.588666</td>\n",
       "      <td>-2.758021</td>\n",
       "      <td>-1.265175</td>\n",
       "      <td>-0.839355</td>\n",
       "      <td>-0.741702</td>\n",
       "      <td>-0.798787</td>\n",
       "      <td>-0.978239</td>\n",
       "      <td>-1.543981</td>\n",
       "      <td>-2.026128</td>\n",
       "      <td>-2.038432</td>\n",
       "      <td>-0.802406</td>\n",
       "      <td>-1.275639</td>\n",
       "      <td>-1.177096</td>\n",
       "      <td>-1.003892</td>\n",
       "      <td>-1.265887</td>\n",
       "      <td>-1.334409</td>\n",
       "      <td>-1.288947</td>\n",
       "      <td>-1.205569</td>\n",
       "      <td>-0.831957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id     br_o_r      br_r    xgb_o_r     xgb_r    ada_o_r  \\\n",
       "0  C_ID_0ab67a22ab -33.700006 -2.150192 -33.158463 -3.967904 -33.219281   \n",
       "1  C_ID_130fd0cbdd  -0.630376 -1.209783  -0.250791 -0.199351  -0.200819   \n",
       "2  C_ID_b709037bc5  -0.603817 -1.188017  -0.215734 -1.306369  -0.741702   \n",
       "3  C_ID_d27d835a9f  -0.187282 -0.015526   0.014168 -0.137127  -0.200819   \n",
       "4  C_ID_2b5e3df5c2  -2.588666 -2.758021  -1.265175 -0.839355  -0.741702   \n",
       "\n",
       "      ada_r    dtr_o_r     dtr_r  model_en_o_r  model_en_r  stacking  \\\n",
       "0 -2.538394 -33.219281 -2.210368     -5.183550   -1.959440 -2.900542   \n",
       "1 -0.228062  -0.231458 -3.204083     -0.965219   -1.018610 -0.233773   \n",
       "2 -0.801687  -0.987153 -1.620944     -0.477401   -0.510554 -1.133542   \n",
       "3 -0.228062   0.006248 -3.204083     -0.254504   -0.227652 -0.178881   \n",
       "4 -0.798787  -0.978239 -1.543981     -2.026128   -2.038432 -0.802406   \n",
       "\n",
       "   stacking_o  stack_oof_o  stack_oof  oof_non_out  oof_non_out_nopara  \\\n",
       "0  -33.024661   -33.222214  -3.360535    -0.220527           -0.341691   \n",
       "1   -0.283789    -0.296430  -0.335824    -0.252786           -0.207790   \n",
       "2   -0.298779    -0.452169  -1.241228    -0.781512           -0.503496   \n",
       "3   -0.013869    -0.084705   0.039719    -0.057083           -0.065306   \n",
       "4   -1.275639    -1.177096  -1.003892    -1.265887           -1.334409   \n",
       "\n",
       "   stack_no_out  stack_no_out_para  lbgm_pred  \n",
       "0     -0.395160          -0.311781  -1.595954  \n",
       "1     -0.282106          -0.129126  -0.203021  \n",
       "2     -0.484446          -0.410551  -0.912625  \n",
       "3     -0.062662          -0.103893  -0.204388  \n",
       "4     -1.288947          -1.205569  -0.831957  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking avg of all the models without outliner features and including some models with outliners which gave good result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['target'] = (target['br_r'] +  target['xgb_r'] +  target['ada_r'] + target['dtr_r'] + target['model_en_r'] + 3 *target['stacking']+3.5 *target['stack_oof']+target['oof_non_out']+target['oof_non_out_nopara']+target['stack_no_out'])/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = target[['card_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-3.424717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.847928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-1.494195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.439513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.778866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -3.424717\n",
       "1  C_ID_130fd0cbdd -0.847928\n",
       "2  C_ID_b709037bc5 -1.494195\n",
       "3  C_ID_d27d835a9f -0.439513\n",
       "4  C_ID_2b5e3df5c2 -1.778866"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking features which are important and then creating feature set to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_lbgm = pd.DataFrame(sorted(zip(model_1.feature_importances_,train_all.columns)), columns=['Value','Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = feature_imp_lbgm[feature_imp_lbgm.Value > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>42</td>\n",
       "      <td>all_trans_purchase_amount_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>42</td>\n",
       "      <td>days_feature1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>43</td>\n",
       "      <td>all_time_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>43</td>\n",
       "      <td>avg_new_card_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>43</td>\n",
       "      <td>new_tr_n_amount_month_ratio_mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Value                           Feature\n",
       "252     42     all_trans_purchase_amount_min\n",
       "253     42                     days_feature1\n",
       "254     43                     all_time_diff\n",
       "255     43                  avg_new_card_use\n",
       "256     43  new_tr_n_amount_month_ratio_mean"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = cols['Feature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = train_all[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imp_x = df_temp.drop(columns=['all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_y = train_all['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(Imp_x, imp_y, random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.668890714002883\n"
     ]
    }
   ],
   "source": [
    "level0 = list()\n",
    "level0.append(('en', ElasticNet()))\n",
    "level0.append(('br', BayesianRidge()))\n",
    "level0.append(('dtr', DecisionTreeRegressor()))\n",
    "level0.append(('ada', AdaBoostRegressor()))\n",
    "level0.append(('xgb', XGBRegressor()))\n",
    "# define meta learner model\n",
    "level1 = LGBMRegressor(metric='rmse')\n",
    "# define the stacking ensemble\n",
    "f_model_imp_x = StackingRegressor(estimators=level0, final_estimator=level1, cv=10)\n",
    "# fit the model on all available data\n",
    "f_model_imp_x.fit(X_train_imp, y_train_imp)\n",
    "# make a prediction \n",
    "yhat = f_model_imp_x.predict(X_test_imp)\n",
    "rmse = sqrt(mean_squared_error(y_test_imp, yhat))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta  (151437, 9) (151437,)\n",
      "LinearRegression: RMSE 3.756\n",
      "ElasticNet: RMSE 3.786\n",
      "DecisionTreeRegressor: RMSE 5.558\n",
      "XGBRegressor: RMSE 3.723\n",
      "AdaBoostRegressor: RMSE 7.038\n",
      "BaggingRegressor: RMSE 3.940\n",
      "RandomForestRegressor: RMSE 3.924\n",
      "ExtraTreesRegressor: RMSE 3.946\n",
      "LGBMRegressor: RMSE 3.679\n",
      "Super Learner: RMSE 3.667\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import hstack\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LinearRegression())\n",
    "    models.append(ElasticNet())\n",
    "    models.append(DecisionTreeRegressor())\n",
    "    models.append(XGBRegressor(gpu_id=0,tree_method = 'gpu_hist'.0))\n",
    "    models.append(AdaBoostRegressor())\n",
    "    models.append(BaggingRegressor(n_estimators=10))\n",
    "    models.append(RandomForestRegressor(n_estimators=10))\n",
    "    models.append(ExtraTreesRegressor(n_estimators=10))\n",
    "    models.append(LGBMRegressor(metric='rmse'))\n",
    "    return models\n",
    " \n",
    "# collect out of fold predictions form k-fold cross validation\n",
    "def get_out_of_fold_predictions(X, y, models):\n",
    "    meta_X, meta_y = list(), list()\n",
    "    # define split of data\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        fold_yhats = list()\n",
    "        # get data\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        meta_y.extend(test_y)\n",
    "        # fit and make predictions with each sub-model\n",
    "        for model in models:\n",
    "            model.fit(train_X, train_y)\n",
    "            yhat = model.predict(test_X)\n",
    "            # store columns\n",
    "            fold_yhats.append(yhat.reshape(len(yhat),1))\n",
    "        # store fold yhats as columns\n",
    "        meta_X.append(hstack(fold_yhats))\n",
    "    return vstack(meta_X), asarray(meta_y)\n",
    " \n",
    "# fit all base models on the training dataset\n",
    "def fit_base_models(X, y, models):\n",
    "    for model in models:\n",
    "        model.fit(X, y)\n",
    "\n",
    "# fit a meta model\n",
    "def fit_meta_model(X, y):\n",
    "    model = BayesianRidge()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    " \n",
    "# evaluate a list of models on a dataset\n",
    "def evaluate_models(X, y, models):\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        mse = mean_squared_error(y, yhat)\n",
    "        print('%s: RMSE %.3f' % (model.__class__.__name__, sqrt(mse)))\n",
    "\n",
    "# make predictions with stacked model\n",
    "def super_learner_predictions_imp(X, models, meta_model):\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        meta_X.append(yhat.reshape(len(yhat),1))\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return meta_model.predict(meta_X)\n",
    " \n",
    "\n",
    "models = get_models()\n",
    "# get out of fold predictions\n",
    "meta_X, meta_y = get_out_of_fold_predictions(X_train_imp, y_train_imp, models)\n",
    "print('Meta ', meta_X.shape, meta_y.shape)\n",
    "# fit base models\n",
    "fit_base_models(X_train_imp, y_train_imp, models)\n",
    "# fit the meta model\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "# evaluate base models\n",
    "evaluate_models(X_test_imp, y_test_imp, models)\n",
    "yhat = super_learner_predictions_imp(X_test_imp, models, meta_model)\n",
    "print('Super Learner: RMSE %.3f' % (sqrt(mean_squared_error(y_test_imp, yhat))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw there are values which are -33 so we are Adding 33 to the target variable and then creating a model to check to and see if can find any improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = train_all['target'] + 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sum, X_test_sum, y_train_sum, y_test_sum = train_test_split(X, y_val , random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333333333333333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8333333333333333\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111111111111111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111111111111111\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111111111111111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111111111111111\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111111111111111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111111111111111\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111111111111111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111111111111111\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111111111111111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111111111111111\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111111111111111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111111111111111\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111111111111111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111111111111111\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111111111111111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111111111111111\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111111111111111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111111111111111\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111111111111111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111111111111111\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8722222222222222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8722222222222222\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6777777777777778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6777777777777778\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7944444444444444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7944444444444444\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7166666666666667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7166666666666667\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "3.6839531866446515\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': list(range(60, 150, 15)),\n",
    "    'min_data_in_leaf': [90, 100, 110,120,130,140],\n",
    "    'min_child_samples': [20,25,30],\n",
    "    'max_depth': [8, 12, 16, 20],\n",
    "    'learning_rate': [0.1, 0.01, 0.005],\n",
    "    'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    'reg_lambda': np.linspace(0.1, 0.95, 10),\n",
    "    'n_estimators': [200, 400,600]\n",
    "}\n",
    "\n",
    "model = LGBMRegressor()\n",
    "\n",
    "clf_1 = RandomizedSearchCV(model, param_grid, cv=10, scoring='neg_root_mean_squared_error',return_train_score=True)\n",
    "clf_1.fit(X_train_sum,y_train_sum)\n",
    "\n",
    "best_params_lgbm = clf_1.best_params_\n",
    "\n",
    "model_1_sum = LGBMRegressor(learning_rate= best_params_lgbm['learning_rate'],bagging_fraction=best_params_lgbm['bagging_fraction'],\n",
    "                        reg_alpha=best_params_lgbm['reg_alpha'],num_leaves =best_params_lgbm['num_leaves'],\n",
    "                        min_data_in_leaf =best_params_lgbm['min_data_in_leaf'],max_depth =best_params_lgbm['max_depth'],\n",
    "                        reg_lambda=best_params_lgbm['reg_lambda'],bagging_freq=best_params_lgbm['bagging_freq'],metric='rmse')\n",
    "\n",
    "\n",
    "model_1_sum.fit(X_train_sum,y_train_sum)\n",
    "\n",
    "pred = model_1_sum.predict(X_test_sum)\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_test_sum, pred))\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1103814.5059998874, tolerance: 226.3965036299738\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 981026.5490654014, tolerance: 201.18640175135928\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 992962.9183868956, tolerance: 203.71407084287924\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 997941.754581631, tolerance: 204.75036709053\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1004033.9319372728, tolerance: 205.96648332564902\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 995355.4701347415, tolerance: 204.15960537629326\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 991854.4478520715, tolerance: 203.3274753701759\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 989644.0460775483, tolerance: 203.03932010322868\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 998486.7999956647, tolerance: 204.74547331480366\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 987928.3234653333, tolerance: 202.71040955611366\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 994689.380969921, tolerance: 203.96766217574245\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6652672385429295\n"
     ]
    }
   ],
   "source": [
    "level0 = list()\n",
    "level0.append(('en', ElasticNet()))\n",
    "level0.append(('br', BayesianRidge()))\n",
    "level0.append(('dtr', DecisionTreeRegressor()))\n",
    "level0.append(('ada', AdaBoostRegressor()))\n",
    "level0.append(('xgb', XGBRegressor()))\n",
    "# define meta learner model\n",
    "level1 = LGBMRegressor(metric='rmse')\n",
    "# define the stacking ensemble\n",
    "f_model_sum_x = StackingRegressor(estimators=level0, final_estimator=level1, cv=10)\n",
    "# fit the model on all available data\n",
    "f_model_sum_x.fit(X_train_sum, y_train_sum)\n",
    "# make a prediction \n",
    "yhat = f_model_sum_x.predict(X_test_sum)\n",
    "rmse = sqrt(mean_squared_error(y_test_sum, yhat))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 990974.6973120896, tolerance: 203.27211411864093\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 989390.0808979871, tolerance: 202.88049577113543\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 985886.1320161511, tolerance: 202.19496909781304\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1000195.8739579503, tolerance: 205.16832434247948\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 983667.925710106, tolerance: 201.78903927467238\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 981601.9958186939, tolerance: 201.26226526301434\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1010514.7334894895, tolerance: 207.37634115901358\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1014462.0123010753, tolerance: 208.11836514179697\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 990498.0761517085, tolerance: 203.0835256200572\n",
      "  positive)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 986674.3126277131, tolerance: 202.4187011688625\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta  (151437, 9) (151437,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1103814.5059998874, tolerance: 226.3965036299738\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: RMSE 44.520\n",
      "ElasticNet: RMSE 65.731\n",
      "DecisionTreeRegressor: RMSE 5.565\n",
      "XGBRegressor: RMSE 3.711\n",
      "AdaBoostRegressor: RMSE 7.460\n",
      "BaggingRegressor: RMSE 3.930\n",
      "RandomForestRegressor: RMSE 3.926\n",
      "ExtraTreesRegressor: RMSE 3.900\n",
      "LGBMRegressor: RMSE 3.656\n",
      "Super Learner: RMSE 23.039\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import hstack\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LinearRegression())\n",
    "    models.append(ElasticNet())\n",
    "    models.append(DecisionTreeRegressor())\n",
    "    models.append(XGBRegressor(gpu_id=0,tree_method = 'gpu_hist'))\n",
    "    models.append(AdaBoostRegressor())\n",
    "    models.append(BaggingRegressor(n_estimators=10))\n",
    "    models.append(RandomForestRegressor(n_estimators=10))\n",
    "    models.append(ExtraTreesRegressor(n_estimators=10))\n",
    "    models.append(LGBMRegressor(metric='rmse'))\n",
    "    return models\n",
    " \n",
    "# collect out of fold predictions form k-fold cross validation\n",
    "def get_out_of_fold_predictions(X, y, models):\n",
    "    meta_X, meta_y = list(), list()\n",
    "    # define split of data\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        fold_yhats = list()\n",
    "        # get data\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        meta_y.extend(test_y)\n",
    "        # fit and make predictions with each sub-model\n",
    "        for model in models:\n",
    "            model.fit(train_X, train_y)\n",
    "            yhat = model.predict(test_X)\n",
    "            # store columns\n",
    "            fold_yhats.append(yhat.reshape(len(yhat),1))\n",
    "        # store fold yhats as columns\n",
    "        meta_X.append(hstack(fold_yhats))\n",
    "    return vstack(meta_X), asarray(meta_y)\n",
    " \n",
    "# fit all base models on the training dataset\n",
    "def fit_base_models(X, y, models):\n",
    "    for model in models:\n",
    "        model.fit(X, y)\n",
    "\n",
    "# fit a meta model\n",
    "def fit_meta_model(X, y):\n",
    "    model = BayesianRidge()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    " \n",
    "# evaluate a list of models on a dataset\n",
    "def evaluate_models(X, y, models):\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        mse = mean_squared_error(y, yhat)\n",
    "        print('%s: RMSE %.3f' % (model.__class__.__name__, sqrt(mse)))\n",
    "\n",
    "# make predictions with stacked model\n",
    "def super_learner_predictions_sum(X, models, meta_model):\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        meta_X.append(yhat.reshape(len(yhat),1))\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return meta_model.predict(meta_X)\n",
    " \n",
    "\n",
    "models = get_models()\n",
    "# get out of fold predictions\n",
    "meta_X, meta_y = get_out_of_fold_predictions(X_train, y_train, models)\n",
    "print('Meta ', meta_X.shape, meta_y.shape)\n",
    "# fit base models\n",
    "fit_base_models(X_train, y_train, models)\n",
    "# fit the meta model\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "# evaluate base models\n",
    "evaluate_models(X_test, y_test, models)\n",
    "yhat = super_learner_predictions_sum(X_test, models, meta_model)\n",
    "print('Super Learner: RMSE %.3f' % (sqrt(mean_squared_error(y_test, yhat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: RMSE 44.520\n",
      "ElasticNet: RMSE 65.731\n",
      "DecisionTreeRegressor: RMSE 5.565\n",
      "XGBRegressor: RMSE 3.711\n",
      "AdaBoostRegressor: RMSE 7.460\n",
      "BaggingRegressor: RMSE 3.930\n",
      "RandomForestRegressor: RMSE 3.926\n",
      "ExtraTreesRegressor: RMSE 3.900\n",
      "LGBMRegressor: RMSE 3.656\n",
      "Super Learner: RMSE 3.746\n"
     ]
    }
   ],
   "source": [
    "def fit_meta_model(X, y):\n",
    "    model = XGBRegressor()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "# evaluate base models\n",
    "evaluate_models(X_test, y_test, models)\n",
    "yhat = super_learner_predictions_sum(X_test, models, meta_model)\n",
    "print('Super Learner: RMSE %.3f' % (sqrt(mean_squared_error(y_test, yhat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_out = test_all.drop(columns=['card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tar_sum = f_model_sum_x.predict(final_test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_pickle('target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tar_sum = Tar_sum - 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['target_sum'] = Tar_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>br_o_r</th>\n",
       "      <th>br_r</th>\n",
       "      <th>xgb_o_r</th>\n",
       "      <th>xgb_r</th>\n",
       "      <th>ada_o_r</th>\n",
       "      <th>ada_r</th>\n",
       "      <th>dtr_o_r</th>\n",
       "      <th>dtr_r</th>\n",
       "      <th>model_en_o_r</th>\n",
       "      <th>...</th>\n",
       "      <th>stacking</th>\n",
       "      <th>stacking_o</th>\n",
       "      <th>stack_oof_o</th>\n",
       "      <th>stack_oof</th>\n",
       "      <th>oof_non_out</th>\n",
       "      <th>oof_non_out_nopara</th>\n",
       "      <th>stack_no_out</th>\n",
       "      <th>stack_no_out_para</th>\n",
       "      <th>lbgm_pred</th>\n",
       "      <th>target_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-33.700006</td>\n",
       "      <td>-2.150192</td>\n",
       "      <td>-33.158463</td>\n",
       "      <td>-3.967904</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-2.538394</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-2.210368</td>\n",
       "      <td>-5.183550</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.900542</td>\n",
       "      <td>-33.024661</td>\n",
       "      <td>-33.222214</td>\n",
       "      <td>-3.360535</td>\n",
       "      <td>-0.220527</td>\n",
       "      <td>-0.341691</td>\n",
       "      <td>-0.395160</td>\n",
       "      <td>-0.311781</td>\n",
       "      <td>-1.595954</td>\n",
       "      <td>-2.690558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.630376</td>\n",
       "      <td>-1.209783</td>\n",
       "      <td>-0.250791</td>\n",
       "      <td>-0.199351</td>\n",
       "      <td>-0.200819</td>\n",
       "      <td>-0.228062</td>\n",
       "      <td>-0.231458</td>\n",
       "      <td>-3.204083</td>\n",
       "      <td>-0.965219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233773</td>\n",
       "      <td>-0.283789</td>\n",
       "      <td>-0.296430</td>\n",
       "      <td>-0.335824</td>\n",
       "      <td>-0.252786</td>\n",
       "      <td>-0.207790</td>\n",
       "      <td>-0.282106</td>\n",
       "      <td>-0.129126</td>\n",
       "      <td>-0.203021</td>\n",
       "      <td>0.042033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.603817</td>\n",
       "      <td>-1.188017</td>\n",
       "      <td>-0.215734</td>\n",
       "      <td>-1.306369</td>\n",
       "      <td>-0.741702</td>\n",
       "      <td>-0.801687</td>\n",
       "      <td>-0.987153</td>\n",
       "      <td>-1.620944</td>\n",
       "      <td>-0.477401</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.133542</td>\n",
       "      <td>-0.298779</td>\n",
       "      <td>-0.452169</td>\n",
       "      <td>-1.241228</td>\n",
       "      <td>-0.781512</td>\n",
       "      <td>-0.503496</td>\n",
       "      <td>-0.484446</td>\n",
       "      <td>-0.410551</td>\n",
       "      <td>-0.912625</td>\n",
       "      <td>-1.694079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.187282</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>0.014168</td>\n",
       "      <td>-0.137127</td>\n",
       "      <td>-0.200819</td>\n",
       "      <td>-0.228062</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>-3.204083</td>\n",
       "      <td>-0.254504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178881</td>\n",
       "      <td>-0.013869</td>\n",
       "      <td>-0.084705</td>\n",
       "      <td>0.039719</td>\n",
       "      <td>-0.057083</td>\n",
       "      <td>-0.065306</td>\n",
       "      <td>-0.062662</td>\n",
       "      <td>-0.103893</td>\n",
       "      <td>-0.204388</td>\n",
       "      <td>-0.083882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-2.588666</td>\n",
       "      <td>-2.758021</td>\n",
       "      <td>-1.265175</td>\n",
       "      <td>-0.839355</td>\n",
       "      <td>-0.741702</td>\n",
       "      <td>-0.798787</td>\n",
       "      <td>-0.978239</td>\n",
       "      <td>-1.543981</td>\n",
       "      <td>-2.026128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.802406</td>\n",
       "      <td>-1.275639</td>\n",
       "      <td>-1.177096</td>\n",
       "      <td>-1.003892</td>\n",
       "      <td>-1.265887</td>\n",
       "      <td>-1.334409</td>\n",
       "      <td>-1.288947</td>\n",
       "      <td>-1.205569</td>\n",
       "      <td>-0.831957</td>\n",
       "      <td>-1.695802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id     br_o_r      br_r    xgb_o_r     xgb_r    ada_o_r  \\\n",
       "0  C_ID_0ab67a22ab -33.700006 -2.150192 -33.158463 -3.967904 -33.219281   \n",
       "1  C_ID_130fd0cbdd  -0.630376 -1.209783  -0.250791 -0.199351  -0.200819   \n",
       "2  C_ID_b709037bc5  -0.603817 -1.188017  -0.215734 -1.306369  -0.741702   \n",
       "3  C_ID_d27d835a9f  -0.187282 -0.015526   0.014168 -0.137127  -0.200819   \n",
       "4  C_ID_2b5e3df5c2  -2.588666 -2.758021  -1.265175 -0.839355  -0.741702   \n",
       "\n",
       "      ada_r    dtr_o_r     dtr_r  model_en_o_r  ...  stacking  stacking_o  \\\n",
       "0 -2.538394 -33.219281 -2.210368     -5.183550  ... -2.900542  -33.024661   \n",
       "1 -0.228062  -0.231458 -3.204083     -0.965219  ... -0.233773   -0.283789   \n",
       "2 -0.801687  -0.987153 -1.620944     -0.477401  ... -1.133542   -0.298779   \n",
       "3 -0.228062   0.006248 -3.204083     -0.254504  ... -0.178881   -0.013869   \n",
       "4 -0.798787  -0.978239 -1.543981     -2.026128  ... -0.802406   -1.275639   \n",
       "\n",
       "   stack_oof_o  stack_oof  oof_non_out  oof_non_out_nopara  stack_no_out  \\\n",
       "0   -33.222214  -3.360535    -0.220527           -0.341691     -0.395160   \n",
       "1    -0.296430  -0.335824    -0.252786           -0.207790     -0.282106   \n",
       "2    -0.452169  -1.241228    -0.781512           -0.503496     -0.484446   \n",
       "3    -0.084705   0.039719    -0.057083           -0.065306     -0.062662   \n",
       "4    -1.177096  -1.003892    -1.265887           -1.334409     -1.288947   \n",
       "\n",
       "   stack_no_out_para  lbgm_pred  target_sum  \n",
       "0          -0.311781  -1.595954   -2.690558  \n",
       "1          -0.129126  -0.203021    0.042033  \n",
       "2          -0.410551  -0.912625   -1.694079  \n",
       "3          -0.103893  -0.204388   -0.083882  \n",
       "4          -1.205569  -0.831957   -1.695802  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating final target by taking 4 best model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target_sum</th>\n",
       "      <th>stack_oof</th>\n",
       "      <th>stacking</th>\n",
       "      <th>lbgm_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.690558</td>\n",
       "      <td>-3.360535</td>\n",
       "      <td>-2.900542</td>\n",
       "      <td>-1.595954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>-0.335824</td>\n",
       "      <td>-0.233773</td>\n",
       "      <td>-0.203021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-1.694079</td>\n",
       "      <td>-1.241228</td>\n",
       "      <td>-1.133542</td>\n",
       "      <td>-0.912625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.083882</td>\n",
       "      <td>0.039719</td>\n",
       "      <td>-0.178881</td>\n",
       "      <td>-0.204388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.695802</td>\n",
       "      <td>-1.003892</td>\n",
       "      <td>-0.802406</td>\n",
       "      <td>-0.831957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  target_sum  stack_oof  stacking  lbgm_pred\n",
       "0  C_ID_0ab67a22ab   -2.690558  -3.360535 -2.900542  -1.595954\n",
       "1  C_ID_130fd0cbdd    0.042033  -0.335824 -0.233773  -0.203021\n",
       "2  C_ID_b709037bc5   -1.694079  -1.241228 -1.133542  -0.912625\n",
       "3  C_ID_d27d835a9f   -0.083882   0.039719 -0.178881  -0.204388\n",
       "4  C_ID_2b5e3df5c2   -1.695802  -1.003892 -0.802406  -0.831957"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = target[['card_id','target_sum','stack_oof','stacking','lbgm_pred']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['target'] = (1.2*df['target_sum'] + 1.7* df['stack_oof'] + 1.3* df['stacking'] + 1.3 *df['lbgm_pred'])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"target_sum\", \"stack_oof\",'stacking','lbgm_pred'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-3.696756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.272074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-1.700750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.132846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.466563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -3.696756\n",
       "1  C_ID_130fd0cbdd -0.272074\n",
       "2  C_ID_b709037bc5 -1.700750\n",
       "3  C_ID_d27d835a9f -0.132846\n",
       "4  C_ID_2b5e3df5c2 -1.466563"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result we got from all the above modeling is 3.72 so we took the 3 best target values and combining them to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = pd.read_csv('best1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = pd.read_csv('best2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = pd.read_csv('best3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = target[['card_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df1['target'] = (0.3*xx['target'] + 0.4*yy['target'] + 0.3*zz['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('df1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the final result we got is a little improvement we got 3.71 from our best 3 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we Try for neural networks to check if they can provide better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import layers,models,utils,Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Activation,BatchNormalization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_all[train_all['target'] > -20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = temp['target'].values\n",
    "X = temp.drop(columns=['target','card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing hyper parameter tunning for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=input_dim, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(10, kernel_initializer=init,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, kernel_initializer=init, activation='relu'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['mean_squared_error'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 6s 55us/sample - loss: 15.2725 - mean_squared_error: 15.2725\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0925 - mean_squared_error: 15.0925\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0833 - mean_squared_error: 15.0833s - loss: 15.1949 - mean_squared_\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0868 - mean_squared_error: 15.0868s - loss: 15.1013 - mean_squared_error:\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0792 - mean_squared_error: 15.0792s - loss: 15.0878 - mean_squared_error: 15.08\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 3s 32us/sample - loss: 15.0756 - mean_squared_error: 15.0756\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0737 - mean_squared_error: 15.0736\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0739 - mean_squared_error: 15.0739\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0748 - mean_squared_error: 15.0748s - loss: 15.0630 - mean_squared_erro\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0687 - mean_squared_error: 15.0687s - loss: 1\n",
      "50479/50479 [==============================] - 1s 10us/sample - loss: 15.1310 - mean_squared_error: 15.1310\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 42us/sample - loss: 15.2241 - mean_squared_error: 15.2241\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0985 - mean_squared_error: 15.0985s - loss: 14.8555 - mean_\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0956 - mean_squared_error: 15.0956\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0923 - mean_squared_error: 15.0923s - loss: 14.9521 - mean_squared_error: 14. - ETA: 2s - loss: 15.1778 -\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0828 - mean_squared_error: 15.0828\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 3s 32us/sample - loss: 15.0780 - mean_squared_error: 15.0780\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 3s 32us/sample - loss: 15.0720 - mean_squared_error: 15.0720s - loss: 15.0250 - mean_sq\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0695 - mean_squared_error: 15.0695\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0653 - mean_squared_error: 15.0653\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0630 - mean_squared_error: 15.0630s - loss: 15.0545 - mean_\n",
      "50479/50479 [==============================] - 1s 10us/sample - loss: 15.1093 - mean_squared_error: 15.1093\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 44us/sample - loss: 15.2197 - mean_squared_error: 15.2197\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 3s 32us/sample - loss: 15.1181 - mean_squared_error: 15.1181\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.1143 - mean_squared_error: 15.1143\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.1125 - mean_squared_error: 15.1125\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.1092 - mean_squared_error: 15.1092\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.1030 - mean_squared_error: 15.1030\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0998 - mean_squared_error: 15.0998\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0951 - mean_squared_error: 15.0951\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0934 - mean_squared_error: 15.0934s - loss: 15.1846 - mean_\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0933 - mean_squared_error: 15.0933\n",
      "50479/50479 [==============================] - 0s 10us/sample - loss: 260.0649 - mean_squared_error: 260.0650\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 41us/sample - loss: 15.0864 - mean_squared_error: 15.0864s - loss: 14.9976 - mean_squared_error: 1\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0689 - mean_squared_error: 15.0689\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 3s 32us/sample - loss: 15.0516 - mean_squared_error: 15.0516\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0490 - mean_squared_error: 15.0490\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0436 - mean_squared_error: 15.0436\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0407 - mean_squared_error: 15.0407\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0376 - mean_squared_error: 15.0376\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0347 - mean_squared_error: 15.0347\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0379 - mean_squared_error: 15.0379s - loss: 15.0332 - mean_squared_error: 15.03\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0393 - mean_squared_error: 15.0393s\n",
      "50479/50479 [==============================] - 1s 10us/sample - loss: 15.1314 - mean_squared_error: 15.1314\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 43us/sample - loss: 15.0925 - mean_squared_error: 15.0925\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0815 - mean_squared_error: 15.0815\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 3s 32us/sample - loss: 15.0743 - mean_squared_error: 15.0743\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0632 - mean_squared_error: 15.0631\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0575 - mean_squared_error: 15.0575s - loss: 14.7572 - mean_\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0581 - mean_squared_error: 15.0581\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0575 - mean_squared_error: 15.0575\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0573 - mean_squared_error: 15.0573\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0509 - mean_squared_error: 15.0509\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0519 - mean_squared_error: 15.0519\n",
      "50479/50479 [==============================] - 0s 10us/sample - loss: 15.1050 - mean_squared_error: 15.1050\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 42us/sample - loss: 15.1165 - mean_squared_error: 15.1165s - loss: 15.1021 - m\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.1032 - mean_squared_error: 15.1032\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0987 - mean_squared_error: 15.0987s - loss: 15.1442 - mea\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0948 - mean_squared_error: 15.0948\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0889 - mean_squared_error: 15.0889\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0825 - mean_squared_error: 15.0825\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0838 - mean_squared_error: 15.0838s - loss: 15.0183 -\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0829 - mean_squared_error: 15.0829\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0777 - mean_squared_error: 15.0777\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 3s 31us/sample - loss: 15.0830 - mean_squared_error: 15.0830\n",
      "50479/50479 [==============================] - 0s 10us/sample - loss: 15.1481 - mean_squared_error: 15.1481\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 36us/sample - loss: 15.1790 - mean_squared_error: 15.1790\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0905 - mean_squared_error: 15.0905\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0811 - mean_squared_error: 15.0811s - loss:\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0677 - mean_squared_error: 15.0677s - los\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0613 - mean_squared_error: 15.0613\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0501 - mean_squared_error: 15.0501\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0519 - mean_squared_error: 15.0519s - loss: 14.3520 - - ETA: 0s - loss: 15.0158 - mean_squared_error: 1\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0458 - mean_squared_error: 15.0458s - loss: 15.47\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0391 - mean_squared_error: 15.0391\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0374 - mean_squared_error: 15.0374\n",
      "50479/50479 [==============================] - 0s 9us/sample - loss: 15.1301 - mean_squared_error: 15.1301\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 35us/sample - loss: 15.2861 - mean_squared_error: 15.2861\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.1141 - mean_squared_error: 15.1141\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0986 - mean_squared_error: 15.0986\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0908 - mean_squared_error: 15.0908\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0900 - mean_squared_error: 15.0900\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0806 - mean_squared_error: 15.0806\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0747 - mean_squared_error: 15.0747\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0707 - mean_squared_error: 15.0707\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0716 - mean_squared_error: 15.0716\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0653 - mean_squared_error: 15.0653\n",
      "50479/50479 [==============================] - 0s 9us/sample - loss: 18.2799 - mean_squared_error: 18.2799\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 36us/sample - loss: 15.2511 - mean_squared_error: 15.2511\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.1294 - mean_squared_error: 15.1294\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.1172 - mean_squared_error: 15.1172\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.1102 - mean_squared_error: 15.1102s - loss: 15.1078 - mean_squared_error: 15.10\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.1100 - mean_squared_error: 15.1100\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.1036 - mean_squared_error: 15.1036\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - ETA: 0s - loss: 15.1372 - mean_squared_error: 15.13 - 2s 24us/sample - loss: 15.1035 - mean_squared_error: 15.1035\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0990 - mean_squared_error: 15.0990\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0945 - mean_squared_error: 15.0944\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0955 - mean_squared_error: 15.0955\n",
      "50479/50479 [==============================] - 0s 9us/sample - loss: 4190.9101 - mean_squared_error: 4190.9102\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 39us/sample - loss: 15.0864 - mean_squared_error: 15.0864\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0652 - mean_squared_error: 15.0652\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0556 - mean_squared_error: 15.0556\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 2s 25us/sample - loss: 15.0506 - mean_squared_error: 15.0506\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0405 - mean_squared_error: 15.0405\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0384 - mean_squared_error: 15.0384\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0354 - mean_squared_error: 15.0354\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0316 - mean_squared_error: 15.0316\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0257 - mean_squared_error: 15.0257\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0235 - mean_squared_error: 15.0235\n",
      "50479/50479 [==============================] - 0s 9us/sample - loss: 15.1289 - mean_squared_error: 15.1289\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 37us/sample - loss: 15.0934 - mean_squared_error: 15.0934\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0834 - mean_squared_error: 15.0834\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0715 - mean_squared_error: 15.0715\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0623 - mean_squared_error: 15.0623\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0563 - mean_squared_error: 15.0563\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0585 - mean_squared_error: 15.0585\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0549 - mean_squared_error: 15.0549\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0511 - mean_squared_error: 15.0511\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 3s 25us/sample - loss: 15.0470 - mean_squared_error: 15.0470\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 2s 25us/sample - loss: 15.0502 - mean_squared_error: 15.0502\n",
      "50479/50479 [==============================] - 0s 9us/sample - loss: 15.1044 - mean_squared_error: 15.1044\n",
      "Train on 100958 samples\n",
      "Epoch 1/10\n",
      "100958/100958 [==============================] - 4s 35us/sample - loss: 15.1195 - mean_squared_error: 15.1195\n",
      "Epoch 2/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.1060 - mean_squared_error: 15.1060\n",
      "Epoch 3/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0956 - mean_squared_error: 15.0956\n",
      "Epoch 4/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0888 - mean_squared_error: 15.0888\n",
      "Epoch 5/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0829 - mean_squared_error: 15.0829\n",
      "Epoch 6/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0850 - mean_squared_error: 15.0850\n",
      "Epoch 7/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0777 - mean_squared_error: 15.0777\n",
      "Epoch 8/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0807 - mean_squared_error: 15.0807\n",
      "Epoch 9/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0757 - mean_squared_error: 15.0757\n",
      "Epoch 10/10\n",
      "100958/100958 [==============================] - 2s 24us/sample - loss: 15.0719 - mean_squared_error: 15.0719\n",
      "50479/50479 [==============================] - 0s 9us/sample - loss: 15.0699 - mean_squared_error: 15.0699\n",
      "Train on 151437 samples\n",
      "Epoch 1/10\n",
      "151437/151437 [==============================] - 5s 31us/sample - loss: 15.0954 - mean_squared_error: 15.0954s - loss: 15.0525\n",
      "Epoch 2/10\n",
      "151437/151437 [==============================] - 4s 24us/sample - loss: 15.0796 - mean_squared_error: 15.0796\n",
      "Epoch 3/10\n",
      "151437/151437 [==============================] - 4s 24us/sample - loss: 15.0708 - mean_squared_error: 15.0708\n",
      "Epoch 4/10\n",
      "151437/151437 [==============================] - 4s 24us/sample - loss: 15.0626 - mean_squared_error: 15.0626\n",
      "Epoch 5/10\n",
      "151437/151437 [==============================] - 4s 24us/sample - loss: 15.0593 - mean_squared_error: 15.0593s - loss: 15.2510 - mean_sq\n",
      "Epoch 6/10\n",
      "151437/151437 [==============================] - 4s 24us/sample - loss: 15.0568 - mean_squared_error: 15.0568\n",
      "Epoch 7/10\n",
      "151437/151437 [==============================] - 4s 24us/sample - loss: 15.0556 - mean_squared_error: 15.0556\n",
      "Epoch 8/10\n",
      "151437/151437 [==============================] - 4s 24us/sample - loss: 15.0509 - mean_squared_error: 15.0509\n",
      "Epoch 9/10\n",
      "151437/151437 [==============================] - 4s 24us/sample - loss: 15.0540 - mean_squared_error: 15.0540\n",
      "Epoch 10/10\n",
      "151437/151437 [==============================] - 4s 24us/sample - loss: 15.0492 - mean_squared_error: 15.0492\n"
     ]
    }
   ],
   "source": [
    "model_init_batch_epoch_CV = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "\n",
    "# we choose the initializers that came at the top in our previous cross-validation!!\n",
    "init_mode = ['glorot_uniform', 'uniform'] \n",
    "batches = [512,1024]\n",
    "epochs = [10]\n",
    "\n",
    "# grid search for initializer, batch size and number of epochs\n",
    "param_grid = dict(epochs=epochs, batch_size=batches, init=init_mode)\n",
    "grid = GridSearchCV(estimator=model_init_batch_epoch_CV, \n",
    "                    param_grid=param_grid,\n",
    "                    cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy for -2.946 using {'batch_size': 1024, 'epochs': 10, 'init': 'glorot_uniform'}\n",
      "mean=-2.958, std=0.05131 using {'batch_size': 512, 'epochs': 10, 'init': 'glorot_uniform'}\n",
      "mean=-2.958, std=0.04909 using {'batch_size': 512, 'epochs': 10, 'init': 'uniform'}\n",
      "mean=-2.946, std=0.05645 using {'batch_size': 1024, 'epochs': 10, 'init': 'glorot_uniform'}\n",
      "mean=-2.954, std=0.05246 using {'batch_size': 1024, 'epochs': 10, 'init': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=input_dim, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, input_dim=input_dim, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, input_dim=input_dim, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(10, kernel_initializer=init, activation=tf.nn.relu))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, kernel_initializer=init, activation=tf.nn.relu))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149782 samples, validate on 49928 samples\n",
      "Epoch 1/20\n",
      "149782/149782 [==============================] - 34s 228us/sample - loss: 2.8197 - accuracy: 0.0023 - val_loss: 3912258422.7750 - val_accuracy: 0.0087\n",
      "Epoch 2/20\n",
      "149782/149782 [==============================] - 32s 216us/sample - loss: 2.8198 - accuracy: 0.0027 - val_loss: 9319091247.3137 - val_accuracy: 0.0088\n",
      "Epoch 3/20\n",
      "149782/149782 [==============================] - 35s 235us/sample - loss: 2.8157 - accuracy: 0.0026 - val_loss: 130136481.1777 - val_accuracy: 0.0087\n",
      "Epoch 4/20\n",
      "149782/149782 [==============================] - 35s 233us/sample - loss: 2.8173 - accuracy: 0.0024 - val_loss: 345881390.9606 - val_accuracy: 0.0087\n",
      "Epoch 5/20\n",
      "149782/149782 [==============================] - 35s 237us/sample - loss: 2.8166 - accuracy: 0.0022 - val_loss: 408687692.4500 - val_accuracy: 0.0088\n",
      "Epoch 6/20\n",
      "149782/149782 [==============================] - 35s 234us/sample - loss: 2.8146 - accuracy: 0.0027 - val_loss: 2762731513.1106 - val_accuracy: 0.0087\n",
      "Epoch 7/20\n",
      "149782/149782 [==============================] - 34s 224us/sample - loss: 2.8158 - accuracy: 0.0025 - val_loss: 231830636.8160 - val_accuracy: 0.0087\n",
      "Epoch 8/20\n",
      "149782/149782 [==============================] - 33s 222us/sample - loss: 2.8158 - accuracy: 0.0027 - val_loss: 68395077971.5399 - val_accuracy: 0.0087\n",
      "Epoch 9/20\n",
      "149782/149782 [==============================] - 33s 223us/sample - loss: 2.8150 - accuracy: 0.0029 - val_loss: 832217248.0803 - val_accuracy: 0.0087\n",
      "Epoch 10/20\n",
      "149782/149782 [==============================] - 33s 224us/sample - loss: 2.8188 - accuracy: 0.0022 - val_loss: 12809796.6183 - val_accuracy: 0.0087\n",
      "Epoch 11/20\n",
      "149782/149782 [==============================] - 34s 227us/sample - loss: 2.8165 - accuracy: 0.0026 - val_loss: 81877579.2576 - val_accuracy: 0.0087\n",
      "Epoch 12/20\n",
      "149782/149782 [==============================] - 34s 228us/sample - loss: 2.8117 - accuracy: 0.0029 - val_loss: 3954.1056 - val_accuracy: 0.0086\n",
      "Epoch 13/20\n",
      "149782/149782 [==============================] - 34s 229us/sample - loss: 2.8145 - accuracy: 0.0029 - val_loss: 6386550152.8316 - val_accuracy: 0.0086\n",
      "Epoch 14/20\n",
      "149782/149782 [==============================] - 35s 236us/sample - loss: 2.8114 - accuracy: 0.0030 - val_loss: 200945.3615 - val_accuracy: 0.0087\n",
      "Epoch 15/20\n",
      "149782/149782 [==============================] - 35s 233us/sample - loss: 2.8099 - accuracy: 0.0031 - val_loss: 8635862.5755 - val_accuracy: 0.0086\n",
      "Epoch 16/20\n",
      "149782/149782 [==============================] - 33s 222us/sample - loss: 2.8114 - accuracy: 0.0028 - val_loss: 13575915313.2573 - val_accuracy: 0.0086\n",
      "Epoch 17/20\n",
      "149782/149782 [==============================] - 33s 219us/sample - loss: 2.8141 - accuracy: 0.0030 - val_loss: 410861988.1482 - val_accuracy: 0.0087\n",
      "Epoch 18/20\n",
      "149782/149782 [==============================] - 33s 220us/sample - loss: 2.8149 - accuracy: 0.0026 - val_loss: 90984771125.0448 - val_accuracy: 0.0087\n",
      "Epoch 19/20\n",
      "149782/149782 [==============================] - 33s 219us/sample - loss: 2.8212 - accuracy: 0.0023 - val_loss: 18901290954455.8086 - val_accuracy: 0.0087\n",
      "Epoch 20/20\n",
      "149782/149782 [==============================] - 33s 221us/sample - loss: 2.8130 - accuracy: 0.0027 - val_loss: 1661427.0835 - val_accuracy: 0.0087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20254714b88>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.fit(X_train,y_train,epochs=20, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_out = test_all.drop(columns=['card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mo.predict(final_test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that neural networks are not doing very good job as the loss is very high and accuracy is very low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that folds provide better result and LBGM regressor provided good result so performing Kfolds on LBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.read_pickle('train_all.pkl')\n",
    "test_all = pd.read_pickle('test_all.pkl')\n",
    "test_all_out = pd.read_pickle('test_all_outliner.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_out = train_all.copy()\n",
    "train_all_out['outliers'] = 0\n",
    "train_all_out.loc[train_all['target'] < -30, 'outliers'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleting the features and removing features which are of date type\n",
    "y = train_all['target']\n",
    "X = train_all.drop(columns=['target','card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleting the features and removing features which are of date type\n",
    "y_o = train_all_out['target']\n",
    "X_o = train_all_out.drop(columns=['target','card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_all.drop(columns=['card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values\n",
    "test_o = test_all_out.drop(columns=['card_id','first_active_month','new_tr_purchase_date_max','new_tr_purchase_date_min','all_trans_purchase_date_max','all_trans_purchase_date_min']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Took help from kaggle to find the best hyper-parameter as mine was not giving the best result\n",
    "best_params_x = {'num_leaves': 50,\n",
    "            'boosting_type': 'rf',\n",
    "             'min_data_in_leaf': 30, \n",
    "             'objective':'regression',\n",
    "             'max_depth': -1,\n",
    "             'learning_rate': 0.01,\n",
    "             \"min_child_samples\": 20,\n",
    "             \"boosting\": \"gbdt\",\n",
    "             \"feature_fraction\": 0.9,\n",
    "             \"bagging_freq\": 1,\n",
    "             \"bagging_fraction\": 0.9 ,\n",
    "             \"bagging_seed\": 11,\n",
    "             \"metric\": 'rmse',\n",
    "             \"lambda_l1\": 0.1,\n",
    "             \"verbosity\": -1,\n",
    "             \"nthread\": 4,\n",
    "             \"random_state\": 33}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "fold n0\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 3.22351\tvalid_1's rmse: 3.7146\n",
      "[1800]\ttraining's rmse: 3.01788\tvalid_1's rmse: 3.71355\n",
      "Early stopping, best iteration is:\n",
      "[1372]\ttraining's rmse: 3.10652\tvalid_1's rmse: 3.71249\n",
      "----\n",
      "fold n1\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 3.22295\tvalid_1's rmse: 3.66664\n",
      "Early stopping, best iteration is:\n",
      "[1233]\ttraining's rmse: 3.1364\tvalid_1's rmse: 3.66548\n",
      "----\n",
      "fold n2\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 3.23039\tvalid_1's rmse: 3.59431\n",
      "[1800]\ttraining's rmse: 3.02541\tvalid_1's rmse: 3.59173\n",
      "Early stopping, best iteration is:\n",
      "[1937]\ttraining's rmse: 2.99964\tvalid_1's rmse: 3.59079\n",
      "----\n",
      "fold n3\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 3.22883\tvalid_1's rmse: 3.65521\n",
      "Early stopping, best iteration is:\n",
      "[1108]\ttraining's rmse: 3.17353\tvalid_1's rmse: 3.65423\n",
      "----\n",
      "fold n4\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 3.23997\tvalid_1's rmse: 3.51575\n",
      "Early stopping, best iteration is:\n",
      "[1018]\ttraining's rmse: 3.20686\tvalid_1's rmse: 3.51543\n",
      "----\n",
      "fold n5\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 3.22902\tvalid_1's rmse: 3.68036\n",
      "[1800]\ttraining's rmse: 3.02113\tvalid_1's rmse: 3.67933\n",
      "Early stopping, best iteration is:\n",
      "[1510]\ttraining's rmse: 3.0815\tvalid_1's rmse: 3.67765\n",
      "----\n",
      "fold n6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 3.20266\tvalid_1's rmse: 3.84942\n",
      "Early stopping, best iteration is:\n",
      "[1079]\ttraining's rmse: 3.15436\tvalid_1's rmse: 3.84839\n",
      "----\n",
      "fold n7\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 3.21793\tvalid_1's rmse: 3.74169\n",
      "[1800]\ttraining's rmse: 3.00872\tvalid_1's rmse: 3.73933\n",
      "Early stopping, best iteration is:\n",
      "[1991]\ttraining's rmse: 2.97205\tvalid_1's rmse: 3.73907\n",
      "----\n",
      "fold n8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 3.22551\tvalid_1's rmse: 3.65763\n",
      "Early stopping, best iteration is:\n",
      "[883]\ttraining's rmse: 3.23077\tvalid_1's rmse: 3.65732\n",
      "----\n",
      "fold n9\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 3.23431\tvalid_1's rmse: 3.58872\n",
      "Early stopping, best iteration is:\n",
      "[1020]\ttraining's rmse: 3.20105\tvalid_1's rmse: 3.58795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.665910556474236"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score = np.zeros(len(X))\n",
    "test_score  = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X.values, X.values)):\n",
    "    print('----')\n",
    "    print(\"fold n{}\".format(fold_))\n",
    "    \n",
    "    x0,y0 = X.iloc[trn_idx], y[trn_idx]\n",
    "    x1,y1 = X.iloc[val_idx], y[val_idx]\n",
    "    \n",
    "    trn_data = lgb.Dataset(x0, label= y0)\n",
    "    val_data = lgb.Dataset(x1, label= y1)\n",
    "    \n",
    "    num_round = 30000\n",
    "    clf = lgb.train(best_params_x, trn_data, num_round, valid_sets = [trn_data, val_data],verbose_eval=900, early_stopping_rounds = 500)\n",
    "    valid_score[val_idx] = clf.predict(x1, num_iteration=clf.best_iteration)\n",
    "        \n",
    "    test_score += clf.predict(test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "np.sqrt(mean_squared_error(valid_score, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "fold n0\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 1.49397\tvalid_1's rmse: 1.52704\n",
      "[1800]\ttraining's rmse: 1.44285\tvalid_1's rmse: 1.52588\n",
      "Early stopping, best iteration is:\n",
      "[2040]\ttraining's rmse: 1.43051\tvalid_1's rmse: 1.52565\n",
      "----\n",
      "fold n1\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 1.49071\tvalid_1's rmse: 1.56157\n",
      "[1800]\ttraining's rmse: 1.4395\tvalid_1's rmse: 1.5604\n",
      "[2700]\ttraining's rmse: 1.39578\tvalid_1's rmse: 1.55976\n",
      "[3600]\ttraining's rmse: 1.35513\tvalid_1's rmse: 1.55974\n",
      "Early stopping, best iteration is:\n",
      "[3182]\ttraining's rmse: 1.37364\tvalid_1's rmse: 1.55946\n",
      "----\n",
      "fold n2\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 1.49167\tvalid_1's rmse: 1.55746\n",
      "[1800]\ttraining's rmse: 1.44079\tvalid_1's rmse: 1.5553\n",
      "[2700]\ttraining's rmse: 1.39689\tvalid_1's rmse: 1.55484\n",
      "Early stopping, best iteration is:\n",
      "[2319]\ttraining's rmse: 1.41496\tvalid_1's rmse: 1.55475\n",
      "----\n",
      "fold n3\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 1.49157\tvalid_1's rmse: 1.55365\n",
      "[1800]\ttraining's rmse: 1.44059\tvalid_1's rmse: 1.55229\n",
      "[2700]\ttraining's rmse: 1.397\tvalid_1's rmse: 1.55213\n",
      "Early stopping, best iteration is:\n",
      "[2447]\ttraining's rmse: 1.40865\tvalid_1's rmse: 1.55182\n",
      "----\n",
      "fold n4\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 1.49378\tvalid_1's rmse: 1.53042\n",
      "[1800]\ttraining's rmse: 1.44279\tvalid_1's rmse: 1.5284\n",
      "[2700]\ttraining's rmse: 1.39906\tvalid_1's rmse: 1.52778\n",
      "[3600]\ttraining's rmse: 1.35826\tvalid_1's rmse: 1.5273\n",
      "Early stopping, best iteration is:\n",
      "[3607]\ttraining's rmse: 1.35797\tvalid_1's rmse: 1.5273\n",
      "----\n",
      "fold n5\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 1.48867\tvalid_1's rmse: 1.57945\n",
      "[1800]\ttraining's rmse: 1.4377\tvalid_1's rmse: 1.57805\n",
      "[2700]\ttraining's rmse: 1.39454\tvalid_1's rmse: 1.57769\n",
      "Early stopping, best iteration is:\n",
      "[2687]\ttraining's rmse: 1.39512\tvalid_1's rmse: 1.57763\n",
      "----\n",
      "fold n6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 1.49126\tvalid_1's rmse: 1.55833\n",
      "[1800]\ttraining's rmse: 1.44019\tvalid_1's rmse: 1.55673\n",
      "[2700]\ttraining's rmse: 1.39677\tvalid_1's rmse: 1.5564\n",
      "Early stopping, best iteration is:\n",
      "[2644]\ttraining's rmse: 1.39937\tvalid_1's rmse: 1.55629\n",
      "----\n",
      "fold n7\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 1.49053\tvalid_1's rmse: 1.56222\n",
      "[1800]\ttraining's rmse: 1.43962\tvalid_1's rmse: 1.56022\n",
      "[2700]\ttraining's rmse: 1.39597\tvalid_1's rmse: 1.56022\n",
      "Early stopping, best iteration is:\n",
      "[2341]\ttraining's rmse: 1.4127\tvalid_1's rmse: 1.55995\n",
      "----\n",
      "fold n8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 1.49158\tvalid_1's rmse: 1.55048\n",
      "[1800]\ttraining's rmse: 1.44073\tvalid_1's rmse: 1.5492\n",
      "Early stopping, best iteration is:\n",
      "[1862]\ttraining's rmse: 1.43758\tvalid_1's rmse: 1.54909\n",
      "----\n",
      "fold n9\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=rf will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[900]\ttraining's rmse: 1.49201\tvalid_1's rmse: 1.55241\n",
      "[1800]\ttraining's rmse: 1.44124\tvalid_1's rmse: 1.55059\n",
      "[2700]\ttraining's rmse: 1.39724\tvalid_1's rmse: 1.55016\n",
      "Early stopping, best iteration is:\n",
      "[2774]\ttraining's rmse: 1.39378\tvalid_1's rmse: 1.55003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5512652798740767"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score = np.zeros(len(X_o))\n",
    "test_score_o  = np.zeros(len(test_o))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_o.values, X_o.values)):\n",
    "    print('----')\n",
    "    print(\"fold n{}\".format(fold_))\n",
    "    \n",
    "    x0,y0 = X_o.iloc[trn_idx], y_o[trn_idx]\n",
    "    x1,y1 = X_o.iloc[val_idx], y_o[val_idx]\n",
    "    \n",
    "    trn_data = lgb.Dataset(x0, label= y0)\n",
    "    val_data = lgb.Dataset(x1, label= y1)\n",
    "    \n",
    "    num_round = 30000\n",
    "    clf = lgb.train(best_params_x, trn_data, num_round, valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval=900, early_stopping_rounds = 500)\n",
    "    valid_score[val_idx] = clf.predict(x1, num_iteration=clf.best_iteration)\n",
    "    \n",
    "    # feature_importance_df[:, fold_] = clf.feature_importance()\n",
    "    \n",
    "    test_score_o += clf.predict(test_o, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "np.sqrt(mean_squared_error(valid_score, y_o))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we created 2 kfolds LBGM models and merging their result and adding outlier varible to see what the model predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-3.154124</td>\n",
       "      <td>-36.811526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.326668</td>\n",
       "      <td>-0.210400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-1.250757</td>\n",
       "      <td>-0.952863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.244283</td>\n",
       "      <td>-0.222731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-0.905028</td>\n",
       "      <td>-0.919965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id   target1    target2  outliers\n",
       "0  C_ID_0ab67a22ab -3.154124 -36.811526         1\n",
       "1  C_ID_130fd0cbdd -0.326668  -0.210400         0\n",
       "2  C_ID_b709037bc5 -1.250757  -0.952863         0\n",
       "3  C_ID_d27d835a9f -0.244283  -0.222731         0\n",
       "4  C_ID_2b5e3df5c2 -0.905028  -0.919965         0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.DataFrame()\n",
    "id_test = test_all['card_id'].values\n",
    "so = pd.DataFrame()\n",
    "id_test_o = test_all['card_id'].values\n",
    "\n",
    "s['card_id']  = id_test\n",
    "s['target1']  = mfull * 1.12\n",
    "so['card_id'] = id_test_o\n",
    "so['target2']  = mfull_o *1.12\n",
    "\n",
    "ids = test_all_out[['card_id','outliers']]\n",
    "temp = pd.merge(so,ids,on='card_id',how='left')\n",
    "final = pd.merge(s,temp,on='card_id',how='left')\n",
    "final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are taking result from target1 when the point is outlier and taking result from target2 when the point is not outlier to created final target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll=[]\n",
    "for index, row in final.iterrows():\n",
    "    if row['outliers']>0:\n",
    "        ll.append(row['target1'])\n",
    "    else:\n",
    "        ll.append(row['target2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "id_test = final['card_id'].values\n",
    "\n",
    "sub['card_id']  = id_test\n",
    "sub['target']  = ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-3.154124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.952863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.222731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-0.919965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -3.154124\n",
       "1  C_ID_130fd0cbdd -0.210400\n",
       "2  C_ID_b709037bc5 -0.952863\n",
       "3  C_ID_d27d835a9f -0.222731\n",
       "4  C_ID_2b5e3df5c2 -0.919965"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above final target gave us the result of 3.707 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
